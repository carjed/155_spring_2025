[
  {
    "objectID": "solutions/03_slr_introduction.html",
    "href": "solutions/03_slr_introduction.html",
    "title": "Solutions for 03/04: Introduction to simple linear regression",
    "section": "",
    "text": "# Load packages and import data\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(dplyr)\n\nlifts &lt;- read_csv(\"https://mac-stat.github.io/data/powerlifting.csv\")"
  },
  {
    "objectID": "solutions/03_slr_introduction.html#exercise-1-get-to-know-the-data",
    "href": "solutions/03_slr_introduction.html#exercise-1-get-to-know-the-data",
    "title": "Solutions for 03/04: Introduction to simple linear regression",
    "section": "Exercise 1: Get to know the data",
    "text": "Exercise 1: Get to know the data\n\nUse an appropriate function to look at the first few rows of the data.\n\n\nhead(lifts)\n\n# A tibble: 6 × 21\n  Name        Sex   Event Equipment   Age BodyweightKg Best3SquatKg Best3BenchKg\n  &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1 Natalya Po… F     D     Raw        37           58.4          NA          NA  \n2 Fatima Rod… F     SBD   Single-p…  NA           74.8          NA          NA  \n3 Josh Kelley M     SBD   Single-p…  NA           72.4         147.         97.5\n4 Timothy Ca… M     D     Raw        16           72.9          NA          NA  \n5 M Moynihan  M     B     Raw        NA           67.5          NA         100  \n6 Lucas Wegr… M     B     Raw        23.5        103.           NA         188. \n# ℹ 13 more variables: Best3DeadliftKg &lt;dbl&gt;, TotalKg &lt;dbl&gt;, Place &lt;chr&gt;,\n#   Dots &lt;dbl&gt;, Wilks &lt;dbl&gt;, Glossbrenner &lt;dbl&gt;, Goodlift &lt;dbl&gt;, Tested &lt;chr&gt;,\n#   Country &lt;chr&gt;, State &lt;chr&gt;, Date &lt;date&gt;, MeetCountry &lt;chr&gt;, MeetState &lt;chr&gt;\n\n\n\nCreate a new code chunk, and use an appropriate function to learn how much data we have (in terms of cases and variables).\n\n\ndim(lifts)\n\n[1] 100000     21\n\n\n\nA case represents an individual lifter at a single weightlifting competition.\nIt looks like some meets may be missing if they weren’t detected by the web scraper used by the maintainers of the Open Powerlifting database. They don’t describe in detail the process used for transferring PDFs of results to their database, so it’s unclear what errors in transcription might have resulted. Still, it’s worth taking a moment to appreciate the labor they put into making these results available for passionate powerlifters to explore."
  },
  {
    "objectID": "solutions/03_slr_introduction.html#exercise-2-modifying-our-data",
    "href": "solutions/03_slr_introduction.html#exercise-2-modifying-our-data",
    "title": "Solutions for 03/04: Introduction to simple linear regression",
    "section": "Exercise 2: Modifying our data",
    "text": "Exercise 2: Modifying our data\nStrength-to-weight ratio (SWR) is defined as TotalKg/BodyweightKg. We can use the mutate() function from the dplyr package to create a new variable in our dataframe for SWR using the following code:\n\nlifts &lt;- lifts %&gt;% \n    mutate(SWR = TotalKg / BodyweightKg)\n\nAdapt the example above to create a new variable called SWR, where SWR is defined as TotalKg/BodyweightKg."
  },
  {
    "objectID": "solutions/03_slr_introduction.html#exercise-3-get-to-know-the-outcomeresponse-variable",
    "href": "solutions/03_slr_introduction.html#exercise-3-get-to-know-the-outcomeresponse-variable",
    "title": "Solutions for 03/04: Introduction to simple linear regression",
    "section": "Exercise 3: Get to know the outcome/response variable",
    "text": "Exercise 3: Get to know the outcome/response variable\nLet’s get acquainted with the SWR variable.\n\nConstruct an appropriate plot to visualize the distribution of this variable, and compute appropriate numerical summaries.\n\n\nlifts %&gt;%\n  ggplot(aes(SWR)) +\n  geom_histogram(bins = 10, col = \"black\")\n\nWarning: Removed 8752 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\nlifts %&gt;% summarize(mean(SWR, na.rm = TRUE), min(SWR, na.rm = TRUE), max(SWR, na.rm = TRUE), sd(SWR, na.rm = TRUE))\n\n# A tibble: 1 × 4\n  `mean(SWR, na.rm = TRUE)` `min(SWR, na.rm = TRUE)` `max(SWR, na.rm = TRUE)`\n                      &lt;dbl&gt;                    &lt;dbl&gt;                    &lt;dbl&gt;\n1                      4.42                    0.183                     12.5\n# ℹ 1 more variable: `sd(SWR, na.rm = TRUE)` &lt;dbl&gt;\n\n\n\nWrite a good paragraph interpreting the plot and numerical summaries.\n\nStrength-to-weight (SWR) ratio ranges from 0.18 to 12.46, with a mean SWR of 4.4. SWR varies about 2.08 units above and below the mean. We observe that most SWRs appear to be centered between 4 and 7, with a slight right-skew to the data. The distribution of SWRs appears to be unimodal."
  },
  {
    "objectID": "solutions/03_slr_introduction.html#exercise-4-data-visualization---two-quantitative-variables",
    "href": "solutions/03_slr_introduction.html#exercise-4-data-visualization---two-quantitative-variables",
    "title": "Solutions for 03/04: Introduction to simple linear regression",
    "section": "Exercise 4: Data visualization - two quantitative variables",
    "text": "Exercise 4: Data visualization - two quantitative variables\nWe’d like to visualize the relationship between body weight and the strength-to-weight ratio. A scatterplot (or informally, a “point cloud”) allows us to do this! The code below creates a scatterplot of body weight vs. SWR using ggplot().\n\n# scatterplot\n\n# The alpha = 0.5 in geom_point() adds transparency to the points\n# to make them easier to see. You can make this smaller for more transparency\nlifts %&gt;%\n  ggplot(aes(x = BodyweightKg, y = SWR)) +\n  geom_point(alpha = 0.5)\n\nWarning: Removed 8752 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\na & b. In our plot aesthetics, we now have two variables listed (an “x” and a “y”) as opposed to just a single variable. The “geom” for a scatterplot is geom_point. Otherwise, the code structure remains very similar!\n\nIn general, it seems as though higher body weights are associated with lower SWRs. Once body weight (in kg) is greater than 50, the relationship between body weight and SWR appears to be weakly negative, and roughly linear. The points are very dispersed, indicating that there is a good amount of variation in this relationship (hence the term “weak”)."
  },
  {
    "objectID": "solutions/03_slr_introduction.html#exercise-5-scatterplots---patterns-in-point-clouds",
    "href": "solutions/03_slr_introduction.html#exercise-5-scatterplots---patterns-in-point-clouds",
    "title": "Solutions for 03/04: Introduction to simple linear regression",
    "section": "Exercise 5: Scatterplots - patterns in point clouds",
    "text": "Exercise 5: Scatterplots - patterns in point clouds\nSometimes, it can be easier to see a pattern in a point cloud by adding a smoothing line to our scatterplots. The code below adapts the code in Exercise 4 to do this:\n\n# scatterplot with smoothing line\nlifts %&gt;%\n  ggplot(aes(x = BodyweightKg, y = SWR)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\nWarning: Removed 8752 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 8752 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\nThis doesn’t change my answer much (but it may have changed yours, and that’s okay!). It does appear as though there is a weakly negative relationship between body weight and SWR, particularly once body weight is above a certain value.\nI would say that yes, a linear relationship here seems reasonable! Even though there is some curvature in the smoothed trend line early on, that is based on very few data points. Those data points with low body weights aren’t enough to convince me that the relationship couldn’t be roughly linear between body weight and SWR."
  },
  {
    "objectID": "solutions/03_slr_introduction.html#exercise-6-correlation",
    "href": "solutions/03_slr_introduction.html#exercise-6-correlation",
    "title": "Solutions for 03/04: Introduction to simple linear regression",
    "section": "Exercise 6: Correlation",
    "text": "Exercise 6: Correlation\n\nI would describe the correlation between body weight and SWR as weak and negative.\nI’ll guess -0.1, since the line is negative, and the points are very dispersed around the line!"
  },
  {
    "objectID": "solutions/03_slr_introduction.html#exercise-7-computing-correlation-in-r",
    "href": "solutions/03_slr_introduction.html#exercise-7-computing-correlation-in-r",
    "title": "Solutions for 03/04: Introduction to simple linear regression",
    "section": "Exercise 7: Computing correlation in R",
    "text": "Exercise 7: Computing correlation in R\n\n# correlation\n\n# Note: the order in which you put your two quantitative variables into the cor\n# function doesn't matter! Try switching them around to confirm this for yourself\n# Because of the missing data, we need to include the use = \"complete.obs\" - otherwise the correlation would be computed as NA\nlifts %&gt;%\n    summarize(cor(SWR, BodyweightKg, use = \"complete.obs\"))\n\n# A tibble: 1 × 1\n  `cor(SWR, BodyweightKg, use = \"complete.obs\")`\n                                           &lt;dbl&gt;\n1                                        -0.0392\n\n\nSo close to our guess!"
  },
  {
    "objectID": "solutions/03_slr_introduction.html#exercise-8-model-fitting-and-coefficient-interpretation",
    "href": "solutions/03_slr_introduction.html#exercise-8-model-fitting-and-coefficient-interpretation",
    "title": "Solutions for 03/04: Introduction to simple linear regression",
    "section": "Exercise 8: Model fitting and coefficient interpretation",
    "text": "Exercise 8: Model fitting and coefficient interpretation\nLet’s fit a simple linear regression model and examine the results. Step through the code chunks slowly, and make note of new code.\n\n# Construct and save the model as lifts_mod\n# the lm() function has two required arguments:\n#  - What's the purpose of \"SWR ~ BodyweightKg\"?\n#  - What's the purpose of \"data = lifts\"?\nlifts_mod &lt;- lm(SWR ~ BodyweightKg, data = lifts)\n\n\n# The summary() function gives us a detailed glance at the model stored in lifts_mod\nsummary(lifts_mod)\n\n\nCall:\nlm(formula = SWR ~ BodyweightKg, data = lifts)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.3580 -1.9088  0.2323  1.6092  7.9827 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   4.7302909  0.0272262  173.74   &lt;2e-16 ***\nBodyweightKg -0.0037754  0.0003187  -11.85   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.076 on 91246 degrees of freedom\n  (8752 observations deleted due to missingness)\nMultiple R-squared:  0.001535,  Adjusted R-squared:  0.001524 \nF-statistic: 140.3 on 1 and 91246 DF,  p-value: &lt; 2.2e-16\n\n\n\n# A simplified model summary of just the coefficients\ncoef(summary(lifts_mod))\n\n                 Estimate  Std. Error   t value     Pr(&gt;|t|)\n(Intercept)   4.730290938 0.027226248 173.74010 0.000000e+00\nBodyweightKg -0.003775391 0.000318745 -11.84455 2.425487e-32\n\n\n\nUsing the model summary output, complete the following model formula:\nE[SWR | BodyweightKg] = 5.875 + -0.0097 * BodyweightKg\nInterpret the intercept in terms of the data context. Make sure to use non-causal language, include units, and talk about averages rather than individual cases. Is the intercept meaningful in this situation?\n\n\nThe intercept means that on average, we expect n individual with a bodyweight of 0Kg to have a SWR of 5.875. This is not meaningful because a bodyweight of 0Kg is not possible!\n\n\nInterpret the slope in terms of the data context. Make sure to use non-causal language, include units, and talk about averages rather than individual cases.\n\n\nThe slope coefficient tells us that on average, we expect that a lifter’s SWR decreases by 0.0097 per 1Kg increase in bodyweight–so generally, we find that people in this particular dataset (i.e., competitive weightlifters) who weigh less tend to have a higher SWR."
  },
  {
    "objectID": "solutions/03_slr_introduction.html#exercise-9-predictions-and-residuals",
    "href": "solutions/03_slr_introduction.html#exercise-9-predictions-and-residuals",
    "title": "Solutions for 03/04: Introduction to simple linear regression",
    "section": "Exercise 9: Predictions and residuals",
    "text": "Exercise 9: Predictions and residuals\nLet’s look at how well our model does at predicting the strength-weight ratio for a lifter named “Chris Della Fave.” We can get the relevant observed data for Della Fave using the filter() and select() dplyr functions. Note–but don’t worry about–the syntax for the select() function, we haven’t learned this yet:\n\nlifts %&gt;% \n    filter(Name == \"Chris Della Fave\") %&gt;% \n    select(BodyweightKg, SWR) \n\n# A tibble: 1 × 2\n  BodyweightKg   SWR\n         &lt;dbl&gt; &lt;dbl&gt;\n1         118.  11.0\n\n\n\nPeek back at the scatterplot you made in exercise 6a. Identify which point corresponds to this lifter. Is it close to the trend? Is their SWR higher or lower than expected?\n\n\nThe observed SWR for Della Fave is much higher than the trendline\n\n\nUse your model formula from the previous exercise to find what our model predicts Della Fave’s SWR should be, based on his body weight. (That is, where do individuals with similar body weight fall on the model trend line? What SWR should would we expect from a 118.4kg lifter?)\n\n\n5.875 + -0.0097 *118.4 = 4.73 The predicted SWR is much lower than the observed\n\n\nCheck your part b calculation using the predict() function. Take careful note of the syntax – there’s a lot going on!\n\n\n# What is the purpose of newdata = ___???\npredict(lifts_mod, newdata = data.frame(BodyweightKg = 118.39))\n\n       1 \n4.283322 \n\n\n\nCalculate the residual or prediction error. How far does Della Fave’s observed SWR fall from the model prediction?\n\n\nresidual = observed y - predicted y = 10.98-4.73 = 6.25\n\n\nAre positive residuals above or below the trend line? When we have positive residuals, does the model over- or under-estimate SWR? Repeat these questions for negative residuals.\n\n\npositive residual = above the trendline, so the model has UNDERestimated SWR in this case.\n\n\nnegative residual = below the trendline, so when this occurs, the model has OVERestimated SWR."
  },
  {
    "objectID": "solutions/03_slr_introduction.html#exercise-10-lines-of-best-fit",
    "href": "solutions/03_slr_introduction.html#exercise-10-lines-of-best-fit",
    "title": "Solutions for 03/04: Introduction to simple linear regression",
    "section": "Exercise 10: Lines of best fit",
    "text": "Exercise 10: Lines of best fit\nIn this activity, we’ve learned how to fit straight lines to data, to help us visualize the relationship between two quantitative variables. So far, ggplot has chosen the line for us. How does it know which line is “best”, and what does “best” even mean?\nFor this exercise, we’ll be working with the anscombe dataset, which is built in to R. To load this dataset into our environment, we run the following code:\n\n# load anscombe data\ndata(\"anscombe\")\n\nWe’ll consider the relationship between the x1 and y1 variables in the anscombe dataset. Run the following code, which creates a scatterplot with a fitted line to our data using the function geom_abline:\n\n# scatterplot with a fitted line, whose slope is 0.4 and intercept is 3\nanscombe %&gt;%\n  ggplot(aes(x = x1, y = y1)) +\n  geom_point() +\n  geom_abline(slope = 0.4, intercept = 3, col = \"blue\", size = 1)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\nDescribe the line that you see. Do you think the line is “good”? What are you using to define “good”?\nSome things to think about:\n\nHow many points are above the line?\nHow many points are below the line?\nAre the distances of the points above and below the line roughly similar, or is there meaningful difference?\n\nNow we’ll add another line to our plot. Which line do you think is better suited for this data? Why? Be specific!\n\n# scatterplot with a fitted line, whose slope is 0.4 and intercept is 3\nanscombe %&gt;%\n  ggplot(aes(x = x1, y = y1)) +\n  geom_point() +\n  geom_abline(slope = 0.4, intercept = 3, col = \"blue\", size = 1) +\n  geom_abline(slope = 0.5, intercept = 4, col = \"orange\", size = 1)\n\n\n\n\n\n\n\n\nIt’s usually quite simple to note when a line is bad, but more difficult to quantify when a line is a good fit for our data. Consider the following line:\n\n# scatterplot with a fitted line, whose slope is 0.4 and intercept is 3\nanscombe %&gt;%\n  ggplot(aes(x = x1, y = y1)) +\n  geom_point() +\n  geom_abline(slope = -0.5, intercept = 10, col = \"red\", size = 1) \n\n\n\n\n\n\n\n\nIn the reading/videos for today, we formalized the principle of least squares, which gives us one particular definition of a line of best fit that is commonly used in statistics! We’ll take advantage of the vertical distances between each point and the fitted line (residuals), which will help us define (mathematically) a line that best fits our data:\n\nlibrary(broom)\nanscombe %&gt;%\n  lm(y1 ~ x1, data = .) %&gt;%\n  augment() %&gt;%\n  ggplot(aes(x = x1, y = y1)) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  geom_segment(aes(xend = x1, yend = .fitted), col = \"red\") +\n  geom_point()\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "solutions/03_slr_introduction.html#exercise-11-data-drills-filter-select-summarize",
    "href": "solutions/03_slr_introduction.html#exercise-11-data-drills-filter-select-summarize",
    "title": "Solutions for 03/04: Introduction to simple linear regression",
    "section": "Exercise 11: Data drills (filter, select, summarize)",
    "text": "Exercise 11: Data drills (filter, select, summarize)\nThis exercise is designed to help you keep building your dplyr skills. These skills are important to data cleaning and digging, which in turn is important to really making meaning of our data. We’ll work with a simpler set of 10 data points:\n\nnew_lifts &lt;- lifts %&gt;% \n    select(Name, State, Sex, Age, BodyweightKg, SWR) %&gt;% \n    head(10)\n\n\nVerb 1: summarize\nThus far, in the dplyr grammar you’ve seen 3 verbs or action words: summarize(), select(), filter(). Try out the following code and then summarize the point of the summarize() function:\n\nnew_lifts %&gt;% \n    summarize(mean_bodyweight = mean(BodyweightKg, na.rm=T),\n              mean_SWR = mean(SWR, na.rm=T))\n\n# A tibble: 1 × 2\n  mean_bodyweight mean_SWR\n            &lt;dbl&gt;    &lt;dbl&gt;\n1            75.3     3.52\n\n\n\n\nVerb 2: select\nTry out the following code and then summarize the point of the select() function:\n\nnew_lifts %&gt;%\n    select(Name, State)\n\n# A tibble: 10 × 2\n   Name               State\n   &lt;chr&gt;              &lt;chr&gt;\n 1 Natalya Polenova   &lt;NA&gt; \n 2 Fatima Rodriguez   &lt;NA&gt; \n 3 Josh Kelley        &lt;NA&gt; \n 4 Timothy Catlin     &lt;NA&gt; \n 5 M Moynihan         QLD  \n 6 Lucas Wegrzyn      &lt;NA&gt; \n 7 Shane Brinker      MO   \n 8 Robbie Walden      &lt;NA&gt; \n 9 Katelynn Henderson AZ   \n10 Marko Basic        &lt;NA&gt; \n\n\n\nnew_lifts %&gt;% \n    select(-Name, -State)\n\n# A tibble: 10 × 4\n   Sex     Age BodyweightKg   SWR\n   &lt;chr&gt; &lt;dbl&gt;        &lt;dbl&gt; &lt;dbl&gt;\n 1 F      37           58.4  1.58\n 2 F      NA           74.8 NA   \n 3 M      NA           72.4  5.74\n 4 M      16           72.9  2.37\n 5 M      NA           67.5  1.48\n 6 M      23.5        103.   1.82\n 7 M      24.5         82.3  6.74\n 8 M      NA           56    2.81\n 9 F      25.5         93.2  4.26\n10 M      20.5         72.6  4.85\n\n\n\n\nVerb 3: filter\nTry out the following code and then summarize the point of the filter() function:\n\nnew_lifts %&gt;% \n    filter(Age &gt;=28)\n\n# A tibble: 1 × 6\n  Name             State Sex     Age BodyweightKg   SWR\n  &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;        &lt;dbl&gt; &lt;dbl&gt;\n1 Natalya Polenova &lt;NA&gt;  F        37         58.4  1.58\n\n\n\nnew_lifts %&gt;% \n    filter(State == \"CA\")\n\n# A tibble: 0 × 6\n# ℹ 6 variables: Name &lt;chr&gt;, State &lt;chr&gt;, Sex &lt;chr&gt;, Age &lt;dbl&gt;,\n#   BodyweightKg &lt;dbl&gt;, SWR &lt;dbl&gt;\n\n\n\nnew_lifts %&gt;% \n    filter(Age &gt;= 28, State==\"CA\")\n\n# A tibble: 0 × 6\n# ℹ 6 variables: Name &lt;chr&gt;, State &lt;chr&gt;, Sex &lt;chr&gt;, Age &lt;dbl&gt;,\n#   BodyweightKg &lt;dbl&gt;, SWR &lt;dbl&gt;\n\n\nUse dplyr verbs to complete each task below using the new_lifts dataframe.\n\n# Keep only BodyweightKg and SWR variables\n\nnew_lifts %&gt;%\n  select(BodyweightKg, SWR)\n\n# A tibble: 10 × 2\n   BodyweightKg   SWR\n          &lt;dbl&gt; &lt;dbl&gt;\n 1         58.4  1.58\n 2         74.8 NA   \n 3         72.4  5.74\n 4         72.9  2.37\n 5         67.5  1.48\n 6        103.   1.82\n 7         82.3  6.74\n 8         56    2.81\n 9         93.2  4.26\n10         72.6  4.85\n\n# Keep only BodyweightKg and SWR variables using a different approach\nnew_lifts %&gt;%\n  select(-Name, -State, -Age, -Sex)\n\n# A tibble: 10 × 2\n   BodyweightKg   SWR\n          &lt;dbl&gt; &lt;dbl&gt;\n 1         58.4  1.58\n 2         74.8 NA   \n 3         72.4  5.74\n 4         72.9  2.37\n 5         67.5  1.48\n 6        103.   1.82\n 7         82.3  6.74\n 8         56    2.81\n 9         93.2  4.26\n10         72.6  4.85\n\n# Keep only participants (observations) who are female\nnew_lifts %&gt;%\n  filter(Sex==\"F\")\n\n# A tibble: 3 × 6\n  Name               State Sex     Age BodyweightKg   SWR\n  &lt;chr&gt;              &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;        &lt;dbl&gt; &lt;dbl&gt;\n1 Natalya Polenova   &lt;NA&gt;  F      37           58.4  1.58\n2 Fatima Rodriguez   &lt;NA&gt;  F      NA           74.8 NA   \n3 Katelynn Henderson AZ    F      25.5         93.2  4.26\n\n# Keep only participants (observations) who are female and younger than 30\nnew_lifts %&gt;%\n  filter(Sex==\"F\", Age&lt;30)\n\n# A tibble: 1 × 6\n  Name               State Sex     Age BodyweightKg   SWR\n  &lt;chr&gt;              &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;        &lt;dbl&gt; &lt;dbl&gt;\n1 Katelynn Henderson AZ    F      25.5         93.2  4.26\n\n# Calculate the maximum and minimum ages of participants\nnew_lifts %&gt;%\n  summarise(age_min = min(Age, na.rm=T),\n            age_max = max(Age, na.rm=T))\n\n# A tibble: 1 × 2\n  age_min age_max\n    &lt;dbl&gt;   &lt;dbl&gt;\n1      16      37"
  },
  {
    "objectID": "solutions/03_slr_introduction.html#exercise-12-limitations-of-correlation",
    "href": "solutions/03_slr_introduction.html#exercise-12-limitations-of-correlation",
    "title": "Solutions for 03/04: Introduction to simple linear regression",
    "section": "Exercise 12: Limitations of correlation",
    "text": "Exercise 12: Limitations of correlation\n\n# correlation between x1, y1\nanscombe %&gt;% summarize(cor(x1, y1))\n\n  cor(x1, y1)\n1   0.8164205\n\n# correlation between x2, y2\nanscombe %&gt;% summarize(cor(x2, y2))\n\n  cor(x2, y2)\n1   0.8162365\n\n# correlation between x3, y3\nanscombe %&gt;% summarize(cor(x3, y3))\n\n  cor(x3, y3)\n1   0.8162867\n\n# correlation between x4, y4\nanscombe %&gt;% summarize(cor(x4, y4))\n\n  cor(x4, y4)\n1   0.8165214\n\n\n\nEach of these correlations are nearly the same!\nEach of these correlations is relatively strong, and positive, since 0.8 is positive and closer to 1 than 0.\n\n\n\n# scatterplot: x1, y1\nanscombe %&gt;%\n  ggplot(aes(x = x1, y = y1)) +\n  geom_point()\n\n\n\n\n\n\n\n# scatterplot: x2, y2\nanscombe %&gt;%\n  ggplot(aes(x = x2, y = y2)) +\n  geom_point()\n\n\n\n\n\n\n\n# scatterplot: x3, y3\nanscombe %&gt;%\n  ggplot(aes(x = x3, y = y3)) +\n  geom_point()\n\n\n\n\n\n\n\n# scatterplot: x4, y4\nanscombe %&gt;%\n  ggplot(aes(x = x4, y = y4)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nThe message of this exercise is that data visualization is important in addition to numerical summaries! Many different sets of points can have nearly the same correlation, but display very different patterns in point clouds upon closer inspection. Reporting correlation alone is not enough to summarize the relationship between two quantitative variables, and should be accompanied by a scatter plot!"
  },
  {
    "objectID": "solutions/03_slr_introduction.html#exercise-13-correlation-and-extreme-values",
    "href": "solutions/03_slr_introduction.html#exercise-13-correlation-and-extreme-values",
    "title": "Solutions for 03/04: Introduction to simple linear regression",
    "section": "Exercise 13: Correlation and extreme values",
    "text": "Exercise 13: Correlation and extreme values\n\n# create a toy dataset\nset.seed(1234)\nx &lt;- rnorm(100, mean = 5, sd = 2)\ny &lt;- -3 * x + rnorm(100, sd = 4)\ndat &lt;- data.frame(x = x, y = y)\n\n\n\n\n\n# scatterplot\ndat %&gt;% \n  ggplot(aes(x = x, y = y)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nThe correlation between x and y is moderately strong and negative.\nI’ll guess -0.6, since the relationship is negative and is sort of in-between weak and strong.\n\n\n\n# correlation\ndat %&gt;% summarize(cor(x, y))\n\n   cor(x, y)\n1 -0.8295483\n\n\n\n\n\n\n# creating dat_new1\nx1 &lt;- c(x, 15)\ny1 &lt;- c(y, -45)\ndat_new1 &lt;- data.frame(x = x1, y = y1)\n\n\n\n\n\n# scatterplot\ndat_new1 %&gt;%\n  ggplot(aes(x1, y1)) +\n  geom_point()\n\n\n\n\n\n\n\n# correlation\ndat %&gt;% summarize(cor(x1, y1))\n\n  cor(x1, y1)\n1  -0.8573567\n\n\nOur correlation stayed roughly the same with the addition of this new point!\n\n\n\n\n# creating dat_new1\nx2 &lt;- c(x, 15)\ny2 &lt;- c(y, 45)\ndat_new2 &lt;- data.frame(x = x2, y = y2)\n\n\n\n\n\n# scatterplot\ndat_new2 %&gt;%\n  ggplot(aes(x2, y2)) +\n  geom_point()\n\n\n\n\n\n\n\n# correlation\ndat_new2 %&gt;% summarize(cor(x2, y2))\n\n  cor(x2, y2)\n1  -0.2924792\n\n\nThe correlation changes quite a bit with the addition of this new point! Something to note is that this new point does not follow the rough linear trend that the original points had, that the first point we considered adding also had. This line seems way off base, comparatively!\n\nThe takeaway message here is that even though both of these additional points might be considered “outliers” because they have extreme x values, one changes the relationship between x and y much more than the other. In this case, the second point we considered would be influential because it changes the observed relationship between all x’s and y’s much more than the first point we considered. Not all “outliers” are considered equal!\n\n\n\n\n\ndat_new1 %&gt;%\n  ggplot(aes(x1, y1)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\ndat_new2 %&gt;%\n  ggplot(aes(x2, y2)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "activities/02_foundations_univariate.html",
    "href": "activities/02_foundations_univariate.html",
    "title": "02. Univariate visualization and summaries",
    "section": "",
    "text": "Download the .qmd file for this activity here.",
    "crumbs": [
      "02. Univariate visualization and summaries"
    ]
  },
  {
    "objectID": "activities/02_foundations_univariate.html#learning-goals",
    "href": "activities/02_foundations_univariate.html#learning-goals",
    "title": "02. Univariate visualization and summaries",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of this lesson, you should be able to:\n\nDescribe what a case (or unit of analysis) represents in a dataset.\nDescribe what a variable represents in a dataset.\nIdentify whether a variable is categorical or quantitative and what summarizations and visualizations are appropriate for that variable\nWrite R code to read in data and to summarize and visualize a single variable at a time.\nInterpret key features of barplots, boxplots, histograms, and density plots\nDescribe information about the distribution of a quantitative variable using the concepts of shape, center, spread, and outliers\nRelate summary statistics of data to the concepts of shape, center, spread, and outliers",
    "crumbs": [
      "02. Univariate visualization and summaries"
    ]
  },
  {
    "objectID": "activities/02_foundations_univariate.html#readings-and-videos",
    "href": "activities/02_foundations_univariate.html#readings-and-videos",
    "title": "02. Univariate visualization and summaries",
    "section": "Readings and videos",
    "text": "Readings and videos\nChoose either the reading or the videos to go through before class.\n\nReading: Sections 2.1-2.4, 2.6 in the STAT 155 Notes\nVideos:\n\nUnivariate visualization and summarization (slides)\nR Code for Categorical Visualization and Summarization\nR Code for Quantitative Visualization and Summarization\n\n\n\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder.",
    "crumbs": [
      "02. Univariate visualization and summaries"
    ]
  },
  {
    "objectID": "activities/02_foundations_univariate.html#exercise-1-get-curious",
    "href": "activities/02_foundations_univariate.html#exercise-1-get-curious",
    "title": "02. Univariate visualization and summaries",
    "section": "Exercise 1: Get curious",
    "text": "Exercise 1: Get curious\n\nHypothesize with each other: what themes do you think might come up often in Dear Abby letters?\nAfter brainstorming, take a quick glance at the original article from The Pudding to see what themes they explored.\nGo to the very end of the Pudding article to the section titled “Data and Method”. In thinking about the who, what, when, where, why, and how of data context, what concerns/limitations surface with regards to using this data to learn about Americans’ concerns over the decades?",
    "crumbs": [
      "02. Univariate visualization and summaries"
    ]
  },
  {
    "objectID": "activities/02_foundations_univariate.html#exercise-2-importing-and-getting-to-know-the-data",
    "href": "activities/02_foundations_univariate.html#exercise-2-importing-and-getting-to-know-the-data",
    "title": "02. Univariate visualization and summaries",
    "section": "Exercise 2: Importing and getting to know the data",
    "text": "Exercise 2: Importing and getting to know the data\nFirst, in the Console pane of RStudio, run the following command to install some necessary packages (you will need to do this any time you are installing a new package):\ninstall.packages(\"tidyverse\")\nNow, in the Quarto pane, run the following code chunk to load the package and load a dataset (you can either click the green arrow in the top right of the code chunk, put your cursor in the code chunk and hit Ctrl+Alt+C [on Windows/Linux] or Command+Option+C [on Mac]).\n\n# Load package\nlibrary(tidyverse)\n\n# Read in the course evaluation data\nabby &lt;- read_csv(\"https://mac-stat.github.io/data/dear_abby.csv\")\n\nIf it runs successfully, you should see the following output appear in the Console pane:\n&gt; # Load package\n&gt; library(tidyverse)\n&gt; \n&gt; # Read in the course evaluation data\n&gt; abby &lt;- read_csv(\"https://mac-stat.github.io/data/dear_abby.csv\")\nRows: 20034 Columns: 11\n── Column specification ────────────────────────────\nDelimiter: \",\"\nchr (4): day, url, title, question_only\ndbl (7): year, month, letterId, afinn_overall, a...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nClick on the Environment tab (generally in the upper right hand pane in RStudio). Then click the abby line. The abby data will pop up as a separate pane (like viewing a spreadsheet) – check it out.\nIn this tidy dataset, what is the unit of observation? That is, what is represented in each row of the dataset?\nWhat term do we use for the columns of the dataset?\nTry out each function below. Identify what each function tells you about the abby data and note this in the ???:\n\n\n# ??? [what do both numbers mean?]\ndim(abby)\n\n\n# ???\nnrow(abby)\n\n\n# ???\nncol(abby)\n\n\n# ???\nhead(abby)\n\n\n# ???\nnames(abby)\n\n\n[OPTIONAL] If you’re not sure how exactly to use a function, you can pull up a built-in help page with information about the arguments a function takes (i.e., what goes inside the parentheses), and the output it produces. To do this, click inside the Console pane, and enter ?function_name. For example, to pull up a help page for the dim() function, we can type ?dim and hit Enter. Try pulling up the help page for the read_csv() function we used to load the dataset.",
    "crumbs": [
      "02. Univariate visualization and summaries"
    ]
  },
  {
    "objectID": "activities/02_foundations_univariate.html#exercise-3-preparing-to-summarize-and-visualize-the-data",
    "href": "activities/02_foundations_univariate.html#exercise-3-preparing-to-summarize-and-visualize-the-data",
    "title": "02. Univariate visualization and summaries",
    "section": "Exercise 3: Preparing to summarize and visualize the data",
    "text": "Exercise 3: Preparing to summarize and visualize the data\nIn the next exercises, we will be exploring themes in the Dear Abby questions and the overall “mood” or sentiment of the questions. Before continuing, read the codebook for this dataset for some context about sentiment analysis, which gives us a measure of the mood/sentiment of a text.\n\nWhat sentiment variables do we have in the dataset? Are they quantitative or categorical?\nIf we were able to create a theme variable that took values like “friendship”, “marriage”, and “relationships”, would theme be quantitative or categorical?\nWhat visualizations are appropriate for looking at the distribution of a single quantitative variable? What about a single categorical variable?",
    "crumbs": [
      "02. Univariate visualization and summaries"
    ]
  },
  {
    "objectID": "activities/02_foundations_univariate.html#exercise-4-exploring-themes-in-the-letters",
    "href": "activities/02_foundations_univariate.html#exercise-4-exploring-themes-in-the-letters",
    "title": "02. Univariate visualization and summaries",
    "section": "Exercise 4: Exploring themes in the letters",
    "text": "Exercise 4: Exploring themes in the letters\nThe dplyr package provides many useful functions for managing data (like creating new variables, summarizing information). The stringr package provides tools for working with strings (text). We’ll use these packages to search for words in the questions in order to (roughly) identify themes/subjects.\nThe code below searches for words related to mothers, fathers, marriage, and money and combines them into a single theme variable.\n\nInside mutate() the line moms = ifelse(str_detect(question_only, \"mother|mama|mom\"), \"mom\", \"no mom\") creates a new variable called moms. If any of the text “mother”, “mama”, or “mom” (which covers “mommy”) is found, then the variable takes the value “mom”. Otherwise, the variable takes the value “no mom”.\nThe dads, marriage, and money variables are created similarly.\nThe themes = str_c(moms, dads, marriage, money, sep = \"|\") line takes the 4 created variables and combines the text of those variables separated with a |. For example, one value of the themes variable is “mom|no_dad|no_marriage|no_money” (which contains words about moms but not dads, marriage, or money).\n\n\nlibrary(dplyr)\nlibrary(stringr)\n\nabby &lt;- abby %&gt;% \n    mutate(\n        moms = ifelse(str_detect(question_only, \"mother|mama|mom\"), \"mom\", \"no mom\"),\n        dads = ifelse(str_detect(question_only, \"father|papa|dad\"), \"dad\", \"no dad\"),\n        marriage = ifelse(str_detect(question_only, \"marriage|marry|married\"), \"marriage\", \"no marriage\"),\n        money = ifelse(str_detect(question_only, \"money|finance\"), \"money\", \"no money\"),\n        themes = str_c(moms, dads, marriage, money, sep = \"|\")\n    )\n\n\nModify the code above however you wish to replace themes (e.g., replace “moms” with something else) or add new themes to search for. If you want to add a new subject to search for, copy and paste a line for an existing subject above the themes line, and modify the code like this:\n\nIf your subject is captured by multiple words: YOUR_SUBJECT = ifelse(str_detect(question_only, \"WORD1|WORD2|ETC\"), \"SUBJECT\", \"NO SUBJECT\"),\nIf your subject is captured by a single word: YOUR_SUBJECT = ifelse(str_detect(question_only, \"WORD\"), \"SUBJECT\", \"NO SUBJECT\"),\nTry to have no more than 6 subjects—otherwise we’ll have too many themes, which will complicate exploration.\n\nThe code below makes a barplot of the themes variable using the ggplot2 visualization package. Before making the plot, make note of what you expect the plot might look like. (This might be hard–just do your best!) Then compare to what you observe when you run the code chunk to make the plot. (Clearly defining your expectations first is good scientific practice to avoid confirmation bias.)\n\n\n# Load package\nlibrary(ggplot2)\n\n# barplot\nggplot(abby, aes(x = themes)) +\n    geom_bar() +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\nWe can follow up on the barplot with a simple numerical summary. Whereas the ggplot2 package is great for visualizations, dplyr is great for numerical summaries. The code below constructs a table of the number of questions with each theme. Make sure that these numerical summaries match up with what you saw in the barplot.\n\n\n# Construct a table of counts\nabby %&gt;% \n    count(themes)\n\n\nBefore proceeding, let’s break down the plotting code above. Run each chunk to see how the two lines of code above build up the plot in “layers”. Add comments (on the lines starting with #) to document what you notice.\n\n\n# ???\nggplot(abby, aes(x = themes))\n\n\n# ???\nggplot(abby, aes(x = themes)) +\n    geom_bar()\n\n\n# ???\nggplot(abby, aes(x = themes)) +\n    geom_bar() +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n# ???\nggplot(abby, aes(x = themes)) +\n    geom_bar() +\n    theme_classic() +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))",
    "crumbs": [
      "02. Univariate visualization and summaries"
    ]
  },
  {
    "objectID": "activities/02_foundations_univariate.html#exercise-5-exploring-sentiment",
    "href": "activities/02_foundations_univariate.html#exercise-5-exploring-sentiment",
    "title": "02. Univariate visualization and summaries",
    "section": "Exercise 5: Exploring sentiment",
    "text": "Exercise 5: Exploring sentiment\nWe’ll look at the distribution of the afinn_overall sentiment variable and associated summary statistics.\n\nThe code below creates a boxplot of this variable. In the comment, make note of how this code is simliar to the code for the barplot above. As in the previous exercise, before running the code chunk to create the plot, make note of what you expect the boxplot to look like.\n\n\n# ???\nggplot(abby, aes(x = afinn_overall)) +\n    geom_boxplot()\n\n\nChallenge: Using the code for the barplot and boxplot as a guide, try to make a histogram and a density plot of the overall average ratings.\n\nWhat information is given by the tallest bar of the histogram?\nHow would you describe the shape of the distribution?\n\n\n\n# Histogram\n\n# Density plot\n\n\nWe can compute summary statistics (numerical summaries) for a quantitative variable using the summary() function or with the summarize() function from the dplyr package. (1st Qu. and 3rd Qu. stand for first and third quartile.) After inspecting these summaries, look back to your boxplot, histogram, and density plot. Which plots show which summaries most clearly?\n\n\n# Summary statistics\n# Using summary() - convenient for computing many summaries in one command\n# Does not show the standard deviation\nsummary(abby$afinn_overall)\n\n# Using summarize() from dplyr\n# Note that we use %&gt;% to pipe the data into the summarize() function\n# We need to use na.rm = TRUE because there are missing values (NAs)\nabby %&gt;% \n    summarize(mean(afinn_overall, na.rm = TRUE), median(afinn_overall, na.rm = TRUE), sd(afinn_overall, na.rm = TRUE))\n\n\nWrite a good paragraph describing the information in the histogram (or density plot) by discussing shape, center, spread, and outliers. Incorporate the numerical summaries from part c.",
    "crumbs": [
      "02. Univariate visualization and summaries"
    ]
  },
  {
    "objectID": "activities/02_foundations_univariate.html#exercise-6-box-plots-vs.-histograms-vs.-density-plots",
    "href": "activities/02_foundations_univariate.html#exercise-6-box-plots-vs.-histograms-vs.-density-plots",
    "title": "02. Univariate visualization and summaries",
    "section": "Exercise 6: Box plots vs. histograms vs. density plots",
    "text": "Exercise 6: Box plots vs. histograms vs. density plots\nWe took 3 different approaches to plotting the quantitative average course variable above. They all have pros and cons.\n\nWhat is one pro about the boxplot in comparison to the histogram and density plot?\nWhat is one con about the boxplot in comparison to the histogram and density plots?\nIn this example, which plot do you prefer and why?",
    "crumbs": [
      "02. Univariate visualization and summaries"
    ]
  },
  {
    "objectID": "activities/02_foundations_univariate.html#exercise-7-explore-outliers",
    "href": "activities/02_foundations_univariate.html#exercise-7-explore-outliers",
    "title": "02. Univariate visualization and summaries",
    "section": "Exercise 7: Explore outliers",
    "text": "Exercise 7: Explore outliers\nGiven that Dear Abby column is an advice column, it seems natural that the sentiment of the questions would lean more negative. What’s going on with the questions that have particularly positive sentiments?\nWe can use the filter() function in the dplyr package to look at the . Based on the plots of afinn_overall that you made in Exercise 5, pick a threshold for the afinn_overall variable—we’ll say that questions with an overall sentiment score above this threshold are high outliers. Fill in this number where it says YOUR_THRESHOLD below.\n\nabby %&gt;% \n    filter(afinn_overall &gt; YOUR_THRESHOLD) %&gt;% \n    pull(question_only)\n\nWhat do you notice? Why might these questions have such high sentiment scores?",
    "crumbs": [
      "02. Univariate visualization and summaries"
    ]
  },
  {
    "objectID": "activities/02_foundations_univariate.html#exercise-8-returning-to-our-context-looking-ahead",
    "href": "activities/02_foundations_univariate.html#exercise-8-returning-to-our-context-looking-ahead",
    "title": "02. Univariate visualization and summaries",
    "section": "Exercise 8: Returning to our context, looking ahead",
    "text": "Exercise 8: Returning to our context, looking ahead\nIn this activity, we explored data on Dear Abby question, with a focus on exploring a single variable at a time.\n\nIn big picture terms, what have we learned about Dear Abby questions?\nWhat further curiosities do you have about the data?",
    "crumbs": [
      "02. Univariate visualization and summaries"
    ]
  },
  {
    "objectID": "activities/02_foundations_univariate.html#exercise-9-different-ways-to-think-about-data-visualization",
    "href": "activities/02_foundations_univariate.html#exercise-9-different-ways-to-think-about-data-visualization",
    "title": "02. Univariate visualization and summaries",
    "section": "Exercise 9: Different ways to think about data visualization",
    "text": "Exercise 9: Different ways to think about data visualization\nIn working with and visualizing data, it’s important to keep in mind what a data point represents. It can reflect the experience of a real person. It might reflect the sentiment in a piece of art. It might reflect history. We’ve taken one very narrow and technical approach to data visualization. Check out the following examples, and write some notes about anything you find interesting.\n\nDear Data\nW.E.B. DuBois\nDecolonizing Data Viz\nPhase Change Project (by Prof Kim, Mac research students)",
    "crumbs": [
      "02. Univariate visualization and summaries"
    ]
  },
  {
    "objectID": "activities/02_foundations_univariate.html#exercise-10-rendering-your-work",
    "href": "activities/02_foundations_univariate.html#exercise-10-rendering-your-work",
    "title": "02. Univariate visualization and summaries",
    "section": "Exercise 10: Rendering your work",
    "text": "Exercise 10: Rendering your work\nSave this file, and then click the “Render” button in the menu bar for this pane (blue arrow pointing right). This will create an HTML file containing all of the directions, code, and responses from this activity. A preview of the HTML will appear in the browser.\n\nScroll through and inspect the document to see how your work was translated into this HTML format. Neat!\nClose the browser tab.\nGo to the “Background Jobs” pane in RStudio and click the Stop button to end the rendering process.\nNavigate to your “Activities” subfolder within your “STAT155” folder and locate the HTML file. You can open it again in your browser to double check.",
    "crumbs": [
      "02. Univariate visualization and summaries"
    ]
  },
  {
    "objectID": "activities/02_foundations_univariate.html#reflection",
    "href": "activities/02_foundations_univariate.html#reflection",
    "title": "02. Univariate visualization and summaries",
    "section": "Reflection",
    "text": "Reflection\nGo to the top of this file and review the learning objectives for this lesson. Which objectives do you have a good handle on, are at least familiar with, or are struggling with? What feels challenging right now? What are some wins from the day?\n\nResponse: Put your response here.",
    "crumbs": [
      "02. Univariate visualization and summaries"
    ]
  },
  {
    "objectID": "activities/02_foundations_univariate.html#exercise-11-read-in-and-get-to-know-the-weather-data",
    "href": "activities/02_foundations_univariate.html#exercise-11-read-in-and-get-to-know-the-weather-data",
    "title": "02. Univariate visualization and summaries",
    "section": "Exercise 11: Read in and get to know the weather data",
    "text": "Exercise 11: Read in and get to know the weather data\nDaily weather data are available for 3 locations in Perth, Australia.\n\nView the codebook here.\nComplete the code below to read in the data.\n\n\n# Replace the ??? with your own name for the weather data\n# Replace the ___ with the correct function\n??? &lt;- ___(\"https://mac-stat.github.io/data/weather_3_locations.csv\")",
    "crumbs": [
      "02. Univariate visualization and summaries"
    ]
  },
  {
    "objectID": "activities/02_foundations_univariate.html#exercise-12-exploring-the-data-structure",
    "href": "activities/02_foundations_univariate.html#exercise-12-exploring-the-data-structure",
    "title": "02. Univariate visualization and summaries",
    "section": "Exercise 12: Exploring the data structure",
    "text": "Exercise 12: Exploring the data structure\nCheck out the basic features of the weather data.\n\n# Examine the first six cases\n\n# Find the dimensions of the data\n\nWhat does a case represent in this data?",
    "crumbs": [
      "02. Univariate visualization and summaries"
    ]
  },
  {
    "objectID": "activities/02_foundations_univariate.html#exercise-13-exploring-rainfall",
    "href": "activities/02_foundations_univariate.html#exercise-13-exploring-rainfall",
    "title": "02. Univariate visualization and summaries",
    "section": "Exercise 13: Exploring rainfall",
    "text": "Exercise 13: Exploring rainfall\nThe raintoday variable contains information about rainfall.\n\nIs this variable quantitative or categorical?\nCreate an appropriate visualization, and compute appropriate numerical summaries.\nWhat do you learn about rainfall in Perth?\n\n\n# Visualization\n\n# Numerical summaries",
    "crumbs": [
      "02. Univariate visualization and summaries"
    ]
  },
  {
    "objectID": "activities/02_foundations_univariate.html#exercise-14-exploring-temperature",
    "href": "activities/02_foundations_univariate.html#exercise-14-exploring-temperature",
    "title": "02. Univariate visualization and summaries",
    "section": "Exercise 14: Exploring temperature",
    "text": "Exercise 14: Exploring temperature\nThe maxtemp variable contains information on the daily high temperature.\n\nIs this variable quantitative or categorical?\nCreate an appropriate visualization, and compute appropriate numerical summaries.\nWhat do you learn about high temperatures in Perth?\n\n\n# Visualization\n\n# Numerical summaries",
    "crumbs": [
      "02. Univariate visualization and summaries"
    ]
  },
  {
    "objectID": "activities/02_foundations_univariate.html#exercise-15-customizing-challenge",
    "href": "activities/02_foundations_univariate.html#exercise-15-customizing-challenge",
    "title": "02. Univariate visualization and summaries",
    "section": "Exercise 15: Customizing! (CHALLENGE)",
    "text": "Exercise 15: Customizing! (CHALLENGE)\nThough you will naturally absorb some RStudio code throughout the semester, being an effective statistical thinker and “programmer” does not require that we memorize all code. That would be impossible! In contrast, using the foundation you built today, do some digging online to learn how to customize your visualizations.\n\nFor the histogram below, add a title and more meaningful axis labels. Specifically, title the plot “Distribution of max temperatures in Perth”, change the x-axis label to “Maximum temperature” and y-axis label to “Number of days”. HINT: Do a Google search for something like “add axis labels ggplot”.\n\n\n# Add a title and axis labels\nggplot(weather, aes(x = maxtemp)) + \n    geom_histogram()\n\n\nAdjust the code below in order to color the bars green. NOTE: Color can be an effective tool, but here it is simply gratuitous.\n\n\n# Make the bars green\nggplot(weather, aes(x = raintoday)) + \n    geom_bar()\n\n\nCheck out the ggplot2 cheat sheet. Try making some of the other kinds of univariate plots outlined there.\nWhat else would you like to change about your plot? Try it!\n\n\nSolutions",
    "crumbs": [
      "02. Univariate visualization and summaries"
    ]
  },
  {
    "objectID": "solutions/02_foundations_univariate.html",
    "href": "solutions/02_foundations_univariate.html",
    "title": "Solutions for 02. Univariate visualization and summaries",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nDescribe what a case (or unit of analysis) represents in a dataset.\nDescribe what a variable represents in a dataset.\nIdentify whether a variable is categorical or quantitative and what summarizations and visualizations are appropriate for that variable\nWrite R code to read in data and to summarize and visualize a single variable at a time.\nInterpret key features of barplots, boxplots, histograms, and density plots\nDescribe information about the distribution of a quantitative variable using the concepts of shape, center, spread, and outliers\nRelate summary statistics of data to the concepts of shape, center, spread, and outliers\n\n\n\n\nChoose either the reading or the videos to go through before class.\n\nReading: Sections 2.1-2.4, 2.6 in the STAT 155 Notes\nVideos:\n\nUnivariate visualization and summarization (slides)\nR Code for Categorical Visualization and Summarization\nR Code for Quantitative Visualization and Summarization\n\n\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder."
  },
  {
    "objectID": "solutions/02_foundations_univariate.html#learning-goals",
    "href": "solutions/02_foundations_univariate.html#learning-goals",
    "title": "Solutions for 02. Univariate visualization and summaries",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nDescribe what a case (or unit of analysis) represents in a dataset.\nDescribe what a variable represents in a dataset.\nIdentify whether a variable is categorical or quantitative and what summarizations and visualizations are appropriate for that variable\nWrite R code to read in data and to summarize and visualize a single variable at a time.\nInterpret key features of barplots, boxplots, histograms, and density plots\nDescribe information about the distribution of a quantitative variable using the concepts of shape, center, spread, and outliers\nRelate summary statistics of data to the concepts of shape, center, spread, and outliers"
  },
  {
    "objectID": "solutions/02_foundations_univariate.html#readings-and-videos",
    "href": "solutions/02_foundations_univariate.html#readings-and-videos",
    "title": "Solutions for 02. Univariate visualization and summaries",
    "section": "",
    "text": "Choose either the reading or the videos to go through before class.\n\nReading: Sections 2.1-2.4, 2.6 in the STAT 155 Notes\nVideos:\n\nUnivariate visualization and summarization (slides)\nR Code for Categorical Visualization and Summarization\nR Code for Quantitative Visualization and Summarization\n\n\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder."
  },
  {
    "objectID": "solutions/02_foundations_univariate.html#exercise-1-get-curious",
    "href": "solutions/02_foundations_univariate.html#exercise-1-get-curious",
    "title": "Solutions for 02. Univariate visualization and summaries",
    "section": "Exercise 1: Get curious",
    "text": "Exercise 1: Get curious\n\nHypothesize with each other: what themes do you think might come up often in Dear Abby letters?\nAfter brainstorming, take a quick glance at the original article from The Pudding to see what themes they explored.\nGo to the very end of the Pudding article to the section titled “Data and Method”. In thinking about the who, what, when, where, why, and how of data context, what concerns/limitations surface with regards to using this data to learn about Americans’ concerns over the decades?"
  },
  {
    "objectID": "solutions/02_foundations_univariate.html#exercise-2-importing-and-getting-to-know-the-data",
    "href": "solutions/02_foundations_univariate.html#exercise-2-importing-and-getting-to-know-the-data",
    "title": "Solutions for 02. Univariate visualization and summaries",
    "section": "Exercise 2: Importing and getting to know the data",
    "text": "Exercise 2: Importing and getting to know the data\nFirst, in the Console pane of RStudio, run the following command to install some necessary packages (you will need to do this any time you are installing a new package):\ninstall.packages(\"tidyverse\")\nNow, in the Quarto pane, run the following code chunk to load the package and load a dataset (you can either click the green arrow in the top right of the code chunk, put your cursor in the code chunk and hit Ctrl+Alt+C [on Windows/Linux] or Command+Option+C [on Mac]).\n\n# Load package\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Read in the course evaluation data\nabby &lt;- read_csv(\"https://mac-stat.github.io/data/dear_abby.csv\")\n\nRows: 20034 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): day, url, title, question_only\ndbl (7): year, month, letterId, afinn_overall, afinn_pos, afinn_neg, bing_pos\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "solutions/02_foundations_univariate.html#exercise-1-get-curious-1",
    "href": "solutions/02_foundations_univariate.html#exercise-1-get-curious-1",
    "title": "Solutions for 02. Univariate visualization and summaries",
    "section": "Exercise 1: Get curious",
    "text": "Exercise 1: Get curious\n\nResults of brainstorming themes will vary\nFrom the “Data and Method” section at the end of the Pudding article, we see this paragraph:\n\n\nThe writers of these questions likely skew roughly 2/3 female (according to Pauline Phillips, who mentions the demographics of responses to a survey she disseminated in 1987), and consequently, their interests are overrepresented; we’ve been unable to find other demographic data surrounding their origins. There is, doubtless, a level of editorializing here: only a fraction of the questions that people have written in have seen publication, because agony aunts (the writers of advice columns) must selectively filter what gets published. Nevertheless, the concerns of the day seem to be represented, such as the HIV/AIDS crisis in the 1980s. Additionally, we believe that the large sample of questions in our corpus (20,000+) that have appeared over recent decades gives a sufficient directional sense of broad trends.\n\n\nWriters of the questions are predominately female. The 2/3 proportion was estimated in 1987, so it would be useful to understand shifts in demographics over time.\nWhat questions were chosen to be answered on the column? Likely a small fraction of what got submitted. What themes tended to get cut out?"
  },
  {
    "objectID": "solutions/02_foundations_univariate.html#exercise-2-importing-and-getting-to-know-the-data-1",
    "href": "solutions/02_foundations_univariate.html#exercise-2-importing-and-getting-to-know-the-data-1",
    "title": "Solutions for 02. Univariate visualization and summaries",
    "section": "Exercise 2: Importing and getting to know the data",
    "text": "Exercise 2: Importing and getting to know the data\n\nNote how clicking the abby data causes both a popup pane and the command View(abby) to appear in the Console. In fact, the View() function is the underlying command that opens a dataset pane. (View() should always be entered in the Console and NOT your Quarto document.)\nEach row / case corresponds to a single question.\nColumns = variables\nTry out each function below. Identify what each function tells you about the abby data and note this in the ???:\n\n\n# First number = number of rows / cases\n# Second number = number of columns / variables\ndim(abby)\n\n[1] 20034    11\n\n# Number of rows (cases)\nnrow(abby)\n\n[1] 20034\n\n# Number of columns (variables)\nncol(abby)\n\n[1] 11\n\n# View first few rows of the dataset (6 rows, by default)\nhead(abby)\n\n# A tibble: 6 × 11\n   year month day   url     title letterId question_only afinn_overall afinn_pos\n  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;                 &lt;dbl&gt;     &lt;dbl&gt;\n1  1985     1 01    proque… WOMA…        1 \"i have been…           -30         5\n2  1985     1 01    proque… WOMA…        1 \"this is for…           -30         5\n3  1985     1 02    proque… LAME…        1 \"our 16-year…             1         3\n4  1985     1 03    proque… 'NOR…        1 \"i was a hap…            -3         7\n5  1985     1 04    proque… IT'S…        1 \"you be the …            13        31\n6  1985     1 04    proque… IT'S…        1 \"a further w…            13        31\n# ℹ 2 more variables: afinn_neg &lt;dbl&gt;, bing_pos &lt;dbl&gt;\n\n# Get all column (variable) names\nnames(abby)\n\n [1] \"year\"          \"month\"         \"day\"           \"url\"          \n [5] \"title\"         \"letterId\"      \"question_only\" \"afinn_overall\"\n [9] \"afinn_pos\"     \"afinn_neg\"     \"bing_pos\"     \n\n\n\nWe can display the first 10 rows with head(abby, n = 10)."
  },
  {
    "objectID": "solutions/02_foundations_univariate.html#exercise-3-preparing-to-summarize-and-visualize-the-data",
    "href": "solutions/02_foundations_univariate.html#exercise-3-preparing-to-summarize-and-visualize-the-data",
    "title": "Solutions for 02. Univariate visualization and summaries",
    "section": "Exercise 3: Preparing to summarize and visualize the data",
    "text": "Exercise 3: Preparing to summarize and visualize the data\n\nThe sentiment variables are afinn_overall, afinn_pos, afinn_neg, and bing_pos, and they are quantitative. The afinn variables don’t have units but we can still get a sense of the scale by remembering that each word gets a score between -5 and 5. The bing_pos variable doesn’t have units because it’s a fraction, but we know that it ranges from 0 to 1.\ntheme would be categorical.\nAppropriate visualizations:\n\nsingle quantitative variable: boxplot, histogram, density plot\nsingle categorical variable: barplot"
  },
  {
    "objectID": "solutions/02_foundations_univariate.html#exercise-4-exploring-themes-in-the-letters",
    "href": "solutions/02_foundations_univariate.html#exercise-4-exploring-themes-in-the-letters",
    "title": "Solutions for 02. Univariate visualization and summaries",
    "section": "Exercise 4: Exploring themes in the letters",
    "text": "Exercise 4: Exploring themes in the letters\n\nlibrary(dplyr)\nlibrary(stringr)\n\nabby &lt;- abby %&gt;% \n    mutate(\n        moms = ifelse(str_detect(question_only, \"mother|mama|mom\"), \"mom\", \"no mom\"),\n        dads = ifelse(str_detect(question_only, \"father|papa|dad\"), \"dad\", \"no dad\"),\n        marriage = ifelse(str_detect(question_only, \"marriage|marry|married\"), \"marriage\", \"no marriage\"),\n        money = ifelse(str_detect(question_only, \"money|finance\"), \"money\", \"no money\"),\n        themes = str_c(moms, dads, marriage, money, sep = \"|\")\n    )\n\n\nCode will vary\nExpectations about the plot will vary\n\n\nggplot(abby, aes(x = themes)) +\n    geom_bar() +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n\n\n\n\n\n\n\nCounts in the table below match the barplot\n\n\n# Construct a table of counts\nabby %&gt;% \n    count(themes)\n\n# A tibble: 16 × 2\n   themes                                 n\n   &lt;chr&gt;                              &lt;int&gt;\n 1 mom|dad|marriage|money                67\n 2 mom|dad|marriage|no money            567\n 3 mom|dad|no marriage|money            109\n 4 mom|dad|no marriage|no money         906\n 5 mom|no dad|marriage|money            121\n 6 mom|no dad|marriage|no money         839\n 7 mom|no dad|no marriage|money         293\n 8 mom|no dad|no marriage|no money     2462\n 9 no mom|dad|marriage|money             41\n10 no mom|dad|marriage|no money         350\n11 no mom|dad|no marriage|money          96\n12 no mom|dad|no marriage|no money      760\n13 no mom|no dad|marriage|money         360\n14 no mom|no dad|marriage|no money     2967\n15 no mom|no dad|no marriage|money      865\n16 no mom|no dad|no marriage|no money  9231\n\n\n\nWhat do the plot layers do?\n\n\n# Just sets up the \"canvas\" of the plot with axis labels\nggplot(abby, aes(x = themes))\n\n\n\n\n\n\n\n\n\n# Adds the bars\nggplot(abby, aes(x = themes)) +\n    geom_bar()\n\n\n\n\n\n\n\n\n\n# Rotates the x axis labels\nggplot(abby, aes(x = themes)) +\n    geom_bar() +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n\n\n\n\n\n\n\n# Changes the visual theme of the plot with a white background and removes gridlines\nggplot(abby, aes(x = themes)) +\n    geom_bar() +\n    theme_classic() +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))"
  },
  {
    "objectID": "solutions/02_foundations_univariate.html#exercise-5-exploring-course-overall-ratings",
    "href": "solutions/02_foundations_univariate.html#exercise-5-exploring-course-overall-ratings",
    "title": "Solutions for 02. Univariate visualization and summaries",
    "section": "Exercise 5: Exploring course overall ratings",
    "text": "Exercise 5: Exploring course overall ratings\nNow we’ll look at the distribution of the avg_rating variable and associated summary statistics.\n\n\nWe might expect the mean of this variable is less than zero given that more negative words might be appear in questions on an advice column.\nThe code has a similar structure to the barplot in that there is an initial ggplot() layer which sets the canvas, then a + to add a layer, then the final layer geom_boxplot() (like geom_bar()) which tells R what type of plot to make.\n\n\n\nggplot(abby, aes(x = afinn_overall)) +\n    geom_boxplot()\n\nWarning: Removed 490 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\n\nWe replace geom_boxplot() with geom_histogram() and geom_density().\n\nThe tallest bar of the histogram indicates that over 7500 questions had an overall afinn sentiment score between around -8 to 0.(The -8 to 0 comes from eyeballing where the tallest bar is placed on the x-axis, and the height of this bar indicates how many cases fall into that bin.)\nThe shape of the distribution: roughly symmetric\n\n\n\n# Histogram\nggplot(abby, aes(x = afinn_overall)) +\n    geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 490 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n# Density plot\nggplot(abby, aes(x = afinn_overall)) +\n    geom_density()\n\nWarning: Removed 490 rows containing non-finite outside the scale range\n(`stat_density()`).\n\n\n\n\n\n\n\n\n\n\n\nBoxplot shows min, max, median, 1st and 3rd quartile easily. (It shows median, 1st and 3rd quartile directly as lines)\nHistogram and density plot show min and max but the mean and median aren’t shown directly–we have to roughly guess based on the peak of the distribution\n\n\n\n# Summary statistics\nsummary(abby$afinn_overall)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max.     NA's \n-140.000   -6.000   -1.000   -1.401    3.000  100.000      490 \n\nabby %&gt;% \n    summarize(mean(afinn_overall, na.rm = TRUE), median(afinn_overall, na.rm = TRUE), sd(afinn_overall, na.rm = TRUE))\n\n# A tibble: 1 × 3\n  mean(afinn_overall, na.rm = TR…¹ median(afinn_overall…² sd(afinn_overall, na…³\n                             &lt;dbl&gt;                  &lt;dbl&gt;                  &lt;dbl&gt;\n1                            -1.40                     -1                   11.1\n# ℹ abbreviated names: ¹​`mean(afinn_overall, na.rm = TRUE)`,\n#   ²​`median(afinn_overall, na.rm = TRUE)`, ³​`sd(afinn_overall, na.rm = TRUE)`\n\n\n\nThe distribution of sentiment scores is roughly symmetric with a mean of -1.4 and a similar median of -1. The median and mean are quite similar because the distribution is fairly symmetric. The standard deviation of the sentiment scores is about 11.08 which tells us how much variation there is from the center of the distribution. 11.08 is somewhat high given the IQR of -6 to 3 (which is a span of 9 units)."
  },
  {
    "objectID": "solutions/02_foundations_univariate.html#exercise-6-box-plots-vs.-histograms-vs.-density-plots",
    "href": "solutions/02_foundations_univariate.html#exercise-6-box-plots-vs.-histograms-vs.-density-plots",
    "title": "Solutions for 02. Univariate visualization and summaries",
    "section": "Exercise 6: Box plots vs. histograms vs. density plots",
    "text": "Exercise 6: Box plots vs. histograms vs. density plots\n\nBoxplots very clearly show key summary statistics like median, 1st and 3rd quartile\nBoxplots can oversimplify by not showing the shape of the distribution."
  },
  {
    "objectID": "solutions/02_foundations_univariate.html#exercise-7-explore-outliers",
    "href": "solutions/02_foundations_univariate.html#exercise-7-explore-outliers",
    "title": "Solutions for 02. Univariate visualization and summaries",
    "section": "Exercise 7: Explore outliers",
    "text": "Exercise 7: Explore outliers\nThere are some positive words in the questions that seem to pull up the sentiment score a lot despite the negative overall tone. From this we can see the limitations of a basic sentiment analysis in which the sentiment of each word is considered in isolation.\n\nabby %&gt;% \n    filter(afinn_overall &gt; 50) %&gt;% \n    pull(question_only) %&gt;% \n    head() # Just to look at first 6\n\n[1] \"i am a 36-year-old college dropout whose lifelong ambition was to be a physician. i have a very good job selling pharmaceutical supplies, but my heart is still in the practice of medicine. i do volunteer work at the local hospital on my time off, and people tell me i would have made a wonderful doctor.\\nif i go back to college and get my degree, then go to medical school, do my internship and finally get into the actual practice of medicine, it will take me seven years! but, abby, in seven years i will be 43 years old. what do you think?\\nunfulfilled in philly\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n[2] \"we have an only child--a grown daughter we dearly love--and when we pass on, we want to leave her our entire estate, which is considerable.\\nthe thing that troubles us is this: our daughter is married to a very unworthy character. for years he has taken advantage of her sweet, forgiving, generous nature because he knows she worships him. we are sure that whatever we leave our daughter will be spent on this dirty dog.\\nhow can we prevent this from happening?\\nbewildered\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n[3] \"both of our sons have been married for about 15 years. their wives were of normal weight when they married our sons, but one daughter-in- law weighs about 300 pounds and the other weighs about 225. their ages are 35 and 37. both our sons are good-looking, and neither is fat.\\nour daughters-in-law seem to have no pride in their appearance, which upsets everyone in the family, except themselves. they are fat, they know it and they don't care! when they first began to put on weight, they tried various diets, pills, doctors, etc., but they both gave up and decided to \\\"accept\\\" themselves as they are.\\nthey wear the wrong kind of clothes (shorts and blue jeans) without any apologies.\\nour problem (my husband's and mine) is how do we cope with this? we are ashamed to be around them. our sons have accepted the situation, but we seem unable to.\\nperhaps we need more help than the girls. any suggestions?\\nupset in florida\"                                                                                                                                                                                                                                                                                                                                                                                                                                           \n[4] \"the letter from \\\"concerned mom,\\\" who was trying to teach her 5-year-old not to accept gifts from strangers, prompts this letter.\\na gentleman friend of mine recently stood in line behind a mother and her young daughter at a bank. the child remarked on the visor he was wearing, as it had the name of a popular pizza imprinted on it.\\nmy friend, who is the public relations director for this pizza firm, wanted the child to have the visor but, instead of giving it to the child, he handed the visor to her mother and said to the child: \\\"i'm giving this to your mother to give to you, because she's probably told you never to accept gifts from a stranger. you won't ever do that, will you?\\\"\\nwhat a thoughtful way to be friendly while reinforcing a message mothers cannot stress enough.\\nsue in wichita, kan.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n[5] \"in january, i sent an original manuscript as a gift to woody allen. i had hand-bound the pages, and decorated the binding with baroque pearls and amethyst. i enclosed my name, address and telephone number. i had hoped that woody would send me a note or call me, or at the very least, instruct his secretary to do so.\\nto date, i haven't received even an acknowledgment that my gift was received. is it unrealistic of me to expect a thank-you from a famous person?\\ndisappointed in california.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n[6] \"will you please, please discourage high school and college graduates from sending graduation invitations to every distant relative they and their parents ever heard of? we all know that sending \\\"invitations\\\" to people we hardly know is a flagrant, shameless bid for a gift. and if, in a moment of weakness, one does send a gift, a barrage of birth announcements and invitations to weddings, showers and more graduations is sure to follow.\\ni am a 75-year-old widow, living on social security and very little else. i just received a high school graduation invitation from the granddaughter of a third cousin whom i have not seen in so long i wouldn't even recognize her. (i have never even met her granddaughter.)\\ni have many relatives in this town, but i never hear from them unless they are celebrating something that requires a gift. i have no car, yet they \\\"invite\\\" me to every imaginable event, knowing full well i can't possibly attend. this is just shameless begging.\\ni am not cheap. i just sent a generous graduation gift to a neighbor girl who used to stop by every day to bring in my mail and newspaper and ask if i needed any errands run.\\ndon't suggest that i send \\\"a nice card\\\" to the relatives who send me invitations to events they know i can't attend. we both know a card is not what these spongers want.\\nsick of them in iowa city\""
  },
  {
    "objectID": "solutions/02_foundations_univariate.html#exercise-8-returning-to-our-context-looking-ahead",
    "href": "solutions/02_foundations_univariate.html#exercise-8-returning-to-our-context-looking-ahead",
    "title": "Solutions for 02. Univariate visualization and summaries",
    "section": "Exercise 8: Returning to our context, looking ahead",
    "text": "Exercise 8: Returning to our context, looking ahead\n\nAnswers will vary"
  },
  {
    "objectID": "solutions/02_foundations_univariate.html#exercise-11-read-in-and-get-to-know-the-weather-data",
    "href": "solutions/02_foundations_univariate.html#exercise-11-read-in-and-get-to-know-the-weather-data",
    "title": "Solutions for 02. Univariate visualization and summaries",
    "section": "Exercise 11: Read in and get to know the weather data",
    "text": "Exercise 11: Read in and get to know the weather data\n\nweather &lt;- read_csv(\"https://raw.githubusercontent.com/Mac-STAT/data/main/weather_3_locations.csv\")\n\nRows: 2367 Columns: 24\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (6): location, windgustdir, winddir9am, winddir3pm, raintoday, raintom...\ndbl  (17): mintemp, maxtemp, rainfall, evaporation, sunshine, windgustspeed,...\ndate  (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "solutions/02_foundations_univariate.html#exercise-12-exploring-the-data-structure",
    "href": "solutions/02_foundations_univariate.html#exercise-12-exploring-the-data-structure",
    "title": "Solutions for 02. Univariate visualization and summaries",
    "section": "Exercise 12: Exploring the data structure",
    "text": "Exercise 12: Exploring the data structure\nCheck out the basic features of the weather data.\n\n# Examine the first six cases\nhead(weather)\n\n# A tibble: 6 × 24\n  date       location  mintemp maxtemp rainfall evaporation sunshine windgustdir\n  &lt;date&gt;     &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;      \n1 2020-01-01 Wollongo…    17.1    23.1        0          NA       NA SSW        \n2 2020-01-02 Wollongo…    17.7    24.2        0          NA       NA SSW        \n3 2020-01-03 Wollongo…    19.7    26.8        0          NA       NA NE         \n4 2020-01-04 Wollongo…    20.4    35.5        0          NA       NA SSW        \n5 2020-01-05 Wollongo…    19.8    21.4        0          NA       NA SSW        \n6 2020-01-06 Wollongo…    18.3    22.9        0          NA       NA NE         \n# ℹ 16 more variables: windgustspeed &lt;dbl&gt;, winddir9am &lt;chr&gt;, winddir3pm &lt;chr&gt;,\n#   windspeed9am &lt;dbl&gt;, windspeed3pm &lt;dbl&gt;, humidity9am &lt;dbl&gt;,\n#   humidity3pm &lt;dbl&gt;, pressure9am &lt;dbl&gt;, pressure3pm &lt;dbl&gt;, cloud9am &lt;dbl&gt;,\n#   cloud3pm &lt;dbl&gt;, temp9am &lt;dbl&gt;, temp3pm &lt;dbl&gt;, raintoday &lt;chr&gt;,\n#   risk_mm &lt;dbl&gt;, raintomorrow &lt;chr&gt;\n\n# Find the dimensions of the data\ndim(weather)\n\n[1] 2367   24\n\n\nA case represents a day of the year in a particular area (Hobart, Uluru, Wollongong as seen by the location variable)."
  },
  {
    "objectID": "solutions/02_foundations_univariate.html#exercise-13-exploring-rainfall",
    "href": "solutions/02_foundations_univariate.html#exercise-13-exploring-rainfall",
    "title": "Solutions for 02. Univariate visualization and summaries",
    "section": "Exercise 13: Exploring rainfall",
    "text": "Exercise 13: Exploring rainfall\nThe raintoday variable contains information about rainfall.\n\nraintoday is categorical (No, Yes)\nIt is more common to have no rain.\n\n\n# Visualization\nggplot(weather, aes(x = raintoday)) +\n    geom_bar()\n\n\n\n\n\n\n\n# Numerical summaries\nweather %&gt;% \n    count(raintoday)\n\n# A tibble: 3 × 2\n  raintoday     n\n  &lt;chr&gt;     &lt;int&gt;\n1 No         1864\n2 Yes         446\n3 &lt;NA&gt;         57"
  },
  {
    "objectID": "solutions/02_foundations_univariate.html#exercise-14-exploring-temperature",
    "href": "solutions/02_foundations_univariate.html#exercise-14-exploring-temperature",
    "title": "Solutions for 02. Univariate visualization and summaries",
    "section": "Exercise 14: Exploring temperature",
    "text": "Exercise 14: Exploring temperature\nThe maxtemp variable contains information on the daily high temperature.\n\nmaxtemp is quantitative\nThe typical max temperature is around 23 degrees Celsius (with an average of 23.62 and a median of 22 degrees). The max temperatures ranged from 8.6 to 45.4 degrees. Finally, on the typical day, the max temp falls about 7.8 degrees from the mean. There are multiple modes in the distribution of max temperature—this likely reflects the different cities in the dataset.\n\n\n# Visualization\nggplot(weather, aes(x = maxtemp)) + \n    geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 34 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n# Numerical summaries\nsummary(weather$maxtemp)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   8.60   18.10   22.00   23.62   27.40   45.40      34 \n\n# There are missing values (NAs) in this variable, so we add\n# the na.rm = TRUE argument\nweather %&gt;% \n    summarize(sd(maxtemp, na.rm = TRUE))\n\n# A tibble: 1 × 1\n  `sd(maxtemp, na.rm = TRUE)`\n                        &lt;dbl&gt;\n1                        7.80"
  },
  {
    "objectID": "solutions/02_foundations_univariate.html#exercise-15-customizing-challenge",
    "href": "solutions/02_foundations_univariate.html#exercise-15-customizing-challenge",
    "title": "Solutions for 02. Univariate visualization and summaries",
    "section": "Exercise 15: Customizing! (CHALLENGE)",
    "text": "Exercise 15: Customizing! (CHALLENGE)\n\n\n\n\nggplot(weather, aes(x = maxtemp)) + \n    geom_histogram() + \n    labs(x = \"Maximum temperature\", y = \"Number of days\", title = \"Distribution of max temperatures in Perth\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 34 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Make the bars green\nggplot(weather, aes(x = raintoday)) + \n    geom_bar(fill = \"green\")"
  },
  {
    "objectID": "activities/07_slr_cat_predictor.html",
    "href": "activities/07_slr_cat_predictor.html",
    "title": "07. Simple linear regression: categorical predictor",
    "section": "",
    "text": "Download the .qmd file for this activity here.",
    "crumbs": [
      "07. Simple linear regression: categorical predictor"
    ]
  },
  {
    "objectID": "activities/07_slr_cat_predictor.html#learning-goals",
    "href": "activities/07_slr_cat_predictor.html#learning-goals",
    "title": "07. Simple linear regression: categorical predictor",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of this lesson, you should be able to:\n\nWrite a model formula for a simple linear regression model with a categorical predictor using indicator variables\nInterpret the intercept and slope coefficients in a simple linear regression model with a categorical predictor",
    "crumbs": [
      "07. Simple linear regression: categorical predictor"
    ]
  },
  {
    "objectID": "activities/07_slr_cat_predictor.html#readings-and-videos",
    "href": "activities/07_slr_cat_predictor.html#readings-and-videos",
    "title": "07. Simple linear regression: categorical predictor",
    "section": "Readings and videos",
    "text": "Readings and videos\nComplete both the reading and the videos to go through before class.\n\nReading: Section 3.9 in the STAT 155 Notes only up through section 3.9.1 Indicator Variables\nVideos:\n\nSimple linear regression: categorical predictor (slides)\nR Code for Categorical Predictors\n\n\n\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder.",
    "crumbs": [
      "07. Simple linear regression: categorical predictor"
    ]
  },
  {
    "objectID": "activities/07_slr_cat_predictor.html#exercise-1-get-to-know-the-data",
    "href": "activities/07_slr_cat_predictor.html#exercise-1-get-to-know-the-data",
    "title": "07. Simple linear regression: categorical predictor",
    "section": "Exercise 1: Get to know the data",
    "text": "Exercise 1: Get to know the data\nWrite R code to answer the following:\n\nHow many cases and variables do we have? What does a case represent?\nWhat do the first few rows of the data look like?\nConstruct and interpret two different visualizations of the price variable.\nConstruct and interpret a visualization of the cut variable.",
    "crumbs": [
      "07. Simple linear regression: categorical predictor"
    ]
  },
  {
    "objectID": "activities/07_slr_cat_predictor.html#exercise-2-visualizations",
    "href": "activities/07_slr_cat_predictor.html#exercise-2-visualizations",
    "title": "07. Simple linear regression: categorical predictor",
    "section": "Exercise 2: Visualizations",
    "text": "Exercise 2: Visualizations\nStart by visualizing this relationship of interest, that between price and cut.\n\nThe appropriate plot depends upon the type of variables we’re plotting. When exploring the relationship between a quantitative response (ridership) and a quantitative predictor (temperature), a scatterplot was an effective choice. After running the code below, explain why a scatterplot is not effective for exploring the relationship between ridership and our categorical cut predictor.\n\n\n# Try a scatterplot\nggplot(diamonds, aes(y = price, x = cut)) + \n    geom_point()\n\n\nSeparately run each chunk below, with two plots. Comment (#) on what changes in the code / output.\n\n\n# Univariate boxplot\nggplot(diamonds, aes(y = price)) + \n    geom_boxplot()\n\n\n# ???\nggplot(diamonds, aes(y = price, x = cut)) + \n    geom_boxplot()\n\n\n# Univariate density plot\nggplot(diamonds, aes(x = price)) + \n    geom_density()\n\n\n# ???\nggplot(diamonds, aes(x = price, color = cut)) + \n    geom_density()\n\n\n# Univariate histogram\nggplot(diamonds, aes(x = price)) + \n    geom_histogram()\n\n\n# ???\nggplot(diamonds, aes(x = price)) + \n    geom_histogram() + \n    facet_wrap(~ cut)\n\n\nDo you notice anything interesting about the relationship between price and cut? What do you think might be happening here?",
    "crumbs": [
      "07. Simple linear regression: categorical predictor"
    ]
  },
  {
    "objectID": "activities/07_slr_cat_predictor.html#exercise-3-numerical-summaries",
    "href": "activities/07_slr_cat_predictor.html#exercise-3-numerical-summaries",
    "title": "07. Simple linear regression: categorical predictor",
    "section": "Exercise 3: Numerical summaries",
    "text": "Exercise 3: Numerical summaries\nLet’s follow up our plots with some numerical summaries.\n\nTo warm up, first calculate the mean price across all diamonds.\n\n\ndiamonds %&gt;% \n    ___(mean(___))\n\n\nTo summarize the trends we observed in the grouped plots above, we can calculate the mean price for each type of cut. This requires the inclusion of the group_by() function:\n\n\n# Calculate mean price by cut\ndiamonds %&gt;% \n    group_by(cut) %&gt;% \n    ___(mean(___))\n\n\nExamine the group mean measurements, and make sure that you can match these numbers up with what you see in the plots.\nBased on the results above, we can see that, on average, diamonds with a “Fair” cut tend to cost more than higher-quality cuts. Let’s construct a new variable named cutFair, using on the following criteria:\n\n\ncutFair = 1 if the diamond is of Fair cut\ncutFair = 0 otherwise (any other value of cut (Good, Very Good, Premium, Ideal))\n\nThe ifelse function allows to create a new variable from an existing one, based on whether or not the values in that variable meet a certain “condition” (remember, you can always look up function documentation in R by typing ?ifelse in the Console, and hitting enter!).\nFill in the following code to create cutFair. The condition was given to you already. Try to use this to complete the code.\n\n# In the first blank, put what value cutFair should have if the condition is \"met\", or TRUE\n# In the second blank, put what value cutFair should have if the condition is \"not met\", or FALSE\ndiamonds &lt;- diamonds %&gt;%\n  mutate(cutFair=ifelse(cut == \"Fair\", ___, ___))\n\nVariables like cutFair that are coded as 0/1 to numerically indicate if a categorical variable is at a particular state are known as an indicator variable. You will sometimes see these referred to as a “binary variable” or “dichotomous variable”; you may also encounter the term “dummy variable” in older statistical literature.\n\nNow, let’s calculate the group means based on the new cutFair indicator variable:\n\n\ndiamonds %&gt;% \n    group_by(cutFair) %&gt;% \n    summarize(mean(price))",
    "crumbs": [
      "07. Simple linear regression: categorical predictor"
    ]
  },
  {
    "objectID": "activities/07_slr_cat_predictor.html#exercise-4-modeling-trend-using-a-categorical-predictor-with-exactly-2-categories",
    "href": "activities/07_slr_cat_predictor.html#exercise-4-modeling-trend-using-a-categorical-predictor-with-exactly-2-categories",
    "title": "07. Simple linear regression: categorical predictor",
    "section": "Exercise 4: Modeling trend using a categorical predictor with exactly 2 categories",
    "text": "Exercise 4: Modeling trend using a categorical predictor with exactly 2 categories\nNext, let’s model the trend in the relationship between the cutFair and price variables using a simple linear regression model:\n\n# Construct the model\ndiamond_mod0 &lt;- lm(price ~ cutFair, data = diamonds)\n\n# Summarize the model\ncoef(summary(diamond_mod0))\n\nCompare these results to the output of exercise 3e. What do you notice? How do you interpret the intercept and cutFair coefficient terms from this model?\n\nyour answer here",
    "crumbs": [
      "07. Simple linear regression: categorical predictor"
    ]
  },
  {
    "objectID": "activities/07_slr_cat_predictor.html#exercise-5-modeling-trend-using-a-categorical-predictor-with-2-categories",
    "href": "activities/07_slr_cat_predictor.html#exercise-5-modeling-trend-using-a-categorical-predictor-with-2-categories",
    "title": "07. Simple linear regression: categorical predictor",
    "section": "Exercise 5: Modeling trend using a categorical predictor with >2 categories",
    "text": "Exercise 5: Modeling trend using a categorical predictor with &gt;2 categories\nUsing a single binary predictor like the cutFair indicator variable is useful when there are two clearly delineated categories. However, the cut variable actually contains 5 categories! Because we’ve collapsed all non-Fair classifications into a single category (i.e. cutFair = 0), the model above can’t tell us anything about the difference in expected price between, say, Premium and Ideal cuts. The good news is that it is very straightforward to model categorical predictors with &gt;2 categories. We can do this by using the cut variable as our predictor:\n\n# Construct the model\ndiamond_mod &lt;- lm(price ~ cut, data = diamonds)\n\n# Summarize the model\ncoef(summary(diamond_mod))\n\n\nEven though we specified a single predictor variable in the model, we are seeing 4 coefficient estimates–why do you think this is the case?\n\n\nyour answer here\n\n\nNOTE: We see 4 indicator variables (for Good, Very Good, Premium, and Ideal), but we do not see cutFair in the model output. This is because Fair is the reference level of the cut variable (it’s first alphabetically). You’ll see below that it is, indeed, still in the model. You’ll also see why the term “reference level” makes sense!\n\n\nAfter examining the summary table output from the code chunk above, complete the model formula:\n\n\n\nE[price | cut] = ___ +/- ___ cutGood +/- ___ cutVery Good +/- ___ cutPremium +/- ___ cutIdeal",
    "crumbs": [
      "07. Simple linear regression: categorical predictor"
    ]
  },
  {
    "objectID": "activities/07_slr_cat_predictor.html#exercise-6-making-sense-of-the-model",
    "href": "activities/07_slr_cat_predictor.html#exercise-6-making-sense-of-the-model",
    "title": "07. Simple linear regression: categorical predictor",
    "section": "Exercise 6: Making sense of the model",
    "text": "Exercise 6: Making sense of the model\nRecall our model: E[price | cut] = 4358.7578 - 429.8933 cutGood - 376.9979 cutVery Good + 225.4999 cutPremium - 901.2158 cutIdeal\n\nUse the model formula to calculate the expected/typical price for diamonds of Good cut.\nSimilarly, calculate the expected/typical price for diamonds of Fair cut.\nRe-examine these 2 calculations. Where have you seen these numbers before?!",
    "crumbs": [
      "07. Simple linear regression: categorical predictor"
    ]
  },
  {
    "objectID": "activities/07_slr_cat_predictor.html#exercise-7-interpreting-coefficients",
    "href": "activities/07_slr_cat_predictor.html#exercise-7-interpreting-coefficients",
    "title": "07. Simple linear regression: categorical predictor",
    "section": "Exercise 7: Interpreting coefficients",
    "text": "Exercise 7: Interpreting coefficients\nRecall that our model formula is not a formula for a line. Thus we can’t interpret the coefficients as “slopes” as we have before. Taking this into account and reflecting upon your calculations above…\n\nInterpret the intercept coefficient (4358.7578) in terms of the data context. Make sure to use non-causal language, include units, and talk about averages rather than individual cases.\nInterpret the cutGood and cutVery Good coefficients (-429.8933 and -376.9979) in terms of the data context. Hint: where did you use these value in the prediction calculations above?",
    "crumbs": [
      "07. Simple linear regression: categorical predictor"
    ]
  },
  {
    "objectID": "activities/07_slr_cat_predictor.html#exercise-8-modeling-choices-challenge",
    "href": "activities/07_slr_cat_predictor.html#exercise-8-modeling-choices-challenge",
    "title": "07. Simple linear regression: categorical predictor",
    "section": "Exercise 8: Modeling choices (CHALLENGE)",
    "text": "Exercise 8: Modeling choices (CHALLENGE)\nWhy do we fit this model in this way (using 4 indicator variables cutGood, cutVery Good, cutPremium, cutIdeal)? Instead, suppose that we created a single variable cutCat that gave each category a numerical value: 0 for Fair, 1 for Good, 2 for Very Good, 3 for Premium, and 4 for Ideal.\nHow would this change things? What are the pros and cons of each approach?",
    "crumbs": [
      "07. Simple linear regression: categorical predictor"
    ]
  },
  {
    "objectID": "activities/07_slr_cat_predictor.html#reflection",
    "href": "activities/07_slr_cat_predictor.html#reflection",
    "title": "07. Simple linear regression: categorical predictor",
    "section": "Reflection",
    "text": "Reflection\nThrough the exercises above, you learned how to build and interpret models that incorporate a categorical predictor variable. For the benefit of your future self, summarize how one can interpret the coefficients for a categorical predictor.\n\nResponse: Put your response here.",
    "crumbs": [
      "07. Simple linear regression: categorical predictor"
    ]
  },
  {
    "objectID": "activities/07_slr_cat_predictor.html#render-your-work",
    "href": "activities/07_slr_cat_predictor.html#render-your-work",
    "title": "07. Simple linear regression: categorical predictor",
    "section": "Render your work",
    "text": "Render your work\n\nClick the “Render” button in the menu bar for this pane (blue arrow pointing right). This will create an HTML file containing all of the directions, code, and responses from this activity. A preview of the HTML will appear in the browser.\nScroll through and inspect the document to check that your work translated to the HTML format correctly.\nClose the browser tab.\nGo to the “Background Jobs” pane in RStudio and click the Stop button to end the rendering process.\nNavigate to your “Activities” subfolder within your “STAT155” folder and locate the HTML file. You can open it again in your browser to double check.",
    "crumbs": [
      "07. Simple linear regression: categorical predictor"
    ]
  },
  {
    "objectID": "activities/07_slr_cat_predictor.html#exercise-9-diamond-color",
    "href": "activities/07_slr_cat_predictor.html#exercise-9-diamond-color",
    "title": "07. Simple linear regression: categorical predictor",
    "section": "Exercise 9: Diamond color",
    "text": "Exercise 9: Diamond color\nConsider modeling price by color.\n\nBefore creating a visualization that shows the relationship between price and color, write down what you expect the plot to look like. Then construct and interpret an apporpriate plot.\nCompute the average price for each color.\nFit an appropriate linear model with lm() and display a short summary of the model.\nWrite out the model formula from the above summary.\nWhich color is the reference level? How can you tell from the model summary?\nInterpret the intercept and two other coefficients from the model in terms of the data context.",
    "crumbs": [
      "07. Simple linear regression: categorical predictor"
    ]
  },
  {
    "objectID": "activities/07_slr_cat_predictor.html#exercise-10-diamond-clarity",
    "href": "activities/07_slr_cat_predictor.html#exercise-10-diamond-clarity",
    "title": "07. Simple linear regression: categorical predictor",
    "section": "Exercise 10: Diamond clarity",
    "text": "Exercise 10: Diamond clarity\nIf you want more practice, repeat the steps from Exercise 8 for the clarity variable.\n\nSolutions",
    "crumbs": [
      "07. Simple linear regression: categorical predictor"
    ]
  },
  {
    "objectID": "solutions/05_slr_model_eval.html",
    "href": "solutions/05_slr_model_eval.html",
    "title": "Solutions for 05. Simple linear regression: model evaluation",
    "section": "",
    "text": "# Load packages and import data\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(dplyr)\n\nbikes &lt;- read_csv(\"https://mac-stat.github.io/data/bikeshare.csv\")"
  },
  {
    "objectID": "solutions/05_slr_model_eval.html#exercise-1-is-the-model-correct",
    "href": "solutions/05_slr_model_eval.html#exercise-1-is-the-model-correct",
    "title": "Solutions for 05. Simple linear regression: model evaluation",
    "section": "Exercise 1: Is the model correct?",
    "text": "Exercise 1: Is the model correct?\nThe blue curved trend line shows a clear downward trend around 85 degrees, which contextually makes plenty of sense—extremely hot days would naturally see less riders. Overall the combination of the upward trend and downward trend makes for a curved relationship that is not captured well by a straight line of best fit.\n\nggplot(bikes, aes(x = temp_feel, y = riders_registered)) + \n    geom_point() + \n    geom_smooth(se = FALSE) +\n    geom_smooth(method = \"lm\", se = FALSE, color = \"red\")\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "solutions/05_slr_model_eval.html#exercise-2-fixing-the-model",
    "href": "solutions/05_slr_model_eval.html#exercise-2-fixing-the-model",
    "title": "Solutions for 05. Simple linear regression: model evaluation",
    "section": "Exercise 2: Fixing the model",
    "text": "Exercise 2: Fixing the model\nThe second plot (showing the model with squared temperature) follows the natural curve in the trend better.\n\nbikes &lt;- bikes %&gt;% \n    mutate(temp_feel_squared = temp_feel^2)\n\n# Plot the model WITHOUT squared temperature\nggplot(bikes, aes(x = temp_feel, y = riders_registered)) + \n    geom_point() + \n    geom_smooth(se = FALSE) +\n    geom_smooth(method = \"lm\", se = FALSE, color = \"red\")\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n# Plot the model WITH squared temperature\nggplot(bikes, aes(x = temp_feel, y = riders_registered)) + \n    geom_point() + \n    geom_smooth(se = FALSE) +\n    geom_smooth(method = \"lm\", formula = y ~ x + I(x^2), se = FALSE, color = \"red\")\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'"
  },
  {
    "objectID": "solutions/05_slr_model_eval.html#exercise-3-residual-plots",
    "href": "solutions/05_slr_model_eval.html#exercise-3-residual-plots",
    "title": "Solutions for 05. Simple linear regression: model evaluation",
    "section": "Exercise 3: Residual plots",
    "text": "Exercise 3: Residual plots\nThe first residual plot (from the model with just a straight line trend) shows a lingering trend in the residuals—the blue curve traces the trend in the residuals, and it does not lie flat on the y = 0 line.\nOn the other hand, the second residual plot (from the model which uses a squared term to allow for curvature) shows very little trend in the residuals—the blue curve is almost flat on the y = 0 line.\n\n# Fit a linear model\nbike_mod1 &lt;- lm(riders_registered ~ temp_feel, data = bikes)\n# Fit a quadratic model\nbike_mod2 &lt;- lm(riders_registered ~ temp_feel + temp_feel_squared, data = bikes)\n\n# Check out the residual plot for bike_mod1 (the incorrect model)\nggplot(bike_mod1, aes(x = .fitted, y = .resid)) + \n    geom_point() + \n    geom_hline(yintercept = 0) +\n    geom_smooth(se = FALSE)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n# Construct the residual plot for bike_mod2 (the good model)\nggplot(bike_mod2, aes(x = .fitted, y = .resid)) + \n    geom_point() + \n    geom_hline(yintercept = 0) +\n    geom_smooth(se = FALSE)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'"
  },
  {
    "objectID": "solutions/05_slr_model_eval.html#exercise-4-another-example-of-an-incorrect-model",
    "href": "solutions/05_slr_model_eval.html#exercise-4-another-example-of-an-incorrect-model",
    "title": "Solutions for 05. Simple linear regression: model evaluation",
    "section": "Exercise 4: Another example of an incorrect model",
    "text": "Exercise 4: Another example of an incorrect model\n\n# Import the data\nlibrary(fivethirtyeight)\ndata(bechdel)\n\n# Get only 1997 movies\nmovies_1997 &lt;- bechdel %&gt;% \n    filter(year == 1997)\n\n# Construct the model\nbechdel_model &lt;- lm(intgross ~ budget, movies_1997)\n\n\n\n\n\n# Scatterplot of earnings and budget with linear and curved trend lines\nggplot(movies_1997, aes(x = budget, y = intgross)) +\n    geom_point() +\n    geom_smooth(se = FALSE) +\n    geom_smooth(method = \"lm\", se = FALSE, color = \"red\")\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n# Residual plot for bechdel_model\nggplot(bechdel_model, aes(x = .fitted, y = .resid)) +\n    geom_point() +\n    geom_hline(yintercept = 0) +\n    geom_smooth(se = FALSE)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nFrom the scatterplot, we can see that there is one movie that is a massive outlier in both budget and earnings, and this outlier is pulling up the trend line that makes the model for “regular” movies that have budgets and earnings in “normal” ranges.\nThe outlier movie is Titanic:\n\n\n# One of many ways to filter to find the outlier movie!\nmovies_1997 %&gt;% \n    filter(intgross &gt; 2000000000)\n\n# A tibble: 1 × 15\n   year imdb      title   test  clean_test binary budget domgross intgross code \n  &lt;int&gt; &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt; &lt;ord&gt;      &lt;chr&gt;   &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;\n1  1997 tt0120338 Titanic ok    ok         PASS      2e8   6.59e8   2.19e9 1997…\n# ℹ 5 more variables: budget_2013 &lt;int&gt;, domgross_2013 &lt;dbl&gt;,\n#   intgross_2013 &lt;dbl&gt;, period_code &lt;int&gt;, decade_code &lt;int&gt;"
  },
  {
    "objectID": "solutions/05_slr_model_eval.html#exercise-5-is-the-model-strong-developing-r-squared-intuition",
    "href": "solutions/05_slr_model_eval.html#exercise-5-is-the-model-strong-developing-r-squared-intuition",
    "title": "Solutions for 05. Simple linear regression: model evaluation",
    "section": "Exercise 5: Is the model strong? Developing R-squared intuition",
    "text": "Exercise 5: Is the model strong? Developing R-squared intuition\nThe R-squared metric is a way to quantify the strength of a model. It measures how much variation in the outcome/response variable can be explained by the model.\nWhere does R-squared come from? Well, it turns out that we can partition the variance of the observed response values into the variability that’s explained by the model (the variance of the predictions) and the variability that’s left unexplained by the model (the variance of the residuals):\n\\[\\text{Var(observed) = Var(predicted) + Var(residuals)}\\]\n“Good” models have residuals that don’t deviate far from 0. So the smaller the variance in the residuals (thus larger the variance in the predictions), the stronger the model. Take a look at the picture below and write a few sentences addressing the following:\n\nThe first row corresponds to the weaker model. We can tell because the points are much more dispersed from the trend line than in the second row. Recall that the correlation metric measures how closely clustered points are about a straight line of best fit, so we would expect the correlation to be lower for the first row than the second row.\nThe variance of the residuals is much lower for the second row—the residuals are all quite small. This indicates a stronger model."
  },
  {
    "objectID": "solutions/05_slr_model_eval.html#exercise-6-r-squared-interpretations",
    "href": "solutions/05_slr_model_eval.html#exercise-6-r-squared-interpretations",
    "title": "Solutions for 05. Simple linear regression: model evaluation",
    "section": "Exercise 6: R-squared Interpretations",
    "text": "Exercise 6: R-squared Interpretations\n\nsummary(bike_mod1)\n\n\nCall:\nlm(formula = riders_registered ~ temp_feel, data = bikes)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3607.1  -959.2  -153.8   998.2  3304.8 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -667.916    251.608  -2.655  0.00811 ** \ntemp_feel     57.892      3.306  17.514  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1310 on 729 degrees of freedom\nMultiple R-squared:  0.2961,    Adjusted R-squared:  0.2952 \nF-statistic: 306.7 on 1 and 729 DF,  p-value: &lt; 2.2e-16\n\n\nMultiple R-squared: 0.2961\nInterpretation: 29.61% of the variation in number of registered riders on any given day can be explained by the variation in temperature (specifically, what temperature it “feels” like it is)."
  },
  {
    "objectID": "solutions/05_slr_model_eval.html#exercise-7-further-exploring-r-squared",
    "href": "solutions/05_slr_model_eval.html#exercise-7-further-exploring-r-squared",
    "title": "Solutions for 05. Simple linear regression: model evaluation",
    "section": "Exercise 7: Further exploring R-squared",
    "text": "Exercise 7: Further exploring R-squared\nIn this exercise, we’ll look at data from a synthetic dataset called Anscombe’s quartet. Load the data in as follows, and look at the first few rows:\n\ndata(anscombe)\n\n# Look at the first few rows\nhead(anscombe)\n\n  x1 x2 x3 x4   y1   y2    y3   y4\n1 10 10 10  8 8.04 9.14  7.46 6.58\n2  8  8  8  8 6.95 8.14  6.77 5.76\n3 13 13 13  8 7.58 8.74 12.74 7.71\n4  9  9  9  8 8.81 8.77  7.11 8.84\n5 11 11 11  8 8.33 9.26  7.81 8.47\n6 14 14 14  8 9.96 8.10  8.84 7.04\n\n\nAll of these models have close to the same intercept, slope, and R-squared!\n\nanscombe_mod1 &lt;- lm(y1 ~ x1, data = anscombe)\nanscombe_mod2 &lt;- lm(y2 ~ x2, data = anscombe)\nanscombe_mod3 &lt;- lm(y3 ~ x3, data = anscombe)\nanscombe_mod4 &lt;- lm(y4 ~ x4, data = anscombe)\n\nsummary(anscombe_mod1)\n\n\nCall:\nlm(formula = y1 ~ x1, data = anscombe)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.92127 -0.45577 -0.04136  0.70941  1.83882 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   3.0001     1.1247   2.667  0.02573 * \nx1            0.5001     0.1179   4.241  0.00217 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.237 on 9 degrees of freedom\nMultiple R-squared:  0.6665,    Adjusted R-squared:  0.6295 \nF-statistic: 17.99 on 1 and 9 DF,  p-value: 0.00217\n\nsummary(anscombe_mod2)\n\n\nCall:\nlm(formula = y2 ~ x2, data = anscombe)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.9009 -0.7609  0.1291  0.9491  1.2691 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)    3.001      1.125   2.667  0.02576 * \nx2             0.500      0.118   4.239  0.00218 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.237 on 9 degrees of freedom\nMultiple R-squared:  0.6662,    Adjusted R-squared:  0.6292 \nF-statistic: 17.97 on 1 and 9 DF,  p-value: 0.002179\n\nsummary(anscombe_mod3)\n\n\nCall:\nlm(formula = y3 ~ x3, data = anscombe)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.1586 -0.6146 -0.2303  0.1540  3.2411 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   3.0025     1.1245   2.670  0.02562 * \nx3            0.4997     0.1179   4.239  0.00218 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.236 on 9 degrees of freedom\nMultiple R-squared:  0.6663,    Adjusted R-squared:  0.6292 \nF-statistic: 17.97 on 1 and 9 DF,  p-value: 0.002176\n\nsummary(anscombe_mod4)\n\n\nCall:\nlm(formula = y4 ~ x4, data = anscombe)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-1.751 -0.831  0.000  0.809  1.839 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   3.0017     1.1239   2.671  0.02559 * \nx4            0.4999     0.1178   4.243  0.00216 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.236 on 9 degrees of freedom\nMultiple R-squared:  0.6667,    Adjusted R-squared:  0.6297 \nF-statistic:    18 on 1 and 9 DF,  p-value: 0.002165\n\n\nBut when we look at the scatterplots, they all look substantially different, and we would want to approach our modeling differently for each one:\n\nx1 and y1: A linear model seems appropriate for this data.\nx2 and y2: The scatterplot is clearly curved—a “linear” regression model with squared terms, for example, would be more appropriate for this data. (We’ll talk more about ways to handle nonlinear relationships soon!)\nx3 and y3: There is a very clear outlier at about x3 = 13 that we would want to dig into to better understand the context. After that investigation, we might consider removing this outlier and refitting the model.\nx4 and y4: There is clearly something strange going on with most of the cases having an x4 value of exactly 8. We would not want to jump straight into modeling. Instead, we should dig deeper to find out more about this data.\n\n\nggplot(anscombe, aes(x = x1, y = y1)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nggplot(anscombe, aes(x = x2, y = y2)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nggplot(anscombe, aes(x = x3, y = y3)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nggplot(anscombe, aes(x = x4, y = y4)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "solutions/05_slr_model_eval.html#exercises-8---11",
    "href": "solutions/05_slr_model_eval.html#exercises-8---11",
    "title": "Solutions for 05. Simple linear regression: model evaluation",
    "section": "Exercises 8 - 11",
    "text": "Exercises 8 - 11\nNo solutions for these exercises. These require longer discussions, not discrete answers."
  },
  {
    "objectID": "tech_setup.html",
    "href": "tech_setup.html",
    "title": "Tech Setup",
    "section": "",
    "text": "Follow these instructions to set up the software that we’ll be using throughout the semester. Even if you’ve already downloaded both R and RStudio, you’ll want to re-download to make sure that you have the most current versions.\n\nRequired: Change the default file download location for your internet browser.\n\nGenerally by default, internet browsers automatically save all files to the Downloads folder on your computer. This does not encourage good file organization practices. You need to change this option so that your browser asks you where to save each file before downloading it.\nThis page has information on how to do this for the most common browsers.\n\n\nRequired: Download R and RStudio.\n\nFIRST: Download R here.\n\nIn the top section, you will see three links “Download R for …”\nChoose the link that corresponds to your computer.\nAs of August 27, 2024, the latest version of R is 4.4.1 (“Race for Your Life”).\n\nSECOND: Download RStudio here.\n\nClick the button under step 2 to install the version of RStudio recommended for your computer.\nAs of August 27, 2024, the latest version of RStudio is 2024.04.2+764.\n\n\n\nSuggested: Watch this video describing key configuration options for RStudio.\n\nRequired: Install required packages.\n\nAn R package is an extra bit of functionality that will help us in our data analysis efforts in a variety of ways.\nOpen RStudio and click inside the Console pane (by default, the bottom left pane). Copy and paste the following command into the Console. You should see the text below appear to the right of the &gt;, which is called the R prompt. After you paste, hit Enter.\n\n\ninstall.packages(c(\"tidyverse\"))\n\n\nYou will see a lot of text from status messages appearing in the Console as the packages are being installed. Wait until you see the &gt; again.\nEnter the command library(tidyverse) and hit Enter.\nIf you see an error message, then there was a problem installing the package. Talk to the instructor or a preceptor for help.\nQuit RStudio. You’re done setting up!\n\n\nOptional: For a tour of RStudio features, watch this video. It also shows you how to customize the layout and color scheme of RStudio.\n\nRequired: Set essential RStudio options.\nGo to Tools -&gt; Global Options -&gt; General -&gt; Workplace. You’ll see 2 options:\n\nRestore .RData into workspace at startup: Leave this unchecked\nSave workspace to .RData on exit: Select “Never”\n\nWithout doing this RStudio will save and reload everything that you’ve been working on from the start of the semester. Since we’ll be working with new data each class, we want to keep our digital environment clean. Essentially, this is like an artist getting a clean canvas for each new painting rather than trying to paint all paintings on a single canvas."
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Course Schedule",
    "section": "",
    "text": "The course schedule below will be filled in throughout the semester. For each day, there will be a link to course slides (if there are any that day) and notes/links on what is due ahead of class time. The “Announcements” column is (hopefully) self-explanatory. Any urgent announcements will be made over email.\n\n\n\nWeek\nTuesday\nThursday\nAnnouncements\n\n\n\n\n4\n2/11: SLR categorical predictors\nBefore class:\n\nComplete today’s Moodle checkpoint\n\n2/13: Quiz 1 (1 hour in class)\n\nPP#2 due by 5pm Wednesday, 2/12\nGroup members for the final project are posted on Moodle\n\n\n\n3\n2/4: SLR model evaluation\nBefore class:\n\nComplete today’s Moodle checkpoint\n\n2/6: SLR variable transformations + library activity\nBefore class:\n\nComplete today’s Moodle checkpoint\n\n\nPP#1 due by 5pm Wednesday, 2/5\nPlease complete the project preferences survey by Friday, 2/7\nSee course Google Calendar for updated office hours\n\n\n\n2\n1/28: Intro to R + univariate visualization & summaries\nBefore class:\n\nComplete today’s Moodle checkpoint\n\n1/30: Intro to simple linear regression\nBefore class:\n\nComplete today’s Moodle checkpoint\n\n\nLast day to add/drop is Friday, 1/31\nPreceptor office hours start this week–see the Google calendar for times\nPP#1 is posted on the assignments tab (due Wednesday, 2/5 at 5pm CT)\n\n\n\n1\nWinter Break\n1/23: First day of class!\nBefore class:\n\nReview the course syllabus\nFamiliarize yourself with Moodle and the course website\nComplete the Introductions survey\nDownload R and RStudio\n\nWelcome back to campus!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STAT 155: Introduction to Statistical Modeling",
    "section": "",
    "text": "STAT 155: Introduction to Statistical Modeling\nMacalester College, Spring 2025\n\nLearn the fundamentals of summarizing, visualizing, and modeling data to answer research questions.\n\n\nInstructor: Jedidiah Carlson  Class meeting times:\n\nSection 02: Tu/Th 9:40-11:10am\nSection 03: Tu/Th 1:20-2:50pm\nSection 04: Tu/Th 3:00-4:30pm\n\nClass location: THTR 202 \nJed’s drop-in hours:\n\nlocation: My office (OLRI 235)\ntimes: See this calendar (Typically from 1-3pm on Wednesdays and additional times on Monday or Thursday, depending on the week).\n1:1 appointments: I’m also happy to meet one-on-one if my normal drop-in hours don’t work for you. You can schedule a time to meet with me using this link.\n\n\nR/RStudio Preceptor Office Hours: Available on the MSCS Events google calendar (not to be used for questions about course content, only R-related things!)\nSTAT 155 Preceptor Office Hours: There is a link to a Google Calendar containing all preceptor office hours available at the top of the course Moodle page!\n\nThis course website will be updated throughout the semester with new activities, assignments, and announcements, so please bookmark this page if you are enrolled in the course!\nIf you find any typos, bugs, dead links, or have other questions, please email jcarls13@macalester.edu"
  },
  {
    "objectID": "activities/01_foundations_welcome.html",
    "href": "activities/01_foundations_welcome.html",
    "title": "01. Collecting and Summarizing Data",
    "section": "",
    "text": "Welcome to our first in-class activity! Today we will collect and summarize some data. Our goals are to get to know the people in this class and to start working with data.\nBy the end of this lesson, you should be able to:\n\nDefine cases and variables\nApply the 5 W’s + H (who, what, when, where, why, and how) to data collection\n\nLinks to related reading(s):\n\nWhat is Data?\nData Context\n\nThis activity is structured a bit differently than the activities for the remainder of the class. In this section, you’ll typically find a mini-lecture, review material, or guided / structural examples, followed by exercises.\nFor today, you’ll have some steps to follow for an interactive, tactile activity at your tables before working through the exercises below together.\n\n\nAt your table, write a one to two word answer to each of the following questions, each on a separate post-it note (do this individually). If there are two questions: write your answer to the first question on the left-hand side of the post-it note, and your answer to the second question on the bottom of the post-it note.\n\nHow many hours of sleep did you get last night?\nApproximately how far away (in miles) is your hometown from Macalester?\nWhat is your declared or potential major? (If you are a double major, just pick whichever one you think of first.)\nWhat is your anticipated graduation year?\nHow tall are you in inches?\nHow many stats courses have you taken in the past?\nHave you used R or RStudio before?\nHow many other students in the class do you know?\nIs it your birthday this semester? (yes/no)\nHow many unread emails do you have in your inbox right now?\n\n\n\n\nDesignate one person from your table to distribute your group’s answers to the questions to the corresponding “station” around the classroom. Each table should have a number on it, corresponding to the “station”/question.\n\n\n\nFill out an electronic version of these questions. We’ll come back to this in a future class. Wait until everyone in your group is done with this before moving on to the exercises.",
    "crumbs": [
      "01. Collecting and Summarizing Data"
    ]
  },
  {
    "objectID": "activities/01_foundations_welcome.html#step-1",
    "href": "activities/01_foundations_welcome.html#step-1",
    "title": "01. Collecting and Summarizing Data",
    "section": "",
    "text": "At your table, write a one to two word answer to each of the following questions, each on a separate post-it note (do this individually). If there are two questions: write your answer to the first question on the left-hand side of the post-it note, and your answer to the second question on the bottom of the post-it note.\n\nHow many hours of sleep did you get last night?\nApproximately how far away (in miles) is your hometown from Macalester?\nWhat is your declared or potential major? (If you are a double major, just pick whichever one you think of first.)\nWhat is your anticipated graduation year?\nHow tall are you in inches?\nHow many stats courses have you taken in the past?\nHave you used R or RStudio before?\nHow many other students in the class do you know?\nIs it your birthday this semester? (yes/no)\nHow many unread emails do you have in your inbox right now?",
    "crumbs": [
      "01. Collecting and Summarizing Data"
    ]
  },
  {
    "objectID": "activities/01_foundations_welcome.html#step-2",
    "href": "activities/01_foundations_welcome.html#step-2",
    "title": "01. Collecting and Summarizing Data",
    "section": "",
    "text": "Designate one person from your table to distribute your group’s answers to the questions to the corresponding “station” around the classroom. Each table should have a number on it, corresponding to the “station”/question.",
    "crumbs": [
      "01. Collecting and Summarizing Data"
    ]
  },
  {
    "objectID": "activities/01_foundations_welcome.html#step-3",
    "href": "activities/01_foundations_welcome.html#step-3",
    "title": "01. Collecting and Summarizing Data",
    "section": "",
    "text": "Fill out an electronic version of these questions. We’ll come back to this in a future class. Wait until everyone in your group is done with this before moving on to the exercises.",
    "crumbs": [
      "01. Collecting and Summarizing Data"
    ]
  },
  {
    "objectID": "activities/01_foundations_welcome.html#exercise-1",
    "href": "activities/01_foundations_welcome.html#exercise-1",
    "title": "01. Collecting and Summarizing Data",
    "section": "Exercise 1",
    "text": "Exercise 1\nWith your group, in no more than two sentences per question, respond to the questions posed by the 5 W’s + H for the data at your group’s table. If you need a refresher on the 5 W’s + H, check out the related readings posted at the top of this activity!\nWho\n\nResponse: Type your response here.\n\nWhat\n\nResponse: Type your response here.\n\nWhen\n\nResponse: Type your response here.\n\nWhere\n\nResponse: Type your response here.\n\nWhy\n\nResponse: Type your response here.\n\nHow\n\nResponse: Type your response here.",
    "crumbs": [
      "01. Collecting and Summarizing Data"
    ]
  },
  {
    "objectID": "activities/01_foundations_welcome.html#exercise-2",
    "href": "activities/01_foundations_welcome.html#exercise-2",
    "title": "01. Collecting and Summarizing Data",
    "section": "Exercise 2",
    "text": "Exercise 2\nMove the post-it notes around to construct a visualization of the responses at your station.",
    "crumbs": [
      "01. Collecting and Summarizing Data"
    ]
  },
  {
    "objectID": "activities/01_foundations_welcome.html#exercise-3",
    "href": "activities/01_foundations_welcome.html#exercise-3",
    "title": "01. Collecting and Summarizing Data",
    "section": "Exercise 3",
    "text": "Exercise 3\nCalculate at least one numerical summary of the post-it note responses at your station, and record your numerical summary in the response text below. Write a complete sentence, not just the numerical summary alone! This is good practice for summarizing data in more formal writing.\n\nResponse: Type your response here.",
    "crumbs": [
      "01. Collecting and Summarizing Data"
    ]
  },
  {
    "objectID": "activities/01_foundations_welcome.html#exercise-4",
    "href": "activities/01_foundations_welcome.html#exercise-4",
    "title": "01. Collecting and Summarizing Data",
    "section": "Exercise 4",
    "text": "Exercise 4\nIn no more than three sentences, describe what you learn about from the visual and numerical summaries. Try to write your description in a way that tells an interesting story about the people in this class.\n\nResponse: Type your response here.",
    "crumbs": [
      "01. Collecting and Summarizing Data"
    ]
  },
  {
    "objectID": "activities/01_foundations_welcome.html#exercise-5",
    "href": "activities/01_foundations_welcome.html#exercise-5",
    "title": "01. Collecting and Summarizing Data",
    "section": "Exercise 5",
    "text": "Exercise 5\nImagine that you took all the post-it notes in this room and organized them into a spreadsheet. What would each row in the underlying data set represent? What would each column of the data set represent? Check out the first related reading, linked at the top of this activity, if you need assistance!\n\nResponse: Type your response here.",
    "crumbs": [
      "01. Collecting and Summarizing Data"
    ]
  },
  {
    "objectID": "activities/01_foundations_welcome.html#reflection",
    "href": "activities/01_foundations_welcome.html#reflection",
    "title": "01. Collecting and Summarizing Data",
    "section": "Reflection",
    "text": "Reflection\nIn three to four sentences, reflect upon today’s activity. Some reflection prompts are found below:\n\nDo you think the context in which the data was collected influenced the results you found?\nWho would the numerical summaries you calculated potentially be represented of? Could you generalize the information you learned to a broader population (all students at Mac, perhaps), or would you have ethical concerns with generalizing your results?\nWhat (if anything) surprised you about the numerical summaries calculated by your group, or other groups?\nDid your data visualization help you better understand, or discover new things about the data that otherwise would have been difficult to distinguish? Why or why not?\n\n\nResponse: Type your response here.",
    "crumbs": [
      "01. Collecting and Summarizing Data"
    ]
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Practice Problems",
    "section": "",
    "text": "…due Wednesdays at 5pm Central on Moodle!\n\nPractice Problems 1, due 2/5\nPractice Problems 2, due 2/12\n[Practice Problems 3], due 2/26\n[Practice Problems 4], due 3/5\n[Practice Problems 5], due 3/26\n[Practice Problems 6], due 4/9\n[Practice Problems 7], due 4/16\n[Practice Problems 8], due 4/23"
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Project",
    "section": "",
    "text": "As noted in the syllabus, a detailed description of the group project can be found here. Important dates and additional information are listed below.\n\nImportant Dates\nDetails coming soon!\n\n\nGrading\nThe final draft will be graded using the rubric found here. Although the first two checkpoints will not directly contribute to your course grade, the feedback they allow me to provide will ensure the success of your final draft!\n\n\nResources\nLater in the semester, I will post at least one example of a successful final draft, as well as a google doc template for the final draft.\n\n\nProject Groups\nProject groups will ultimately be determined by me, with the assistance of a Project Group Preferences survey. The survey will be sent out early in the semester (exact date TBD) and will allow you to either list people you would like to be in a group with or specify that you would like to be placed in a group randomly by me. I will do my best to ensure that groups are constructed as closely to survey responses as possible. Since one component of the project involves an in-class presentation, you may not work with students in different sections on the project.\nIf for any reason there is an individual (or individuals) with whom you do not feel safe participating in a project group with, there will be a space to note this on the survey. You will not be expected to provide any justification for your response to this question, but note that as I need to place you in groups, the survey will not be anonymous.\nGroup work and collaboration are important components of nearly all statistical analyses and projects. I recognize that individual contributions to a group project are not always consistent between group members. To this end, you will (as a group) be expected to explicitly specify the project tasks completed by each team member along with the final draft of your paper.\nIf there are any concerns with project groups throughout the semester, I am happy to meet with groups or individuals to discuss ways to move forward."
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": " ",
    "section": "",
    "text": "Macalester College, Spring 2025\n\nSection 02: Tu/Th 9:40-11:10am, THTR 202\nSection 03: Tu/Th 1:20-2:50pm, THTR 202\nSection 04: Tu/Th 3:00-4:30pm, THTR 202\n\n\n\n\nJedidiah (Jed) Carlson, PhD\nPronouns: he/him\nPronunciation: listen here\nOffice: Olin-Rice 235\nWebsite: https://jedidiahcarlson.com\nEmail: jcarls13@macalester.edu\n\n\n\n\n\n\nCall me “Jed”\n\n\n\nYou may call me (in order of my personal preference), Jed, Professor Carlson, or Dr. Carlson–but please use whichever of these options you are most comfortable with!\n\n\nDrop-in (office) hours:\n\nlocation: My office (OLRI 235)\ntimes: See this calendar.\n1:1 appointments: I’m also happy to meet one-on-one if my normal drop-in hours don’t work for you. You can schedule a time to meet with me using this link.\n\n\n\n\nThis course provides an introduction to statistical modeling. In other words, you will develop the basic skills to analyze data, test research hypotheses, and make predictions about the world.\nBeing able to summarize, interpret, and communicate about data are crucial for navigating today’s information landscape, and these are precisely the skills that we’ll build in this class. Throughout the semester, we’ll study the fundamental methods that statisticians use to extract knowledge from data, emphasizing statistical literacy & intuition, real data applications, and modern computing over memorizing facts and formulas.\n\n\nBy actively participating in this course, you will develop and/or strengthen your abilities to:\n\nVisualize: explore, understand, and describe patterns in data with plots and graphics\nModel: build, interpret, and evaluate statistical models to identify trends in data\nInfer: extend observations from sample data to draw conclusions and make predictions\nCompute: use the (free!) statistical software R to analyze real data and create reproducible reports\nContextualize: interpret results in context, by considering the methods of data collection, the scientific and social contexts, and ethical dimensions\nCommunicate: accurately describe methods and results in a way that is scientifically sound and widely accessible\nCollaborate: work productively and effectively in a group setting\n\n\n\n\n\n\nThere is no required textbook for this course. Throughout the course, readings may be assigned from these notes, or other sources. All links and materials needed will be provided on the Schedule tab of this website.\nThe best resources for this course are course content videos, attending and participating in class / assignments, and office hours. I am happy to talk about possible additional materials / strategies for effective learning at any time throughout the semester!\n\n\n\nWe will use the (completely free and open source) R programming language extensively throughout this course. RStudio (an interface for R) will facilitate our use of R. You may use RStudio in one of two ways:\n\nDesktop version: Download for Windows or Mac at https://posit.co/downloads/. Note: You first need to download and install R on your computer in order to use the desktop version of RStudio\nOnline: Go to https://rstudio.macalester.edu, and log in with your full Mac email address and your usual Mac password to get access. (Note that this is a shared resource across MSCS, and you may experience performance issues due to high traffic, server outages, etc.)\n\nMore detailed instructions on downloading, installing, and getting started with R, RStudio, and an important package called Quarto is available on the Tech Setup tab.\n\n\n\n\nWhen taking a new course, figuring out the right workflow/cadence of effort throughout the week can be a big adjustment. And most of you are doing this for 4 different courses! Below are some suggestions for what to expect in the course and how to focus your time and attention during and outside of class.\n\n\nPre-class videos/readings: Some class periods will have required videos or reading to get acquainted with new concepts before seeing them again in class. My goal for these videos and readings is for you to get the most out of class time by being able to more easily follow explanations in class and to engage most fully in class activities. When there are required readings or videos, there will be an associated checkpoint to complete on Moodle (due 30 minutes before the start of the next class).\n\n\n\n\n\n\nSuggestions\n\n\n\n\nAs you take notes on videos/readings, highlight or otherwise mark all the areas where you have questions. Gather up all of these questions in one place, and bring them to class with you.\nRecord any reflections from in-class time about your learning process or interactions with peers while they are still fresh.\nAfter learning a new topic in class, it is helpful to attempt the upcoming assignment as soon as possible. Just by getting some rough ideas down quickly, you avoid the difficulty of starting from a blank slate.\nCome to instructor and preceptor drop-in hours (office hours) to chat about the course or anything else!\n\n\n\n\n\n\nClass time will be a mix of interactive lecture and longer stretches of group work. During the lecture portion, I will pause explanation frequently to prompt a short exercise or ask questions that you’ll reflect on individually or together.\n\n\n\n\n\n\nSuggestions\n\n\n\n\nAs we review the material at the start of class and as you work on the class activity, reference your set of questions from the pre-class material. Have you made progress on addressing those questions? Who or what helped with improving your understanding, and how?"
  },
  {
    "objectID": "syllabus.html#your-instructor",
    "href": "syllabus.html#your-instructor",
    "title": " ",
    "section": "",
    "text": "Jedidiah (Jed) Carlson, PhD\nPronouns: he/him\nPronunciation: listen here\nOffice: Olin-Rice 235\nWebsite: https://jedidiahcarlson.com\nEmail: jcarls13@macalester.edu\n\n\n\n\n\n\nCall me “Jed”\n\n\n\nYou may call me (in order of my personal preference), Jed, Professor Carlson, or Dr. Carlson–but please use whichever of these options you are most comfortable with!\n\n\nDrop-in (office) hours:\n\nlocation: My office (OLRI 235)\ntimes: See this calendar.\n1:1 appointments: I’m also happy to meet one-on-one if my normal drop-in hours don’t work for you. You can schedule a time to meet with me using this link."
  },
  {
    "objectID": "syllabus.html#overview",
    "href": "syllabus.html#overview",
    "title": " ",
    "section": "",
    "text": "This course provides an introduction to statistical modeling. In other words, you will develop the basic skills to analyze data, test research hypotheses, and make predictions about the world.\nBeing able to summarize, interpret, and communicate about data are crucial for navigating today’s information landscape, and these are precisely the skills that we’ll build in this class. Throughout the semester, we’ll study the fundamental methods that statisticians use to extract knowledge from data, emphasizing statistical literacy & intuition, real data applications, and modern computing over memorizing facts and formulas.\n\n\nBy actively participating in this course, you will develop and/or strengthen your abilities to:\n\nVisualize: explore, understand, and describe patterns in data with plots and graphics\nModel: build, interpret, and evaluate statistical models to identify trends in data\nInfer: extend observations from sample data to draw conclusions and make predictions\nCompute: use the (free!) statistical software R to analyze real data and create reproducible reports\nContextualize: interpret results in context, by considering the methods of data collection, the scientific and social contexts, and ethical dimensions\nCommunicate: accurately describe methods and results in a way that is scientifically sound and widely accessible\nCollaborate: work productively and effectively in a group setting\n\n\n\n\n\n\nThere is no required textbook for this course. Throughout the course, readings may be assigned from these notes, or other sources. All links and materials needed will be provided on the Schedule tab of this website.\nThe best resources for this course are course content videos, attending and participating in class / assignments, and office hours. I am happy to talk about possible additional materials / strategies for effective learning at any time throughout the semester!\n\n\n\nWe will use the (completely free and open source) R programming language extensively throughout this course. RStudio (an interface for R) will facilitate our use of R. You may use RStudio in one of two ways:\n\nDesktop version: Download for Windows or Mac at https://posit.co/downloads/. Note: You first need to download and install R on your computer in order to use the desktop version of RStudio\nOnline: Go to https://rstudio.macalester.edu, and log in with your full Mac email address and your usual Mac password to get access. (Note that this is a shared resource across MSCS, and you may experience performance issues due to high traffic, server outages, etc.)\n\nMore detailed instructions on downloading, installing, and getting started with R, RStudio, and an important package called Quarto is available on the Tech Setup tab.\n\n\n\n\nWhen taking a new course, figuring out the right workflow/cadence of effort throughout the week can be a big adjustment. And most of you are doing this for 4 different courses! Below are some suggestions for what to expect in the course and how to focus your time and attention during and outside of class.\n\n\nPre-class videos/readings: Some class periods will have required videos or reading to get acquainted with new concepts before seeing them again in class. My goal for these videos and readings is for you to get the most out of class time by being able to more easily follow explanations in class and to engage most fully in class activities. When there are required readings or videos, there will be an associated checkpoint to complete on Moodle (due 30 minutes before the start of the next class).\n\n\n\n\n\n\nSuggestions\n\n\n\n\nAs you take notes on videos/readings, highlight or otherwise mark all the areas where you have questions. Gather up all of these questions in one place, and bring them to class with you.\nRecord any reflections from in-class time about your learning process or interactions with peers while they are still fresh.\nAfter learning a new topic in class, it is helpful to attempt the upcoming assignment as soon as possible. Just by getting some rough ideas down quickly, you avoid the difficulty of starting from a blank slate.\nCome to instructor and preceptor drop-in hours (office hours) to chat about the course or anything else!\n\n\n\n\n\n\nClass time will be a mix of interactive lecture and longer stretches of group work. During the lecture portion, I will pause explanation frequently to prompt a short exercise or ask questions that you’ll reflect on individually or together.\n\n\n\n\n\n\nSuggestions\n\n\n\n\nAs we review the material at the start of class and as you work on the class activity, reference your set of questions from the pre-class material. Have you made progress on addressing those questions? Who or what helped with improving your understanding, and how?"
  },
  {
    "objectID": "syllabus.html#course-website",
    "href": "syllabus.html#course-website",
    "title": " ",
    "section": "Course website",
    "text": "Course website\nAll course materials will be posted on the course website. The Schedule tab of this website will contain information about due dates, in-class activities, etc."
  },
  {
    "objectID": "syllabus.html#moodle",
    "href": "syllabus.html#moodle",
    "title": " ",
    "section": "Moodle",
    "text": "Moodle\nMoodle will be used to submit assignments/checkpoint quizzes, post grades, assignment feedback, announcements, and more. Please check the course Moodle page every day before class!"
  },
  {
    "objectID": "syllabus.html#email",
    "href": "syllabus.html#email",
    "title": " ",
    "section": "Email",
    "text": "Email\nPlease send any personal questions or administrative updates (e.g., attendance, accommodations) to me via email. Please put “STAT 155” in the subject line of all emails to help ensure that it does not get lost in my inbox!\nI will generally not respond to emails outside of business hours (9am-5pm M-F). Please allow 1 business day for a response (e.g. an email sent on Friday may not get a response until the following Monday).\nAny urgent announcements (e.g. unexpected class cancellations, notice of modifications to assignments) will be made over email."
  },
  {
    "objectID": "syllabus.html#drop-in-office-hours",
    "href": "syllabus.html#drop-in-office-hours",
    "title": " ",
    "section": "Drop-in (office) hours",
    "text": "Drop-in (office) hours\nOffice hours are an open-ended time for you to go over coursework, clarify concepts, solicit my biased opinions sage wisdom on career planning/graduate school, discuss research/internship opportunities, find resources you need, or chat about life in general. To encourage attendance at office hours, there may be individual and/or collective incentives along the way and/or at the end of the semester, depending on how well you utilize office hours (but please be respectful of your peers and do not monopolize this time).\n\n\n\n\n\n\nFirst time office hours user?\n\n\n\nIf you are nervous about coming to office hours for the first time, I encourage you to come with a friend! (they don’t even have to be enrolled in STAT 155!). You may also find it useful to come prepared with a specific question or topic you would like to discuss (some examples here–and remember, it does not have to be about STAT 155 material!)."
  },
  {
    "objectID": "syllabus.html#preceptors",
    "href": "syllabus.html#preceptors",
    "title": " ",
    "section": "Preceptors",
    "text": "Preceptors\nWe have many preceptors for STAT 155 this semester! You may attend office hours for any of the STAT 155 preceptors, not just those grading/attending my sections. All MSCS courses will also share a dedicated R preceptor (Kyle Suelflow), who can help with any issues you have with your R code or RStudio configuration. The course Moodle site contains detailed information for preceptor office hour times/locations.\nThe role of an MSCS preceptor is to help students with content questions, assist in the navigation of available resources, advise on studying approaches for classes, and assist with concepts, tools, and skills needed for problem sets. Students are accountable for their own learning; as such, preceptors are not allowed to share answers to assignments (unless specifically directed by the instructor), are not expected to immediately know the right approach, or provide assistance outside of office hours. Guidelines and expectations on how to interact with preceptors can be found here.\nIn addition, the Macalester Academic Excellence (MAX) Center provides tutoring for STAT 155. Check out their website for more information and their tutoring schedule."
  },
  {
    "objectID": "syllabus.html#course-grading-system",
    "href": "syllabus.html#course-grading-system",
    "title": " ",
    "section": "Course grading system",
    "text": "Course grading system\nYour overall course grade will consist of three, evenly-weighted components (Quizzes, Practice Problems, and the Project), modified by your Checkpoint Quiz completion.\n\n33% Quizzes\n33% Practice Problems\n33% Project\n\nOverall percentages will correspond to the following letter grades:\n\n\n\nLetter Grade\nOverall Course Percentage\n\n\n\n\nA\n&gt;90%\n\n\nA-\n87-90%\n\n\nB+\n84-87%\n\n\nB\n81-84%\n\n\nB-\n78-81%\n\n\nC+\n75-78%\n\n\nC\n72-75%\n\n\nC-\n69-72%\n\n\nD\n&lt;69%\n\n\n\nNote that I may slightly relax the cutoffs for letter grades on a case-by-case basis, depending on your overall engagement in class, utilization of office hours, demonstrated growth, completion of &gt;80% of Moodle checkpoints, etc.\n\nQuizzes\nThere will be 3 quizzes over the course of the semester.\n\nQuiz 1: Thursday, 2/13. 1 hour in class.\nQuiz 2: Thursday, 3/27. 1 hour in class. Will cover material from the first quiz to some extent because of the way that material in this course builds on earlier ideas.\nQuiz 3: Final exam period. The quiz will be written to take 1.25 hours, but you will have the full two hour period to complete it. Will cover content from the whole course.\nSection 02: Fri. 5/9 8:00am-10:00am\nSection 03: Thurs. 5/8 1:30pm-3:30pm\nSection 04: Sat. 5/10 10:30am-12:30pm\n\nQuiz format:\n\nFully pen/pencil and paper. You will not need to write code or use a calculator, but you will need to be able to read and interpret output from R code.\nYou are allowed to bring a 3x5 index card with notes written on both sides. Typing your notes and pasting them on the card is fine.\n\nShowing growth: You can earn up to 50% of missed points back on quizzes if you submit a quiz correction and reflection. You must:\n\nWrite a reflection of how you prepared for the quiz and where you felt strongest and more uncertain in your understanding before taking the quiz.\nSubmit your quiz corrections along with your reflection to the instructor, no later than one week after quizzes have been handed back.\n\nYou will not have the option to earn points back on the third quiz, due to time constraints at the end of the semester, so I encourage you to make full use of the reflection opportunities on the first two quizzes!\n\n\nPractice problems\nThere will be 8 practice problem sets throughout the course, building off of topics learned in videos/our in-class activities. Practice problems will be due on Wednesdays at 5pm. You are encouraged to work together on practice problems, but the work that you submit, including code, should be your own.\nYou will receive qualitative feedback on all questions on these practice problem sets. Each question (or occasionally, parts of a question) will receive an overall score on the following scale:\n\nHigh pass: 2 points\nPass: 1 point\nNeeds improvement: 0 points\n\nThus, the number of overall points on a given Practice Problem may vary depending on the length of the assignment. Your lowest practice problem score will be dropped from your final grade, so long as you have submitted all 8 practice problems and demonstrated effort on each one.\n\n\nGroup Project\nThe goal of the course project is to apply the data analysis skills from our course to collaboratively investigate a research question in a dataset of your choosing. Through milestones over the course of the semester, you will make steady progress on your projects and iterate on feedback. Full details about the project will be available on the Project page.\n\n\nCheckpoints\nSome class periods will have readings and/or videos assigned ahead of time. For these classes, there will be a short multiple-choice Moodle checkpoint, due by the end of the day. I strongly encourage you to complete the checkpoints before class, but you have the option to complete them after class if you find that doing so helps you review & retain the material better.\nThese short quizzes are designed to ensure that you stay on top of course material, since we move very quickly and much of the content in this course builds on itself.\nCheckpoint quizzes are graded for completion. If you complete 80% of the checkpoint quizzes before the time they are due, your overall course grade will not be negatively affected. If you complete less than 80% of the checkpoint quizzes before the time they are due, your overall course grade will be lowered by 1/3 of a letter grade (i.e. B → B-, A- → B+, etc.)."
  },
  {
    "objectID": "syllabus.html#attendance",
    "href": "syllabus.html#attendance",
    "title": " ",
    "section": "Attendance",
    "text": "Attendance\nAttendance is not (directly) a part of your grade—I recognize that some students may learn more effectively when working through the material independently, and mandating attendance can create a barrier to accessibility. However, because this course is designed to be interactive and community-oriented, regular attendance will likely improve your experience and help you get the most out of the course (remember, that encompasses lots of intangible benefits beyond your final grade!).\nIf you do miss class, I expect you to complete any in-class activities on your own. Check the solutions in the online manual and come to office hours with any follow-up questions."
  },
  {
    "objectID": "syllabus.html#late-work",
    "href": "syllabus.html#late-work",
    "title": " ",
    "section": "Late work",
    "text": "Late work\nThroughout the semester, you may use up to three, three-day extensions. These three extensions can be used on Problem Sets only, not quizzes. The purpose of deadlines (and extensions) are to keep you accountable for your own learning, to keep you on track with the pace of the course (which builds upon itself throughout the semester), and to provide preceptors and myself with the ability to provide you with timely feedback on assignments. Since the Problem Sets are due roughly every two weeks, you must begin working on them early if you want to succeed.\nExtensions can be used automatically, without letting me know in advance. The Moodle dropboxes for assignments will close exactly 3 days after the original deadline (i.e. Saturdays at 5pm), and I will not accept work submitted after that point unless there are extenuating circumstances that you have communicated with me about ahead of the original deadline. If you email me a completed assignment after a 3-day extension is up, I may have the preceptors provide you with feedback, but you will not receive credit for the assignment (equivalent to “Needs Improvement” on every question of the relevant assignment).\nI expect you to keep track of how many extensions you’ve used. I will do my best to email you a reminder if you have used all three of your extensions and have none remaining.\nIf you have run out of extensions and/or an extenuating circumstance occurs that impacts your ability to submit assignments on time, please email me to discuss the situation. I am happy to be flexible as long as you communicate!"
  },
  {
    "objectID": "syllabus.html#religious-observance",
    "href": "syllabus.html#religious-observance",
    "title": " ",
    "section": "Religious Observance",
    "text": "Religious Observance\nStudents may wish to take part in religious observances that occur during the semester. If you have a religious observance/practice that conflicts with your participation in the course, please contact me before the end of the second week of the semester to discuss appropriate accommodations."
  },
  {
    "objectID": "syllabus.html#academic-integrity",
    "href": "syllabus.html#academic-integrity",
    "title": " ",
    "section": "Academic integrity",
    "text": "Academic integrity\nAcademic integrity is the cornerstone of our learning community. Students are expected to be familiar with the college’s standards on academic integrity.\nI encourage you to work with your classmates to discuss material and ideas for assignments, but in order for you to receive individualized feedback on your own learning, you must submit your own work. This involves writing your own code and putting explanations into your own words. Always cite any sources you use, including AI (see section below)."
  },
  {
    "objectID": "syllabus.html#artificial-intelligence-ai-use",
    "href": "syllabus.html#artificial-intelligence-ai-use",
    "title": " ",
    "section": "Artificial Intelligence (AI) Use",
    "text": "Artificial Intelligence (AI) Use\nIn this course, I strongly discourage the use of generative AI tools (ChatGPT, Google Gemini, Claude, etc.), for three main reasons:\n\nWe are learning the essentials of a new language and way of thinking. Learning how to do something the “long” or “hard” way is beneficial not only for developing critical thinking skills, but because that process can be enriching and fulfilling in its own right. Though AI can (sometimes) put access to answers at your fingertips, it cannot replace the physical, sensory, and emotional experience of sketching out ideas on a whiteboard with friends, stopping by your professor’s office for a donut, or the satisfaction of knowing that you can do something hard from scratch.\nI care much more about developing your ability to identify interesting problems, iteratively seek a solution, and convince the world that your solution works than I do about your ability to find answers that are already known (using AI or otherwise). Remember that “generative” AI is only capable of remixing existing information—it cannot create new knowledge, situate that knowledge in the context of your lived experience, or apply that knowledge to instigate change.\nIn this course, I hope to emphasize the importance of process over output. Consider an analogy of a painting class at Macalester. You’re a novice painter, but you have a strong point of view and a solid understanding of context and tradition, so you decide to write an AI prompt to generate the artwork and translate it to physical media. After lots of wordsmithing and iterations on Midjourney, your AI-generated image ready. It’s provocative and beautiful…it will look even better on canvas! You get to work, admiring yourself for finishing faster than your classmates because you knew exactly what your final product would look like. You step back to admire your masterpiece, and realize it’s at best a paint-by-numbers, and at worst, complete garbage because you were so focused on crafting the perfect AI prompt that you didn’t really learn how to mix colors or use different brush techniques.\n\nAll of that being said, I have neither the time nor interest in policing the use of AI tools. If you do choose to use AI, any ideas, language, or code that is produced by AI must be cited, just like any other resource.\n\nHow to cite AI: If you have used AI in any assignment, please include a paragraph at the end explaining what you used the AI for and what prompts you used to get the results. Failure to do so is in violation of the academic integrity policy at Macalester College."
  },
  {
    "objectID": "syllabus.html#well-being",
    "href": "syllabus.html#well-being",
    "title": " ",
    "section": "Well-being",
    "text": "Well-being\nI want you to succeed. Both here at Macalester and beyond. To help make this happen, I am committed to the following.\nRespect: Everyone comes from a different path through life, and it is our moral duty as human beings to listen to each other without judgment and to respect one another. I have no tolerance for discrimination of any kind, in and out of the classroom. If you are seeking campus resources regarding discrimination, the Department of Multicultural Life and the Center for Religious and Spiritual Life are wonderful resources. We will also respect the MSCS Community Guidelines.\nSensitive Topics: Applications in this course span issues in science, policy, and society. As such, we may sometimes address sensitive topics. I will try to announce in class if an assignment or activity involves a potentially sensitive topic. If you have reservations about a particular topic, please come talk to me to discuss possible options.\nAccommodations: If you need accommodations for any reason, please contact Disability Services to discuss your needs, and speak with me as soon as possible afterwards so that we can discuss your accommodation plan. If you already have official accommodations, please discuss these with me within the first week of class so that you get off to a great start. Contact me if you have other special circumstances. I will find resources for you.\nTitle IX: You deserve a community free from discrimination, sexual harassment, hostility, sexual assault, domestic violence, dating violence, and stalking. If you or anyone you know has experienced harassment or discrimination, know that you are not alone. Macalester provides staff and resources to help you find support. Please be aware that as a faculty member, it is my responsibility to report disclosure about sexual harassment, sexual misconduct, relationship violence, and stalking to the Title IX Office. The purpose of this report is to ensure that anyone experiencing harm receives the resources and support they need. I will keep this information private, and it will not be shared beyond this required report.\nYou may also contact Macalester’s Title IX Coordinator directly (phone: 651-696-6258; e-mail: titleixcordinator@macalester.edu); they will provide you with supportive measures, resources, and referrals. Additional information about how to file a report (including anonymously) is available on the Title IX website.\nGeneral Health and Well-being: I care that you prioritize your well-being in this semester and beyond. Investing time into taking care of yourself will have profound impacts on all aspects of your life. Remember that beyond being a student, you are a human being carrying your own experiences, thoughts, emotions, and identities. It is important to acknowledge any stressors you may be facing, which can be mental, emotional, physical, cultural, financial, etc., and how they can have an impact on you. I encourage you to remember that you have a body with needs. In the classroom, eat when you are hungry, drink water, use the restroom, and step out if you are upset and need some air. Please do what is necessary so long as it does not impede your or others’ ability to be mentally and emotionally present in the course. Outside of the classroom, sleeping well, moving your body, and connecting with others can be strategies can help nourish you. If you are having difficulties maintaining your well-being, please don’t hesitate to contact me and/or find support from physical and mental health resources here, here, and here."
  },
  {
    "objectID": "syllabus.html#you-belong-here",
    "href": "syllabus.html#you-belong-here",
    "title": " ",
    "section": "You belong here!",
    "text": "You belong here!\nStatistics–like most other areas of science–has a long history of excluding and exploiting people from marginalized communities and identities. Many of the earliest statisticians in the 19th and 20th centuries used and abused statistics to justify colonialism, ableism, classism, sexism, eugenics, and white supremacy.\nOn top of this problematic history, cultural norms around academic performance in quantitative disciplines can make courses like this one feel intimidating and exclusionary, rather than collaborative and interdisciplinary.\nTo counter these barriers, my central goal as an instructor is to intentionally foster community and connectedness. I believe that your unique voices and perspectives in this class will enrich our collective learning process and, in turn, your college experience. I encourage you to get to know your classmates (and me!) beyond a superficial familiarity and connect over our shared interests, identities, and ideas. You can help cultivate that community by being thoughtful about the way you engage with others and stretching your comfort zone to interact with people who are outside of your established social circles."
  },
  {
    "objectID": "syllabus.html#informed-skepticism",
    "href": "syllabus.html#informed-skepticism",
    "title": " ",
    "section": "Informed skepticism",
    "text": "Informed skepticism\nIn virtually all of contemporary Western science, statistical reasoning is foundational to establishing trust in scientific theories. However, it is shockingly common to encounter “statistically justified” conclusions that are 1) not generalizable or cannot be replicated, 2) invalidated by honest coding/modeling mistakes, 3) based on deliberately cherry-picked models, or–in extreme cases–4) data that have been outright fabricated/falsified. Like in all aspects of life, trust in scientific claims must be earned.\nIn this course and beyond, I encourage you to approach any statistical results you encounter with a healthy skepticism, informed by both your gut intuition and the material you’ve learned. Know that you may be wrong (counter-intuitive results are abundant!) but you should always feel empowered to respectfully and rigorously challenge statistical claims."
  },
  {
    "objectID": "syllabus.html#a-commitment-to-ethical-deliberation-and-conduct",
    "href": "syllabus.html#a-commitment-to-ethical-deliberation-and-conduct",
    "title": " ",
    "section": "A commitment to ethical deliberation and conduct",
    "text": "A commitment to ethical deliberation and conduct\nBecause statistics is a way to make sense of the world around us, it is also a way to influence it. This comes with an inherent responsibility to grapple with the ethical and sociopolitical dimensions of the content in this course. This includes delving into the context of how methods were developed, questioning assumptions, and considering the potential for misuse and misinterpretation. Throughout the course, you will be challenged to consider the broader impact of your work: How might your results and interpretations directly or indirectly affect the environment, specific individuals, or human culture & society? Whose prior scientific contributions are you amplifying or ignoring? How do your assumptions and biases shape your scientific approach and communication?"
  },
  {
    "objectID": "syllabus.html#mistakes-and-uncertainty-are-essential",
    "href": "syllabus.html#mistakes-and-uncertainty-are-essential",
    "title": " ",
    "section": "Mistakes and uncertainty are essential",
    "text": "Mistakes and uncertainty are essential\nI expect that you and I will make lots of mistakes along the way in this course. Perhaps paradoxically, this is an important way to gain confidence: as we make mistakes, we will develop skills for recognizing and correcting them. These skills are vital for succeeding in STEM careers (and life in general). This course will provide a low-stakes environment for us to practice accountability, reflection, and troubleshooting when mistakes occur."
  },
  {
    "objectID": "syllabus.html#context-before-content",
    "href": "syllabus.html#context-before-content",
    "title": " ",
    "section": "Context before content",
    "text": "Context before content\nRigorous statistical reasoning demands that we understand the context of our data and our research questions before we run a model and obtain/interpret results. I also aim to be mindful of various other contexts that shape our learning experience: our individual identities/histories, the classroom environment, the campus climate, etc. Throughout the semester, we will create space to address and discuss whatever contexts might impact our ability to engage the material (and how they may even relate to the material!)."
  },
  {
    "objectID": "activities/05_slr_model_eval.html",
    "href": "activities/05_slr_model_eval.html",
    "title": "05. Simple linear regression: model evaluation",
    "section": "",
    "text": "Download the .qmd file for this activity here.",
    "crumbs": [
      "05. Simple linear regression: model evaluation"
    ]
  },
  {
    "objectID": "activities/05_slr_model_eval.html#learning-goals",
    "href": "activities/05_slr_model_eval.html#learning-goals",
    "title": "05. Simple linear regression: model evaluation",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of this lesson, you should be able to:\n\nUse residual plots to evaluate the correctness of a model\nExplain the rationale for the R-squared metric of model strength\nInterpret the R-squared metric\nThink about ethical implications of modeling by examining the impacts of biased data, power dynamics, the role of categorization, and the role of emotion and lived experience",
    "crumbs": [
      "05. Simple linear regression: model evaluation"
    ]
  },
  {
    "objectID": "activities/05_slr_model_eval.html#readings-and-videos",
    "href": "activities/05_slr_model_eval.html#readings-and-videos",
    "title": "05. Simple linear regression: model evaluation",
    "section": "Readings and videos",
    "text": "Readings and videos\nChoose either the reading or the videos to go through before class.\n\nReading: Sections 1.7, 3.7, and 3.8 in the STAT 155 Notes\n\nNote: You do not need to focus on the “Ladder of Power” in Section 3.8. Transformations in general will be the focus of the next activity we do.\n\nVideos:\n\nModel evaluation: is the model wrong? (slides)\nModel evaluation: is the model strong? (slides)\nModel evaluation: is the model fair? (slides)\nR Code for Evaluating and Using a Linear Model",
    "crumbs": [
      "05. Simple linear regression: model evaluation"
    ]
  },
  {
    "objectID": "activities/05_slr_model_eval.html#independence-assumption",
    "href": "activities/05_slr_model_eval.html#independence-assumption",
    "title": "05. Simple linear regression: model evaluation",
    "section": "Independence Assumption",
    "text": "Independence Assumption\nOne way to think about model evaluation is to consider whether or not underlying assumptions of our regression models are being met (or not). Asking ourselves if our models are “wrong”, “strong”, and “fair” approaches this from one perspective. Another perspective, that is more classical, is to consider the following four assumptions of linear regression:\n\nLinearity\nIndependence\nNormality\nEqual Variance\n\nNote that they spell “LINE” (how convenient!).\nBy assumptions, we mean that the above four “things” are needed mathematically in order for linear regression to “work”. We won’t get into the details of most of these (because it turns out that two of the above assumptions aren’t really needed in most cases… ask your professor for more details), but one important one to note that was not covered in the videos/course notes is the Independence assumption.\nWhat we mean by independence, is that the residuals in our model do not depend on one another. This may seem like an unsatisfying definition, so here are some examples:\n\nSuppose I want to understand the association between a person’s high school GPA and their college GPA. I collect data from every graduating senior, at three different high schools. If I have college GPA as my outcome, and high school GPA as my predictor, are my residuals independent? Probably not! It is reasonable to believe that students from the same high school may have similar GPAs, due to resources their high school may have had available, or specific teachers grading differently at one school or another. This is an example of clustering, where we have clusters of students within schools. The independence assumption of our linear regression model would be violated. One way to address this would be to include which high school they went to as an additional covariate in our regression model (we’ll get to this with multiple linear regression), and more advanced methods are covered in a course on Correlated Data.\nSuppose I want to understand the association between a mouse’s weight and their water consumption across time. I collect data for 365 days for ten different mice, recording their weight and water consumption each day of the year. If I have weight as my predictor and water consumption as my outcome, are my residuals independent? Nope! This is an example of correlated data that is longitudinal in nature: I have multiple observations per individual (mouse) across time. A mouse’s weight one day is certainly not independent of it’s weight the following day. The independence assumption of our linear regression model would again be violated. One way to address this would be to include “Mouse ID” as a predictor in our regression model (again, we’ll get to this with multiple linear regression).\n\nAll types of data that will violate the independence assumption of linear regression will have some sort of correlation structure (within individual, across time, across space, etc.). Think about clusters. If your observations fall neatly into specific clusters, your data may violate the independence assumption of linear regression.\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder.",
    "crumbs": [
      "05. Simple linear regression: model evaluation"
    ]
  },
  {
    "objectID": "activities/05_slr_model_eval.html#exercise-1-is-the-model-correct",
    "href": "activities/05_slr_model_eval.html#exercise-1-is-the-model-correct",
    "title": "05. Simple linear regression: model evaluation",
    "section": "Exercise 1: Is the model correct?",
    "text": "Exercise 1: Is the model correct?\nWe previously explored modeling daily ridership among registered users as a function of temperature. Create a plot of this relationship with both a curved and linear trend line. Based on this plot, do you think a linear model is correct?\n\n# Plot temp_feel vs riders_registered with a model trend\n___(___, aes(x = ___, y = ___)) + \n    geom___() + \n    geom___(se = FALSE) +\n    geom___(method = \"lm\", se = FALSE, color = \"red\")",
    "crumbs": [
      "05. Simple linear regression: model evaluation"
    ]
  },
  {
    "objectID": "activities/05_slr_model_eval.html#exercise-2-fixing-the-model",
    "href": "activities/05_slr_model_eval.html#exercise-2-fixing-the-model",
    "title": "05. Simple linear regression: model evaluation",
    "section": "Exercise 2: Fixing the model",
    "text": "Exercise 2: Fixing the model\nIn this course, we have and will continue to build “linear” regression models. “Linear” means we have a linear combination of predictors. It does not mean that the models themselves must look linear! It’s possible to include “transformations” in our models in order to better match the trend. Below we create a squared version of temperature and visualize the predictions from 2 models: (1) with just temperature as a linear term and (2) with both temperature and squared temperature. (Don’t worry about the new syntax in geom_smooth().)\nHow does the quality (correctness) of the two models compare?\n\nbikes &lt;- bikes %&gt;% \n    mutate(temp_feel_squared = temp_feel^2)\n\n# Plot the model WITHOUT squared temperature\nggplot(bikes, aes(x = temp_feel, y = riders_registered)) + \n    geom_point() + \n    geom_smooth(se = FALSE) +\n    geom_smooth(method = \"lm\", se = FALSE, color = \"red\")\n# Plot the model WITH squared temperature\nggplot(bikes, aes(x = temp_feel, y = riders_registered)) + \n    geom_point() + \n    geom_smooth(se = FALSE) +\n    geom_smooth(method = \"lm\", formula = y ~ x + I(x^2), se = FALSE, color = \"red\")",
    "crumbs": [
      "05. Simple linear regression: model evaluation"
    ]
  },
  {
    "objectID": "activities/05_slr_model_eval.html#exercise-3-residual-plots",
    "href": "activities/05_slr_model_eval.html#exercise-3-residual-plots",
    "title": "05. Simple linear regression: model evaluation",
    "section": "Exercise 3: Residual plots",
    "text": "Exercise 3: Residual plots\nPlotting the residuals vs the predictions (also called “fitted values”) for each case can help us assess how wrong our model is. This will be a particularly important tool when evaluating models with multiple predictors. Construct the residual plots for our two temperature models. Do these suggest that bike_mod1 is wrong? What about bike_mod2? Explain.\nNote: Information about the residuals (.resid) and predictions (.fitted) are stored within our model, thus we start our ggplot() with the model name as opposed to the raw dataset. We will rarely start ggplot() with a model instead of the data.\n\n# Fit a linear model\nbike_mod1 &lt;- lm(riders_registered ~ temp_feel, data = bikes)\n# Fit a quadratic model\nbike_mod2 &lt;- lm(riders_registered ~ temp_feel + temp_feel_squared, data = bikes)\n\n# Check out the residual plot for bike_mod1 (the incorrect model)\nggplot(bike_mod1, aes(x = .fitted, y = .resid)) + \n    geom_point() + \n    geom_hline(yintercept = 0) +\n    geom_smooth(se = FALSE)\n\n# Construct the residual plot for bike_mod2 (the good model)",
    "crumbs": [
      "05. Simple linear regression: model evaluation"
    ]
  },
  {
    "objectID": "activities/05_slr_model_eval.html#exercise-4-another-example-of-an-incorrect-model",
    "href": "activities/05_slr_model_eval.html#exercise-4-another-example-of-an-incorrect-model",
    "title": "05. Simple linear regression: model evaluation",
    "section": "Exercise 4: Another example of an incorrect model",
    "text": "Exercise 4: Another example of an incorrect model\nThe Bechdel test is a test applied to films to assess the quality of women’s presence in the film. We’ll be looking at movies that have had the Bechdel test applied available in the fivethirtyeight R package. In the Console, enter install.packages(\"fivethirtyeight\") to install this package.\nWe’ll be using the bechdel data. You can view the codebook by entering ?bechdel in the Console.\nLet’s examine the relationship between international earnings (intgross) and movie budget (budget) for films made in 1997.\n\n# Import the data\nlibrary(fivethirtyeight)\ndata(bechdel)\n\n# Get only 1997 movies\nmovies_1997 &lt;- bechdel %&gt;% \n    filter(year == 1997)\n\n# Construct the model\nbechdel_model &lt;- lm(intgross ~ budget, movies_1997)\n\n\nConstruct two plots:\n\n\n# Scatterplot of earnings and budget with linear and curved trend lines\n\n\n# Residual plot for bechdel_model\n\n\nThese two plots confirm that our model is wrong. What is wrong and how might we fix it?\nIdentify which movie is causing the problem. Hint: filter() according to budget. Also, note that we could, but won’t, take that film out of the data set and re-build the model.\n\n\n# NOTE: Many numbers could go in the ___\nmovies_1997 %&gt;%\n    filter(budget &gt; ___)",
    "crumbs": [
      "05. Simple linear regression: model evaluation"
    ]
  },
  {
    "objectID": "activities/05_slr_model_eval.html#exercise-5-is-the-model-strong-developing-r-squared-intuition",
    "href": "activities/05_slr_model_eval.html#exercise-5-is-the-model-strong-developing-r-squared-intuition",
    "title": "05. Simple linear regression: model evaluation",
    "section": "Exercise 5: Is the model strong? Developing R-squared intuition",
    "text": "Exercise 5: Is the model strong? Developing R-squared intuition\nThe R-squared metric is a way to quantify the strength of a model. It measures how much variation in the outcome/response variable can be explained by the variation in the predictors.\nWhere does R-squared come from? Well, it turns out that we can partition the variance of the observed response values into the variability that’s explained by the model (the variance of the predictions) and the variability that’s left unexplained by the model (the variance of the residuals):\n\\[\\text{Var(observed) = Var(predicted) + Var(residuals)}\\]\nStrong models have residuals that don’t deviate far from 0. So the smaller the variance in the residuals (thus larger the variance in the predictions), the stronger the model. Take a look at the picture below and write a few sentences addressing the following:\n\nThe two rows of plots show a stronger and a weaker model. Just by looking at the blue trend line and the dispersion of the points about the line, which row corresponds to the stronger model? How can you tell? Which row would you expect to have a higher correlation?\nWhat is different about the variance of the residuals from the first to the second row?\n\n\nPutting this together, the R-squared compares Var(predicted) to Var(response):\n\\[R^2 = \\frac{\\text{variance of predicted values}}{\\text{variance of observed response values}} = 1 - \\frac{\\text{variance of residuals}}{\\text{variance of observed response values}}\\] ::: {.callout-note collapse=“true”} ## R-squared\n\\[\nR^2 = 1 - \\frac{SSE}{SSTO} = 1 - \\frac{\\sum (y_i - \\hat{y}_i)^2}{\\sum (y_i - \\bar{y})^2}\n\\] where \\(y_i\\) are our observed outcomes, \\(i = 1, \\dots, n\\), \\(\\hat{y}_i\\) are our fitted values/predictions, and \\(\\bar{y}\\) is our observed average outcome. :::",
    "crumbs": [
      "05. Simple linear regression: model evaluation"
    ]
  },
  {
    "objectID": "activities/05_slr_model_eval.html#exercise-6-r-squared-interpretations",
    "href": "activities/05_slr_model_eval.html#exercise-6-r-squared-interpretations",
    "title": "05. Simple linear regression: model evaluation",
    "section": "Exercise 6: R-squared Interpretations",
    "text": "Exercise 6: R-squared Interpretations\nRecall bikemod1 from Exercise 3, where we predicted registered riders by what the temperature felt like on a given day. Use the summary function to look out the model output for bikemod1, and interpret the \\(R^2\\) value for this model, in the context of the problem. (NOTE: \\(R^2\\) is reported in output here as “Multiple R-squared”).\n\n# Get R-squared\nsummary(bike_mod1)",
    "crumbs": [
      "05. Simple linear regression: model evaluation"
    ]
  },
  {
    "objectID": "activities/05_slr_model_eval.html#exercise-7-further-exploring-r-squared",
    "href": "activities/05_slr_model_eval.html#exercise-7-further-exploring-r-squared",
    "title": "05. Simple linear regression: model evaluation",
    "section": "Exercise 7: Further exploring R-squared",
    "text": "Exercise 7: Further exploring R-squared\nIn this exercise, we’ll look at data from a synthetic dataset called Anscombe’s quartet. Load the data in as follows, and look at the first few rows:\n\ndata(anscombe)\n\n# Look at the first few rows\n\nThe anscombe data is actually 4 datasets in one: x1 and y1 go together, and so forth. Examine the coefficient estimates (in the “Estimate” column of the “Coefficients:” part) and the “Multiple R-squared” value on the second to last line. What do you notice? How do these models compare?\n\nanscombe_mod1 &lt;- lm(y1 ~ x1, data = anscombe)\nanscombe_mod2 &lt;- lm(y2 ~ x2, data = anscombe)\nanscombe_mod3 &lt;- lm(y3 ~ x3, data = anscombe)\nanscombe_mod4 &lt;- lm(y4 ~ x4, data = anscombe)\n\nsummary(anscombe_mod1)\nsummary(anscombe_mod2)\nsummary(anscombe_mod3)\nsummary(anscombe_mod4)\n\nNow take a look at the following scatterplots of the 4 pairs of variables. What do you notice? What takeaway can we draw from this exercise?\n\nggplot(anscombe, aes(x = x1, y = y1)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\nggplot(anscombe, aes(x = x2, y = y2)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\nggplot(anscombe, aes(x = x3, y = y3)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\nggplot(anscombe, aes(x = x4, y = y4)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)",
    "crumbs": [
      "05. Simple linear regression: model evaluation"
    ]
  },
  {
    "objectID": "activities/05_slr_model_eval.html#exercise-8-biased-data-biased-results-example-1",
    "href": "activities/05_slr_model_eval.html#exercise-8-biased-data-biased-results-example-1",
    "title": "05. Simple linear regression: model evaluation",
    "section": "Exercise 8: Biased data, biased results: example 1",
    "text": "Exercise 8: Biased data, biased results: example 1\nDATA ARE NOT NEUTRAL. Data can reflect personal biases, institutional biases, power dynamics, societal biases, the limits of our knowledge, and so on. In turn, biased data can lead to biased analyses. Consider an example.\n\nDo a Google image search for “statistics professor.” What do you observe?\nThese search results are produced by a search algorithm / model. Explain why the data used by this model are not neutral.\nWhat are the potential implications, personal or societal, of the search results produced from this biased data?",
    "crumbs": [
      "05. Simple linear regression: model evaluation"
    ]
  },
  {
    "objectID": "activities/05_slr_model_eval.html#exercise-9-biased-data-biased-results-example-2",
    "href": "activities/05_slr_model_eval.html#exercise-9-biased-data-biased-results-example-2",
    "title": "05. Simple linear regression: model evaluation",
    "section": "Exercise 9: Biased data, biased results: example 2",
    "text": "Exercise 9: Biased data, biased results: example 2\nConsider the example of a large company that developed a model / algorithm to review the résumés of applicants for software developer & other tech positions. The model then gave each applicant a score indicating their hireability or potential for success at the company. You can think of this model as something like:\n\\[\\text{potential for success } = \\beta_0 + \\beta_1 (\\text{features from the résumé})\\]\nSkim this Reuter’s article about the company’s résumé model.\n\nExplain why the data used by this model are not neutral.\nWhat are the potential implications, personal or societal, of the results produced from this biased data?",
    "crumbs": [
      "05. Simple linear regression: model evaluation"
    ]
  },
  {
    "objectID": "activities/05_slr_model_eval.html#exercise-10-rigid-data-collection-systems",
    "href": "activities/05_slr_model_eval.html#exercise-10-rigid-data-collection-systems",
    "title": "05. Simple linear regression: model evaluation",
    "section": "Exercise 10: Rigid data collection systems",
    "text": "Exercise 10: Rigid data collection systems\nWhen working with categorical variables, we’ve seen that our units of observation fall into neat groups. Reality isn’t so discrete. For example, check out questions 6 and 9 on page 2 of the 2020 US Census. With your group, discuss the following:\n\nWhat are a couple of issues you see with these questions?\nWhat impact might this type of data collection have on a subsequent analysis of the census responses and the policies it might inform?\nCan you think of a better way to write these questions while still preserving the privacy of respondents?\n\nFOR A DEEPER DISCUSSION: Read Chapter 4 of Data Feminism on “What gets counted counts”.",
    "crumbs": [
      "05. Simple linear regression: model evaluation"
    ]
  },
  {
    "objectID": "activities/05_slr_model_eval.html#exercise-11-presenting-data-elevating-emotion-and-embodiment",
    "href": "activities/05_slr_model_eval.html#exercise-11-presenting-data-elevating-emotion-and-embodiment",
    "title": "05. Simple linear regression: model evaluation",
    "section": "Exercise 11: Presenting data: “Elevating emotion and embodiment”",
    "text": "Exercise 11: Presenting data: “Elevating emotion and embodiment”\nNote: The following example highlights work done by W.E.B. Du Bois in the late 1800s / early 1900s. His work uses language common to that time period and addresses the topic of slavery.\nThe types of visualizations we’ve been learning in this course are standard practice, hence widely understood. Yet these standard visualizations can also suppress the lived experiences of people represented in the data, hence can miss the larger point. W.E.B. Du Bois (1868–1963), a “sociologist, socialist, historian, civil rights activist, Pan-Africanist, author, writer, and editor”1, was a pioneer in elevating emotion and embodiment in data visualization. For the Paris World Fair of 1900, Du Bois and his team of students from Atlanta University presented 60 data visualizations of the Black experience in America, less than 50 years after the abolishment of slavery. To this end, Du Bois noted that “I wanted to set down its aim and method in some outstanding way which would bring my work to notice by the thinking world.” That is, he wanted to increase the impact of his work by partnering technical visualizations with design that better connects to lived experiences. Check out:\n\nAn article by Allen Hillery (@AlDatavizguy).\nA complete set of the data visualizations provided by Anthony Starks (@ajstarks).\n\nDiscuss your observations. In what ways do you think the W.E.B. Du Bois visualizations might have been more effective at sharing his work than, say, plainer bar charts?\nFOR A DEEPER DISCUSSION AND MORE MODERN EXAMPLES: Read Chapter 3 of Data Feminism on the principle of elevating emotion and embodiment, i.e. the value of “multiple forms of knowledge, including the knowledge that comes from people as living, feeling bodies in the world.”",
    "crumbs": [
      "05. Simple linear regression: model evaluation"
    ]
  },
  {
    "objectID": "activities/05_slr_model_eval.html#reflection",
    "href": "activities/05_slr_model_eval.html#reflection",
    "title": "05. Simple linear regression: model evaluation",
    "section": "Reflection",
    "text": "Reflection\nWhat has stuck with you most in our exploration of model evaluation? Why\n\nResponse: Put your response here.",
    "crumbs": [
      "05. Simple linear regression: model evaluation"
    ]
  },
  {
    "objectID": "activities/05_slr_model_eval.html#render-your-work",
    "href": "activities/05_slr_model_eval.html#render-your-work",
    "title": "05. Simple linear regression: model evaluation",
    "section": "Render your work",
    "text": "Render your work\n\nClick the “Render” button in the menu bar for this pane (blue arrow pointing right). This will create an HTML file containing all of the directions, code, and responses from this activity. A preview of the HTML will appear in the browser.\nScroll through and inspect the document to check that your work translated to the HTML format correctly.\nClose the browser tab.\nGo to the “Background Jobs” pane in RStudio and click the Stop button to end the rendering process.\nNavigate to your “Activities” subfolder within your “STAT155” folder and locate the HTML file. You can open it again in your browser to double check.\n\n\nSolutions",
    "crumbs": [
      "05. Simple linear regression: model evaluation"
    ]
  },
  {
    "objectID": "activities/05_slr_model_eval.html#footnotes",
    "href": "activities/05_slr_model_eval.html#footnotes",
    "title": "05. Simple linear regression: model evaluation",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhttps://en.wikipedia.org/wiki/W._E._B._Du_Bois↩︎",
    "crumbs": [
      "05. Simple linear regression: model evaluation"
    ]
  },
  {
    "objectID": "activities/06_slr_transformations.html",
    "href": "activities/06_slr_transformations.html",
    "title": "06. Simple linear regression: Transformations",
    "section": "",
    "text": "Download the .qmd file for this activity here.",
    "crumbs": [
      "06. Simple linear regression: Transformations"
    ]
  },
  {
    "objectID": "activities/06_slr_transformations.html#learning-goals",
    "href": "activities/06_slr_transformations.html#learning-goals",
    "title": "06. Simple linear regression: Transformations",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of this lesson, you should be able to:\n\nDistinguish between the different motivations for transformations of variables (interpretation, regression assumptions, etc.)\nDetermine when a particular transformation (center, scale, or log) may be appropriate\nInterpret regression coefficients after a transformation has taken place",
    "crumbs": [
      "06. Simple linear regression: Transformations"
    ]
  },
  {
    "objectID": "activities/06_slr_transformations.html#readings-and-videos",
    "href": "activities/06_slr_transformations.html#readings-and-videos",
    "title": "06. Simple linear regression: Transformations",
    "section": "Readings and videos",
    "text": "Readings and videos\nPlease watch the following video before class.\n\nVideo: Simple Linear Regression: Transformations\n\nThe following reading is optional.\n\nSection 3.8.4 in the STAT 155 Notes covers log transformations, and the “ladder of power,” which we will not cover in class.\n\n\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder.",
    "crumbs": [
      "06. Simple linear regression: Transformations"
    ]
  },
  {
    "objectID": "activities/06_slr_transformations.html#exercise-1-location-transformations",
    "href": "activities/06_slr_transformations.html#exercise-1-location-transformations",
    "title": "06. Simple linear regression: Transformations",
    "section": "Exercise 1: Location transformations",
    "text": "Exercise 1: Location transformations\nLocation transformations are ones that shift a predictor variable up or down by a fixed amount. Using a location transformation is sometimes also called centering a predictor.\nWe’ll use the homes data in this exercise.\n\nFit a linear regression model of Price as a function of Living.Area, and call this model home_mod.\n\n\n# Fit the model\n\n\n# Display model summary output\n\n\nInterpret the intercept and the coefficient for Living.Area. Is the interpretation of the intercept meaningful?\nWe can use a location transformation on Living.Area to “start” it at a more reasonable value. We can see from the summarize() code below that the smallest house is 616 quare feet, so let’s center this predictor at 600 square feet. There is no code to fill in here, but make note of the mutate() syntax.\n\n\nhomes %&gt;% \n    summarize(min(Living.Area))\n\n# What is mutate() doing???\nhomes &lt;- homes %&gt;%\n    mutate(Living.Area.Shifted = Living.Area-600)\n\n\nWe can actually determine the coefficients of the Price ~ Living.Area.Shifted model by hand.\n\nFirst, write out in general terms (without specific numbers) how we would interpret the intercept and slope in this model.\nUse these general interpretations as well as the summary output of home_mod to determine what these new coefficients should be.\n\nNow check your answer to part d by fitting the model.\n\n\n# Fit a model of Price vs. Living.Area.Shifted\n\n\n# Display model summary output",
    "crumbs": [
      "06. Simple linear regression: Transformations"
    ]
  },
  {
    "objectID": "activities/06_slr_transformations.html#exercise-2-scale-transformations",
    "href": "activities/06_slr_transformations.html#exercise-2-scale-transformations",
    "title": "06. Simple linear regression: Transformations",
    "section": "Exercise 2: Scale transformations",
    "text": "Exercise 2: Scale transformations\nIn this exercise, we’ll explore the relationship between four-year graduation rate and admissions rate of colleges.\nIn the code chunk below, construct a visualization comparing graduation rate (our outcome variable) and admissions rate (our predictor of interest). Remember that your outcome variable should be on the y-axis, in general!\n\n# Scatterplot of graduation rate vs. admissions rate\n\n\nDescribe the relationship you observe between the two quantitative variables, in terms of correlation (weak/strong, positive/negative). Does the relationship appear to be roughly linear?\nWrite a linear regression model formula of the form E[Y | X] = … (filling in Y and X appropriately).\nFit this model in R, and report (don’t interpret yet!) the slope coefficient and intercept coefficient estimates.\n\n\n# Linear regression model with GradRate as the outcome, AdmisRate as predictor of interest\n\n\nIntercept Estimate: Your response here\n\n\nSlope Estimate: Your response here\n\n\nConsidering the units of AdmisRate, what does it mean for AdmisRate to change by one unit? What are the units for AdmisRate (and GradRate, for that matter!)?\nSuppose I want the interpretation of my slope coefficient for AdmisRate in my linear model to be in terms a “1% increase in admissions rate.” To achieve this, we could mutate our AdmisRate variable to range from 0 to 100. Let’s do that for GradRate too (just because!):\n\n\n# Mutate\ncollege &lt;- college %&gt;%\n  mutate(AdmisRate = AdmisRate * ___,\n         GradRate = ___ * ___)\n\n\nFit a new linear regression model with the updated AdmisRate and GradRate variables as your predictor of interest and outcome, respectively. Again, report the intercept and slope estimate from your model.\n\n\n# Linear regression model with updated GradRate as the outcome, updated AdmisRate as predictor of interest\n\n\nIntercept Estimate: Your response here\n\n\nSlope Estimate: Your response here\n\nHow have your intercept and slope estimates changed from the previous model, if at all?\n\nInterpret the regression coefficient that corresponds to the estimated linear relationship between admissions and graduation rates, in the context of the problem. Make sure to use non-causal language, include units, and talk about averages rather than individual cases.",
    "crumbs": [
      "06. Simple linear regression: Transformations"
    ]
  },
  {
    "objectID": "activities/06_slr_transformations.html#exercise-3-log-transformations",
    "href": "activities/06_slr_transformations.html#exercise-3-log-transformations",
    "title": "06. Simple linear regression: Transformations",
    "section": "Exercise 3: Log transformations",
    "text": "Exercise 3: Log transformations\nThe Big Mac Index has been published by The Economist since 1986 as a metric for comparing purchasing power between countries, giving rise to the phrase Burgernomics. It was developed (sort of jokingly) as a way to explain exchange rates in digestible terms.\nAs an example, suppose a Big Mac in Switzerland costs 6.70 Swiss franc, and in the U.S. a Big Mac costs 5.58 USD. Then the Big Mac Index is 6.70/5.58 = 1.20, and is the implied exchange rate between Swiss franc and USD.\nIf you’d like to read more about the Big Mac index, here’s an article in The Economist (this may be behind a pay-wall for you, you can read up to 5 free articles in the Economist per month).\nFor this exercise, we’ll explore the relationship between average teaching salary in a country and the amount of time someone needs to work to be able to afford a Big Mac. The variables we’ll consider are:\n\nbigmac_mins: average minutes to earn 1 Big Mac\ngross_annual_teacher_income: average gross teacher salary in 1 year (USD)\n\n\nCreate an appropriate visualization that displays the relationship between average minutes to earn a Big Mac and gross annual, average teaching salary, and describe what you observe.\n\n\n# Visualization: Big Mac minutes vs. gross annual teacher income\n\n\nExplain why correlation might not be an appropriate numerical summary for the relationship between the two variables you plotted above.\nFit a linear regression model with bigmac_mins as the outcome and gross_annual_teacher_income as the predictor of interest, and interpret the coefficient for gross_annual_teacher_income, in context. Make sure to use non-causal language, include units, and talk about averages rather than individual cases.\n\n\n# Linear regression code\n\n\nPlot residuals vs. fitted values for the model you fit, and describe what you observe. Are there any noticeable patterns in the residuals? Describe them!\n\n\n# Residuals vs. fitted values plot\n\n\nFor which observations do the residuals from the linear regression model appear to be relatively large (i.e. for which observations would predictions fall farthest from observed outcomes)? What possible consequences would this have for people using this model to predict the amount of time it takes for them to earn enough money to afford a Big Mac?\n\nWe’ll now consider a log transformation of teaching salary. In the code chunk below, create a new variable called log_sal that contains the logged values of gross_annual_teacher_income.\n\n# Creating new variable log_sal\nbigmac &lt;- bigmac %&gt;%\n  mutate(log_sal = log(___))\n\n\nCreate an appropriate visualization that displays the relationship between average minutes to earn a Big Mac and logged gross annual, average teaching salary, and describe what you observe. Does correlation seem like it may be an appropriate numerical summary for the relationship between these two variables? Explain why or why not.\nFit a linear regression model with bigmac_mins as the outcome and log_sal as the predictor of interest, and interpret the coefficient for log_sal, in context. Make sure to use non-causal language, include units, and talk about averages rather than individual cases.\nPlot residuals vs. fitted values for the model you fit, and describe what you observe. Are there any noticeable patterns in the residuals? Describe them!\n\n\n# Residuals vs. fitted values plot",
    "crumbs": [
      "06. Simple linear regression: Transformations"
    ]
  },
  {
    "objectID": "activities/06_slr_transformations.html#reflection",
    "href": "activities/06_slr_transformations.html#reflection",
    "title": "06. Simple linear regression: Transformations",
    "section": "Reflection",
    "text": "Reflection\nTwo of the main motivations for transforming variables in our regression models is to (1) intentionally change the interpretation of regression coefficients, and (2) to better satisfy linear regression assumptions (e.g. remove “patterns” from our residual plots). The first is nearly always justified by the scientific context of the research questions you are trying to answer, while the second is a bit more muddy.\nThink about the pros and cons of transforming your variables to satisfy linear regression assumptions. Is there a limit to how much you would be willing to transform your variables? Would transforming too much leave you with un-interpretable regression coefficients?\n\nResponse: Put your response here.\n\n\nSolutions",
    "crumbs": [
      "06. Simple linear regression: Transformations"
    ]
  },
  {
    "objectID": "solutions/06_slr_transformations.html",
    "href": "solutions/06_slr_transformations.html",
    "title": "Solutions for 06. Simple linear regression: Transformations",
    "section": "",
    "text": "# Load packages and import data\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(dplyr)\n\nhomes &lt;- read_csv(\"https://mac-stat.github.io/data/homes.csv\")\n\nbigmac &lt;- read_csv(\"https://mac-stat.github.io/data/bigmac.csv\")\n\ncollege &lt;- read_csv(\"https://mac-stat.github.io/data/college.csv\")"
  },
  {
    "objectID": "solutions/06_slr_transformations.html#exercise-1-location-transformations",
    "href": "solutions/06_slr_transformations.html#exercise-1-location-transformations",
    "title": "Solutions for 06. Simple linear regression: Transformations",
    "section": "Exercise 1: Location transformations",
    "text": "Exercise 1: Location transformations\nLocation transformations are ones that shift a predictor variable up or down by a fixed amount. Using a location transformation is sometimes also called centering a predictor.\nWe’ll use the homes data in this exercise.\n\nFit a linear regression model of Price as a function of Living.Area, and call this model home_mod.\n\n\n# Fit the model\nhome_mod &lt;- lm(Price ~ Living.Area, data = homes)\n\n# Display model summary output\ncoef(summary(home_mod))\n\n              Estimate  Std. Error   t value      Pr(&gt;|t|)\n(Intercept) 13439.3940 4992.352849  2.691996  7.171207e-03\nLiving.Area   113.1225    2.682341 42.173065 9.486240e-268\n\n\n\n\nInterpretation of slope: Every 1 square foot increase in living area is associated with an expected / average increase in house price of $113.12.\nInterpretation of intercept: The average/expected house price for a house with zero square feet is $13,439.39. Can a house ever be zero square feet??? Nope! The intercept is meaningless in this case.\n\n\n\n\nhomes %&gt;% \n    summarize(min(Living.Area))\n\n# A tibble: 1 × 1\n  `min(Living.Area)`\n               &lt;dbl&gt;\n1                616\n\n# mutate() creates a new variable called Living.Area.Shifted that is equal to Living.Area - 600\nhomes &lt;- homes %&gt;%\n    mutate(Living.Area.Shifted = Living.Area-600)\n\n\n\nIn general terms, the intercept in this model should represent the average house price when Living.Area.Shifted is 0—in other words when Living.Area is 600 square feet. From the coefficient estimates in home_mod, we can calculate the expected / predicted house price for 600 square foot homes: 13439.394 + (113.123*600) = 81312.89. So we’re expecting the new intercept to be $81312.89.\nThe slope in this model represents the average price change for each unit change in Living.Area.Shifted (which is the same as a unit change in Living.Area). Based on this, the slope should be the same as in home_mod ($113.12 per square foot).\n\nLines up with work in part d!\n\n\n# Fit a model of Price vs. Living.Area.Shifted\nhome_mod_centered &lt;- lm(Price ~ Living.Area.Shifted, data = homes)\n\n# Display model summary output\ncoef(summary(home_mod_centered))\n\n                      Estimate  Std. Error  t value      Pr(&gt;|t|)\n(Intercept)         81312.9191 3515.879467 23.12733 2.638371e-103\nLiving.Area.Shifted   113.1225    2.682341 42.17307 9.486240e-268"
  },
  {
    "objectID": "solutions/06_slr_transformations.html#exercise-2-scale-transformations",
    "href": "solutions/06_slr_transformations.html#exercise-2-scale-transformations",
    "title": "Solutions for 06. Simple linear regression: Transformations",
    "section": "Exercise 2: Scale transformations",
    "text": "Exercise 2: Scale transformations\nIn the code chunk below, construct a visualization comparing graduation rate (our outcome variable) and admissions rate (our predictor of interest). Remember that your outcome variable should be on the y-axis, in general!\n\n# Scatterplot of graduation rate vs. admissions rate\ncollege %&gt;%\n  ggplot(aes(x = AdmisRate, y = GradRate)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nThe correlation between admissions and graduation rates appears to be weakly negative. Notably, there are hard boundaries to admissions and graduation rates, since both must fall between 0 and 100%! A few colleges hit up against these boundaries. I would say that, with the exception of the observations that have either 0% graduation rates or 0% admission rates, the relationship does appear to be roughly linear.\nE[GradRate | AdmisRate] = \\(\\beta_0\\) + \\(\\beta_1\\) AdmisRate\n\n\n\n# Linear regression model with GradRate as the outcome, AdmisRate as predictor of interest\nmod &lt;- lm(GradRate ~ AdmisRate, data = college)\nsummary(mod)\n\n\nCall:\nlm(formula = GradRate ~ AdmisRate, data = college)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.68409 -0.13681  0.01296  0.15550  0.66204 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.68409    0.01759   38.89   &lt;2e-16 ***\nAdmisRate   -0.34613    0.02330  -14.85   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2088 on 1649 degrees of freedom\nMultiple R-squared:  0.118, Adjusted R-squared:  0.1175 \nF-statistic: 220.6 on 1 and 1649 DF,  p-value: &lt; 2.2e-16\n\n\n\nIntercept Estimate: 0.68409\n\n\nSlope Estimate: -0.34613\n\n\nOne unit of AdmisRate corresponds to a 100% change in admissions rates! The same goes for graduation rate. This is a huge change (in fact, the largest change possible).\nSuppose I want the interpretation of my slope coefficient for AdmisRate in my linear model to be in terms a “1% increase in admissions rate.” To achieve this, we could mutate our AdmisRate variable to range from 0 to 100. Let’s do that for GradRate too (just because!):\n\n\n# Mutate\ncollege &lt;- college %&gt;%\n  mutate(AdmisRate = AdmisRate * 100,\n         GradRate = GradRate * 100)\n\n\nFit a new linear regression model with the updated AdmisRate and GradRate variables as your predictor of interest and outcome, respectively. Again, report the intercept and slope estimate from your model.\n\n\n# Linear regression model with updated GradRate as the outcome, updated AdmisRate as predictor of interest\nmod_new &lt;- lm(GradRate ~ AdmisRate, data = college)\nsummary(mod_new)\n\n\nCall:\nlm(formula = GradRate ~ AdmisRate, data = college)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-68.409 -13.681   1.296  15.550  66.204 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  68.4088     1.7592   38.89   &lt;2e-16 ***\nAdmisRate    -0.3461     0.0233  -14.85   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 20.88 on 1649 degrees of freedom\nMultiple R-squared:  0.118, Adjusted R-squared:  0.1175 \nF-statistic: 220.6 on 1 and 1649 DF,  p-value: &lt; 2.2e-16\n\n\n\nIntercept Estimate: 68.4088\n\n\nSlope Estimate: -0.3461\n\nOur intercept estimate is now 100x larger, and our slope estimate has remained the same! The slope remained the same because we multiplied our outcome and our predictor of interest by the same value, and the intercept is 100x larger because we multiplied our outcome by 100 (recall that the intercept is the average expected outcome when “x” is zero).\n\nOn average, we expect colleges that differ in admissions rate by 1% to have 0.35% different graduation rates, with colleges with higher admissions rates having lower graduation rates."
  },
  {
    "objectID": "solutions/06_slr_transformations.html#exercise-3-log-transformations",
    "href": "solutions/06_slr_transformations.html#exercise-3-log-transformations",
    "title": "Solutions for 06. Simple linear regression: Transformations",
    "section": "Exercise 3: Log transformations",
    "text": "Exercise 3: Log transformations\n\n\n\n\n# Visualization: Big Mac minutes vs. gross annual teacher income\nbigmac %&gt;%\n  ggplot(aes(x = gross_annual_teacher_income, y = bigmac_mins)) +\n  geom_point() \n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nAs annual teacher income gets higher, time it takes in minutes to earn a Big Mac decreases, though the relationship does not appear linear. The amount of time it takes to earn a Big Mac is very high when income is below about 10,000 where it sharply decreases, and then decreases at a much lower rate when income is above around 20,000.\n\nCorrelation is a summary of the linear relationship between two quantitative variables, and this relationship does not appear to be linear!\n\n\n\n# Linear regression code\nmod &lt;- lm(bigmac_mins ~ gross_annual_teacher_income, data = bigmac)\nsummary(mod)\n\n\nCall:\nlm(formula = bigmac_mins ~ gross_annual_teacher_income, data = bigmac)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-29.649  -9.556  -1.784   4.512  43.715 \n\nCoefficients:\n                              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                  5.801e+01  3.104e+00   18.69  &lt; 2e-16 ***\ngross_annual_teacher_income -9.092e-04  9.591e-05   -9.48 6.16e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15.4 on 66 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.5766,    Adjusted R-squared:  0.5701 \nF-statistic: 89.86 on 1 and 66 DF,  p-value: 6.164e-14\n\n\nOn average, we expect a one dollar increase in gross annual teacher income to be associated with a decrease in the number of minutes it takes to earn a Big Mac by 9 x 10^(-4) minutes. Stated differently, we expect a ten-thousand dollar increase in gross annual teacher income to be associated with a decrease in the number of minutes it takes to earn a Big Mac by 9 minutes (note that here I did a scale transformation of gross annual teacher income to get this interpretation, which might make more sense when looking at the scale of salary!).\n\n\n\n\n# Residuals vs. fitted values plot\nggplot(mod, aes(x = .fitted, y = .resid)) + \n    geom_point() + \n    geom_hline(yintercept = 0) +\n    geom_smooth(se = FALSE)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThe residuals vs. fitted values plot shows a very clear, nonlinear pattern! As fitted values increase, residuals decrease for a while, and then sharply increase once fitted values are higher than around 40 minutes. The spread of residuals around zero also varies, with greater spread for higher fitted values.\n\nThe residuals appear to be large for people with negative fitted values and those with very high fitted values. Recall that a linear model does not “know” that number of minutes to earn a Big Mac can’t be negative, in context. If we look at the fitted line from our linear model on a scatterplot (see below)…\n\n\nbigmac %&gt;%\n  ggplot(aes(x = gross_annual_teacher_income, y = bigmac_mins)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nWe observe that negative fitted values and very large fitted values occur when annual teacher income is greater than around 70,000 and less than 10,000, respectively. This implies that the model does a worse job at predicting the number of minutes to earn a Big Mac in countries where annual teacher income is either very high or very low.\nWe’ll now consider a log transformation of teaching salary. In the code chunk below, create a new variable called log_sal that contains the logged values of gross_annual_teacher_income.\n\n# Creating new variable log_sal\nbigmac &lt;- bigmac %&gt;%\n  mutate(log_sal = log(gross_annual_teacher_income))\n\n\n\n\n\nbigmac %&gt;%\n  ggplot(aes(log_sal, bigmac_mins)) +\n  geom_point()\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nThe relationship between logged annual teaching salary and minutes to earn a Big Mac appears roughly linear, with a weakly negative relationship. Correlation is likely an appropriate numerical summary for the relationship between these two quantitative variables, as the relationship is roughly linear!\n\n\n\n\nmod_log &lt;- lm(bigmac_mins ~ log_sal, data = bigmac)\nsummary(mod_log)\n\n\nCall:\nlm(formula = bigmac_mins ~ log_sal, data = bigmac)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-36.817  -6.951  -1.241   6.032  41.357 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  210.875     14.687   14.36   &lt;2e-16 ***\nlog_sal      -18.142      1.502  -12.08   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 13.21 on 66 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.6886,    Adjusted R-squared:  0.6838 \nF-statistic: 145.9 on 1 and 66 DF,  p-value: &lt; 2.2e-16\n\n\nEach 1 unit increase in logged salary is associated with a 18.14 minute decrease in time to earn a Big Mac on average.\nWe can also use a property of logarithms to interpret the slope of -18.14 in a different way. Suppose we have two salaries: Salary1 and Salary2. If Salary2 is 10% higher than Salary1, then Salary2/Salary1 = 1.1. It is a property of logarithms that log(Salary2/Salary1) = log(Salary2) - log(Salary1). In this case log(Salary2/Salary1) = log(Salary2) - log(Salary1) = log(1.1) = 0.09531018. So a 10% increase in salary is a 0.09 unit increase in the log scale:\n\n# Multiplicative difference of 1.1, or 10% between salaries gives us the \nlog(1.1) * -18.142\n\n[1] -1.729117\n\n\nWhile a 1 unit increase in log salary is associated with an average decrease of 18 Big Mac minutes, a 0.0953 unit increase in log salary (which corresponds to a 10% multiplicative increase), is associated with a 1.7 minute decrease in Big Mac minutes.\nUnderlying math:\nCase 1: Salary = x\n   E[bigmacmin_1] = beta0 + beta1 log(x)\nCase 2: Salary = m*x\n   E[bigmacmin_2] = beta0 + beta1 log(m*x)\n\nE[bigmacmin_2] - E[bigmacmin_1] = beta1 log(m)\n\n\n\n\n# Residuals vs. fitted values plot\nggplot(mod_log, aes(x = .fitted, y = .resid)) + \n    geom_point() + \n    geom_hline(yintercept = 0) +\n    geom_smooth(se = FALSE)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThe residuals seem to lie roughly around zero for all possible fitted values, though the spread is still noticably larger for larger fitted values compared to smaller ones. This implies that the linearity assumption is likely satisfied for this model, but equal variance may be a concern."
  },
  {
    "objectID": "solutions/07_slr_cat_predictor.html",
    "href": "solutions/07_slr_cat_predictor.html",
    "title": "Solutions for 07. Simple linear regression: categorical predictor",
    "section": "",
    "text": "# Load packages and import data\nlibrary(ggplot2)\nlibrary(dplyr)\n\ndata(diamonds)\n\n# A little bit of data wrangling code - let's not focus on this for now\ndiamonds &lt;- diamonds %&gt;% \n    mutate(\n        cut = factor(cut, ordered = FALSE),\n        color = factor(color, ordered = FALSE),\n        clarity = factor(clarity, ordered = FALSE)\n    )"
  },
  {
    "objectID": "solutions/07_slr_cat_predictor.html#exercise-1-get-to-know-the-data",
    "href": "solutions/07_slr_cat_predictor.html#exercise-1-get-to-know-the-data",
    "title": "Solutions for 07. Simple linear regression: categorical predictor",
    "section": "Exercise 1: Get to know the data",
    "text": "Exercise 1: Get to know the data\n\nA case represents a single diamond.\nThe distribution of price is right skewed with considerable high outliers. The right skew is evidenced by the mean price ($3932) being much higher than the median price ($2401).\nMost diamonds in this data are of Good cut or better. Ideal cut diamonds are the most common with each succesive grade being the next most common.\n\n\ndim(diamonds)\n\n[1] 53940    10\n\nhead(diamonds)\n\n# A tibble: 6 × 10\n  carat cut       color clarity depth table price     x     y     z\n  &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n\n# Visualize price (outcome variable)\nggplot(diamonds, aes(x = price)) +\n    geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nggplot(diamonds, aes(y = price)) +\n    geom_boxplot()\n\n\n\n\n\n\n\ndiamonds %&gt;%\n    summarize(mean(price), median(price), sd(price))\n\n# A tibble: 1 × 3\n  `mean(price)` `median(price)` `sd(price)`\n          &lt;dbl&gt;           &lt;dbl&gt;       &lt;dbl&gt;\n1         3933.            2401       3989.\n\n# Visualize cut (predictor variable)\nggplot(diamonds, aes(x = cut)) +\n    geom_bar()\n\n\n\n\n\n\n\ndiamonds %&gt;% \n    count(cut)\n\n# A tibble: 5 × 2\n  cut           n\n  &lt;fct&gt;     &lt;int&gt;\n1 Fair       1610\n2 Good       4906\n3 Very Good 12082\n4 Premium   13791\n5 Ideal     21551"
  },
  {
    "objectID": "solutions/07_slr_cat_predictor.html#exercise-2-visualizations",
    "href": "solutions/07_slr_cat_predictor.html#exercise-2-visualizations",
    "title": "Solutions for 07. Simple linear regression: categorical predictor",
    "section": "Exercise 2: Visualizations",
    "text": "Exercise 2: Visualizations\nStart by visualizing this relationship of interest, that between price and cut.\n\nWe just don’t see anything clearly on a scatterplot. With the small number of unique values of the predictor variable, all of the points are bunched up on each other.\n\n\n# Try a scatterplot\nggplot(diamonds, aes(y = price, x = cut)) + \n    geom_point()\n\n\n\n\n\n\n\n\n\nSeparately run each chunk below, with two plots. Comment (#) on what changes in the code / output.\n\n\n# Univariate boxplot\nggplot(diamonds, aes(y = price)) + \n    geom_boxplot()\n\n\n\n\n\n\n\n\n\n# Separate boxes by category\nggplot(diamonds, aes(y = price, x = cut)) + \n    geom_boxplot()\n\n\n\n\n\n\n\n\n\n# Univariate density plot\nggplot(diamonds, aes(x = price)) + \n    geom_density()\n\n\n\n\n\n\n\n\n\n# Separate density plots by category\nggplot(diamonds, aes(x = price, color = cut)) + \n    geom_density()\n\n\n\n\n\n\n\n\n\n# Univariate histogram\nggplot(diamonds, aes(x = price)) + \n    geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\n# Separate histograms by category\nggplot(diamonds, aes(x = price)) + \n    geom_histogram() + \n    facet_wrap(~ cut)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\nThe relationship between price and cut seems to be opposite what we would expect. The diamonds with the best cut (Ideal) have the lowest average price, and the ones with the worst cut (Fair) are woth the most. Maybe something else is different between the diamonds with the best and worst cuts…size maybe?"
  },
  {
    "objectID": "solutions/07_slr_cat_predictor.html#exercise-3-numerical-summaries",
    "href": "solutions/07_slr_cat_predictor.html#exercise-3-numerical-summaries",
    "title": "Solutions for 07. Simple linear regression: categorical predictor",
    "section": "Exercise 3: Numerical summaries",
    "text": "Exercise 3: Numerical summaries\nLet’s follow up our plots with some numerical summaries.\n\nMean price across all diamonds:\n\n\ndiamonds %&gt;% \n    summarize(mean(price))\n\n# A tibble: 1 × 1\n  `mean(price)`\n          &lt;dbl&gt;\n1         3933.\n\n\n\nMean price for each type of cut:\n\n\ndiamonds %&gt;% \n    group_by(cut) %&gt;% \n    summarize(mean(price))\n\n# A tibble: 5 × 2\n  cut       `mean(price)`\n  &lt;fct&gt;             &lt;dbl&gt;\n1 Fair              4359.\n2 Good              3929.\n3 Very Good         3982.\n4 Premium           4584.\n5 Ideal             3458.\n\n\n\nGroup means should reflect what you see in the plots (easiest to see in the boxplots)\nCreate our new cutFair variable:\n\n\ndiamonds &lt;- diamonds %&gt;%\n  mutate(cutFair=ifelse(cut == \"Fair\", 1, 0))\n\n\nCalculate the group means based on this new variable\n\n\ndiamonds %&gt;% \n    group_by(cutFair) %&gt;% \n    summarize(mean(price))\n\n# A tibble: 2 × 2\n  cutFair `mean(price)`\n    &lt;dbl&gt;         &lt;dbl&gt;\n1       0         3920.\n2       1         4359."
  },
  {
    "objectID": "solutions/07_slr_cat_predictor.html#exercise-4-modeling-trend-using-a-categorical-predictor-with-exactly-2-categories",
    "href": "solutions/07_slr_cat_predictor.html#exercise-4-modeling-trend-using-a-categorical-predictor-with-exactly-2-categories",
    "title": "Solutions for 07. Simple linear regression: categorical predictor",
    "section": "Exercise 4: Modeling trend using a categorical predictor with exactly 2 categories",
    "text": "Exercise 4: Modeling trend using a categorical predictor with exactly 2 categories\n\n# Construct the model\ndiamond_mod0 &lt;- lm(price ~ cutFair, data = diamonds)\n\n# Summarize the model\ncoef(summary(diamond_mod0))\n\n             Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept) 3919.6946    17.4367 224.795616 0.000000e+00\ncutFair      439.0632   100.9269   4.350309 1.361951e-05\n\n\nThe intercept is the expected value (mean) of the price for all diamonds with a cut quality that isn’t Fair (Good, Very Good, Premium, or Ideal, i.e. when cutFair = 0)–the same as we saw in exercise 3e.\n\nWhen we add the intercept and coefficient for cutFair, we get 3919.69 + 439.06 = 4358.75–this is the mean price for all diamonds with a Fair cut quality that we saw in exercise 3e! Therefore, the coefficient of cutFair (439.06) is interpreted as the difference between the mean value of diamonds with a Fair cut quality and the mean value of diamonds with a higher cut quality."
  },
  {
    "objectID": "solutions/07_slr_cat_predictor.html#exercise-5-modeling-trend-using-a-categorical-predictor-with-2-categories",
    "href": "solutions/07_slr_cat_predictor.html#exercise-5-modeling-trend-using-a-categorical-predictor-with-2-categories",
    "title": "Solutions for 07. Simple linear regression: categorical predictor",
    "section": "Exercise 5: Modeling trend using a categorical predictor with >2 categories",
    "text": "Exercise 5: Modeling trend using a categorical predictor with &gt;2 categories\n\n# Construct the model\ndiamond_mod &lt;- lm(price ~ cut, data = diamonds)\n\n# Summarize the model\ncoef(summary(diamond_mod))\n\n              Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept)  4358.7578   98.78795 44.122361 0.000000e+00\ncutGood      -429.8933  113.84940 -3.775982 1.595493e-04\ncutVery Good -376.9979  105.16422 -3.584849 3.375707e-04\ncutPremium    225.4999  104.39521  2.160060 3.077240e-02\ncutIdeal     -901.2158  102.41155 -8.799943 1.408406e-18\n\n\n\nWe are seeing 4 coefficient estimates because each category is being assigned to a separate indicator variable–cutGood = 1 when cut == \"Good\" and 0 otherwise, cutVery Good = 1 when `cut == “Very Good” and 0 otherwise, and so on.\nE[price | cut] = 4358.7578 - 429.8933 cutGood - 376.9979 cutVery Good + 225.4999 cutPremium - 901.2158 cutIdeal"
  },
  {
    "objectID": "solutions/07_slr_cat_predictor.html#exercise-6-making-sense-of-the-model",
    "href": "solutions/07_slr_cat_predictor.html#exercise-6-making-sense-of-the-model",
    "title": "Solutions for 07. Simple linear regression: categorical predictor",
    "section": "Exercise 6: Making sense of the model",
    "text": "Exercise 6: Making sense of the model\n\nExpected/typical price for diamonds of Good cut:\n\nE[price | cut] = 4358.7578 - 429.8933 * 1 - 376.9979 * 0 + 225.4999 * 0 - 901.2158 * 0 = 4358.7578 - 429.8933 = $3928.865\n\npredict(diamond_mod, newdata = data.frame(cut = \"Good\"))\n\n       1 \n3928.864 \n\n\n\nExpected/typical price for diamonds of Fair cut:\n\nE[price | cut] = 4358.7578 - 429.8933 * 0 - 376.9979 * 0 + 225.4999 * 0 - 901.2158 * 0 = $4358.7578\n\npredict(diamond_mod, newdata = data.frame(cut = \"Fair\"))\n\n       1 \n4358.758 \n\n\n\nThese come from our group mean calculations in Exercise 3b! The predicted value for diamonds of Fair cut is also the same as what we obtained using the SLR model in exercise 4 with only a single cutFair indicator variable."
  },
  {
    "objectID": "solutions/07_slr_cat_predictor.html#exercise-7-interpreting-coefficients",
    "href": "solutions/07_slr_cat_predictor.html#exercise-7-interpreting-coefficients",
    "title": "Solutions for 07. Simple linear regression: categorical predictor",
    "section": "Exercise 7: Interpreting coefficients",
    "text": "Exercise 7: Interpreting coefficients\nRecall that our model formula is not a formula for a line. Thus we can’t interpret the coefficients as “slopes” as we have before. Taking this into account and reflecting upon your calculations above…\n\nThe average price of a Fair cut diamonds is $4358.7578.\n\nInterpretation of cutGood coefficient: On average, Good cut diamonds are worth $429.89 less than Fair cut diamonds.\nInterpretation of cutVery Good coefficient: On average, Very Good cut diamonds are worth $377.00 less than Fair cut diamonds."
  },
  {
    "objectID": "solutions/07_slr_cat_predictor.html#exercise-8-modeling-choices-challenge",
    "href": "solutions/07_slr_cat_predictor.html#exercise-8-modeling-choices-challenge",
    "title": "Solutions for 07. Simple linear regression: categorical predictor",
    "section": "Exercise 8: Modeling choices (CHALLENGE)",
    "text": "Exercise 8: Modeling choices (CHALLENGE)\nWhy do we fit this model in this way (using 4 indicator variables cutGood, cutVery Good, cutPremium, cutIdeal)? Instead, suppose that we created a single variable cutCat that gave each category a numerical value: 0 for Fair, 1 for Good, 2 for Very Good, 3 for Premium, and 4 for Ideal.\n\nIf we used 0-4 instead of creating indicator variables, we would be constraining the change from 0 to 1, from 1 to 2, etc. to always be of the same magnitude. That is, a 1 unit change in the cut variable would always have the same change in price in our model.\nUsing separate indicator variables allows the difference between subsequent categories to be different, which allows our model to be a bit more nuanced. It is possible to take nuance too far though. For example, in our previous investigations of bikeshare data, we modeled ridership versus temperature. We treated temperature as a quantitative predictor. Imagine if we had created an indicator variable for each unique temperature in the data—that would be so many variables! Having so many variables creates a very complex model which can be hard to make sense of. (These ideas are addressed further in STAT 253: Statistical Machine Learning!)"
  },
  {
    "objectID": "solutions/07_slr_cat_predictor.html#exercise-9-diamond-color",
    "href": "solutions/07_slr_cat_predictor.html#exercise-9-diamond-color",
    "title": "Solutions for 07. Simple linear regression: categorical predictor",
    "section": "Exercise 9: Diamond color",
    "text": "Exercise 9: Diamond color\nConsider modeling price by color.\n\nThe best color diamonds are J, and worst are D. We would expect D diamonds to have the lowest price and increase steadily as we get to J. This is in fact what we see in the boxplots.\n\n\nggplot(diamonds, aes(x = color, y = price)) +\n    geom_boxplot()\n\n\n\n\n\n\n\ndiamonds %&gt;% \n    group_by(color) %&gt;% \n    summarize(mean(price))\n\n# A tibble: 7 × 2\n  color `mean(price)`\n  &lt;fct&gt;         &lt;dbl&gt;\n1 D             3170.\n2 E             3077.\n3 F             3725.\n4 G             3999.\n5 H             4487.\n6 I             5092.\n7 J             5324.\n\n\n\nWe fit a linear model and obtain the model formula: E[price | color] = 3169.95 - 93.20 colorE + 554.93 colorF + 829.18 colorG + 1316.72 colorH + 1921.92 colorI + 2153.86 colorJ\n\n\ndiamond_mod2 &lt;- lm(price ~ color, data = diamonds)\n\ncoef(summary(diamond_mod2))\n\n              Estimate Std. Error   t value      Pr(&gt;|t|)\n(Intercept) 3169.95410   47.70694 66.446391  0.000000e+00\ncolorE       -93.20162   62.04724 -1.502107  1.330752e-01\ncolorF       554.93230   62.38527  8.895246  6.004834e-19\ncolorG       829.18158   60.34470 13.740751  6.836340e-43\ncolorH      1316.71510   64.28715 20.481777  7.074714e-93\ncolorI      1921.92086   71.55308 26.860072 7.078041e-158\ncolorJ      2153.86392   88.13203 24.439060 3.414906e-131\n\n\n\nColor D is the reference level because we don’t see its indicator variable in the model output.\nInterpretation of the intercept: Diamonds with D color cost $3169.95 on average.\nInterpretation of the colorE coefficient: Diamonds with E color cost $93.20 less than D color diamonds on average.\nInterpretation of the colorF coefficient: Diamonds with F color cost $554.93 more than D color diamonds on average."
  },
  {
    "objectID": "solutions/07_slr_cat_predictor.html#exercise-10-diamond-clarity",
    "href": "solutions/07_slr_cat_predictor.html#exercise-10-diamond-clarity",
    "title": "Solutions for 07. Simple linear regression: categorical predictor",
    "section": "Exercise 10: Diamond clarity",
    "text": "Exercise 10: Diamond clarity\nWe see the unexpected result that diamonds of better clarity (VS1 and higher) have lower average prices. In fact the best clarity diamonds (VVS1 and IF) have the lowest average prices. What might be going on? What if the most clear diamonds were also quite small…\n\nggplot(diamonds, aes(x = clarity, y = price)) +\n    geom_boxplot()\n\n\n\n\n\n\n\ndiamonds %&gt;% \n    group_by(clarity) %&gt;% \n    summarize(mean(price))\n\n# A tibble: 8 × 2\n  clarity `mean(price)`\n  &lt;fct&gt;           &lt;dbl&gt;\n1 I1              3924.\n2 SI2             5063.\n3 SI1             3996.\n4 VS2             3925.\n5 VS1             3839.\n6 VVS2            3284.\n7 VVS1            2523.\n8 IF              2865.\n\ndiamond_mod3 &lt;- lm(price ~ clarity, data = diamonds)\n\ncoef(summary(diamond_mod3))\n\n                 Estimate Std. Error      t value      Pr(&gt;|t|)\n(Intercept)  3924.1686910   144.5619 27.145247517 3.513547e-161\nclaritySI2   1138.8599147   150.2746  7.578526239  3.550711e-14\nclaritySI1     71.8324571   148.6049  0.483378837  6.288287e-01\nclarityVS2      0.8207037   148.8672  0.005512992  9.956013e-01\nclarityVS1    -84.7132999   150.9746 -0.561109670  5.747251e-01\nclarityVVS2  -640.4316203   154.7737 -4.137858008  3.510944e-05\nclarityVVS1 -1401.0540535   158.5401 -8.837224284  1.010097e-18\nclarityIF   -1059.3295848   171.8990 -6.162510636  7.210567e-10"
  },
  {
    "objectID": "activities/03_slr_introduction.html",
    "href": "activities/03_slr_introduction.html",
    "title": "03/04. Introduction to simple linear regression",
    "section": "",
    "text": "Download the .qmd file for this activity here.",
    "crumbs": [
      "03/04. Introduction to simple linear regression"
    ]
  },
  {
    "objectID": "activities/03_slr_introduction.html#learning-goals",
    "href": "activities/03_slr_introduction.html#learning-goals",
    "title": "03/04. Introduction to simple linear regression",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of this lesson, you should be able to:\n\nVisualize and describe the relationship between two quantitative variables using a scatterplot\nDescribe/identify weak / strong, and positive / negative correlation from a point cloud\nDifferentiate between a response / outcome variable and a predictor / explanatory variable\nWrite a model formula and R code for a simple linear regression model with a quantitative predictor\nInterpret the intercept and slope coefficients in a simple linear regression model with a quantitative predictor\nCompute and interpret expected / predicted / fitted values and residuals from a linear regression model formula",
    "crumbs": [
      "03/04. Introduction to simple linear regression"
    ]
  },
  {
    "objectID": "activities/03_slr_introduction.html#readings-and-videos",
    "href": "activities/03_slr_introduction.html#readings-and-videos",
    "title": "03/04. Introduction to simple linear regression",
    "section": "Readings and videos",
    "text": "Readings and videos\n\nReading: Sections 2.8, 3.1-3.3, 3.6 in the STAT 155 Notes\nVideos:\n\nSummarizing the Relationships between Two Quantitative Variables (Time: 12:12)\nIntroduction to Linear Models (Time: 10:57)\nMethod of Least Squares (Time: 5:10)\nInterpretation of Intercept and Slope (Time: 11:09)\nR Code for Fitting a Linear Model (Time: 11:07)\n\n\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder.",
    "crumbs": [
      "03/04. Introduction to simple linear regression"
    ]
  },
  {
    "objectID": "activities/03_slr_introduction.html#exercise-1-get-to-know-the-data",
    "href": "activities/03_slr_introduction.html#exercise-1-get-to-know-the-data",
    "title": "03/04. Introduction to simple linear regression",
    "section": "Exercise 1: Get to know the data",
    "text": "Exercise 1: Get to know the data\n\nCreate a new code chunk by clicking the green “C” button with a green + sign in the top right of the menu bar. In this code chunk, use an appropriate function to look at the first few rows of the data.\nCreate a new code chunk, and use an appropriate function to summarize how much data we have (in terms of number of cases and number of variables).\nWhat does a case represent?\nNavigate to the FAQ page and read the response to the “How does this site work? Do you just download results from the federations?” question. What do you learn about data quality and completeness from this response?",
    "crumbs": [
      "03/04. Introduction to simple linear regression"
    ]
  },
  {
    "objectID": "activities/03_slr_introduction.html#exercise-2-modifying-our-dataframe",
    "href": "activities/03_slr_introduction.html#exercise-2-modifying-our-dataframe",
    "title": "03/04. Introduction to simple linear regression",
    "section": "Exercise 2: Modifying our dataframe",
    "text": "Exercise 2: Modifying our dataframe\n\n2a: mutating\nA popular variable of interest in weightlifting is the Strength-to-Weight ratio (SWR), defined as TotalKg/BodyweightKg. We can use the mutate() function from the dplyr package to create a new SWR variable in our dataframe using the following code:\n\n# The %&gt;% is called a \"pipe\" and feeds what comes before it\n# into what comes after (lifts data is \"fed into\" the mutate() function).\n# When creating a new variable, we often reassign the data frame to itself,\n# which updates the existing columns in lifts with the additional \"new\" column(s)\n# in lifts!\nlifts &lt;- lifts %&gt;% \n    mutate(SWR = TotalKg/BodyweightKg)\n\n\n\n2b: filtering\nAnother common task you’ll see in R is “filtering” a dataframe to only contain observations that match some criteria. Here, we’ll filter our dataframe to include only people age 18 or higher from the USA:\n\n# The %&gt;% is called a \"pipe\" and feeds what comes before it\n# into what comes after (lifts data is \"piped into\" the filter() function)\nlifts &lt;- lifts %&gt;% \n    filter(Country == \"USA\", Age&gt;=18)\n\nLet’s look at how many observations are in our new dataframe–how does this compare to the number of observations in the full lifts dataframe that you found in exercise 1b?\n\nnrow(lifts)\n\n\n\n\n\n\n\nReassign to the original dataframe, or create a new one?\n\n\n\n\n\nIn the example above, we are reassigning the lifts dataframe back to itself after applying the filtering/mutating functions (i.e., lifts &lt;- lifts%&gt;% *FUNCTIONS THAT MODIFY THE DATA FRAME*).\nGenerally this is an OK thing to do, but you want to be sure that you don’t remove or replace information in the original dataframe that you might need later. For example, if we update the lifts dataframe to remove non-USA observations, but later we realize we do want to analyze those observations, we will need to go back to reload the raw data and start over.\nAn alternative when using these functions is to assign the output to a dataframe with a different name. For example, we could assign our filtered data to a dataframe named lifts_usa instead, preserving the original lifts dataframe if we need to go back to it.\nThe only catch is that if you create too many dataframes, R may eventually run out of memory and crash (though this shouldn’t be a concern with the size of datasets we are typically working with).",
    "crumbs": [
      "03/04. Introduction to simple linear regression"
    ]
  },
  {
    "objectID": "activities/03_slr_introduction.html#exercise-3-get-to-know-the-outcomeresponse-variable",
    "href": "activities/03_slr_introduction.html#exercise-3-get-to-know-the-outcomeresponse-variable",
    "title": "03/04. Introduction to simple linear regression",
    "section": "Exercise 3: Get to know the outcome/response variable",
    "text": "Exercise 3: Get to know the outcome/response variable\nLet’s get acquainted with the SWR variable.\n\nCreate a new code chunk and use ggplot to construct an appropriate plot to visualize the distribution of this variable\nCreate a new code chunk and compute at least two appropriate numerical summaries for the SWR variable.\nWrite a brief paragraph interpreting the plot and numerical summaries.",
    "crumbs": [
      "03/04. Introduction to simple linear regression"
    ]
  },
  {
    "objectID": "activities/03_slr_introduction.html#exercise-4-data-visualization---two-quantitative-variables",
    "href": "activities/03_slr_introduction.html#exercise-4-data-visualization---two-quantitative-variables",
    "title": "03/04. Introduction to simple linear regression",
    "section": "Exercise 4: Data visualization - two quantitative variables",
    "text": "Exercise 4: Data visualization - two quantitative variables\nWe’d like to visualize the relationship between body weight and the strength-to-weight ratio. A scatterplot (or informally, a “point cloud”) allows us to do this! The code below creates a scatterplot of body weight vs. SWR using ggplot().\n\n# scatterplot\n\n# The alpha = 0.5 in geom_point() adds transparency to the points\n# to make them easier to see. You can decrease this value to make points\n# more transparent, and increase it to make them more opaque\nlifts %&gt;%\n  ggplot(aes(x = BodyweightKg, y = SWR)) +\n  geom_point(alpha = 0.5)\n\n\nThis is your first bivariate data visualization (visualization for two variables)! What differences do you notice in the code structure when creating a bivariate visualization, compared to univariate visualizations we’ve worked with before?\nWhat similarities do you notice in the code structure?\nDoes there appear to be some sort of pattern in the structure of the point cloud? Describe it, in no more than three sentences! Comment on the direction of the relationship between the two variables (positive? negative?) and the spread of the points (are they dispersed? close together?).",
    "crumbs": [
      "03/04. Introduction to simple linear regression"
    ]
  },
  {
    "objectID": "activities/03_slr_introduction.html#exercise-5-scatterplots---patterns-in-point-clouds",
    "href": "activities/03_slr_introduction.html#exercise-5-scatterplots---patterns-in-point-clouds",
    "title": "03/04. Introduction to simple linear regression",
    "section": "Exercise 5: Scatterplots - patterns in point clouds",
    "text": "Exercise 5: Scatterplots - patterns in point clouds\nSometimes, it can be easier to see a pattern in a point cloud by adding a smoothing line to our scatterplots. We can accomplish this by adding another layer to the code in Exercise 4:\n\n# scatterplot with smoothing line\nlifts %&gt;%\n  ggplot(aes(x = BodyweightKg, y = SWR)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth()\n\n\nLook back at your answer to Exercise 4 (c). Does the smoothing line assist you in seeing a pattern, or change your answer at all? Why or why not?\nBased on the scatterplot with the smoothing line added above, does there appear to be a linear relationship between body weight and SWR (i.e. would a straight line do a decent job at summarizing the relationship between these two variables)? Why or why not?",
    "crumbs": [
      "03/04. Introduction to simple linear regression"
    ]
  },
  {
    "objectID": "activities/03_slr_introduction.html#exercise-6-correlation",
    "href": "activities/03_slr_introduction.html#exercise-6-correlation",
    "title": "03/04. Introduction to simple linear regression",
    "section": "Exercise 6: Correlation",
    "text": "Exercise 6: Correlation\nWe can quantify the linear relationship between two quantitative variables using a numerical summary known as correlation (sometimes known as a “correlation coefficient” or “Pearson’s correlation”). Correlation can range from -1 to 1, where a correlation of 0 indicates that there is no linear relationship between the two quantitative variables.\nBelow is an example of a “Math Box”. You’ll see these occasionally throughout the activities. You are not required to memorize, nor will you be assessed on, anything in the math boxes. If you plan on continuing with Statistics courses at Macalester (or are interested in the math behind everything!), these math boxes are for you!\n\n\n\n\n\n\nCorrelation\n\n\n\n\n\nThe Pearson correlation coefficient, \\(r_{x, y}\\), of \\(x\\) and \\(y\\) is the (almost) average of products of the z-scores of variables \\(x\\) and \\(y\\):\n\\[\nr_{x, y} = \\frac{\\sum z_x z_y}{n - 1}\n\\]\n\n\n\nIn general, we will want to be able to describe (qualitatively) two aspects of correlation:\n\nStrength\n\n\nIs the correlation between x and y strong, or weak, i.e. how closely do the points fit around a line? This has to do with how dispersed our point clouds are.\n\n\nDirection\n\n\nIs the correlation between x and y positive or negative, i.e. does y go “up” when x goes “up” [positive], or does y go “down” when x goes “up” (or vice versa) [negative]?\n\nStronger correlations will be further from 0 (closer to -1 or 1), and positive and negative correlations will have the appropriate respective sign (above or below zero).\n\nIn addition to a smooth trend line, we can add a linear trendline using geom_smooth(method = 'lm'), as below:\n\n\n# scatterplot with linear trend line\nlifts %&gt;%\n  ggplot(aes(x = BodyweightKg, y = SWR)) +\n  geom_point(alpha = 0.5) +\n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE) +\n    geom_smooth(color = \"blue\", se = FALSE)\n\n\nBased on the above scatterplot, how would you describe the correlation between body weight and SWR, in terms of strength and direction?\nMake a guess as to what numerical value the correlation between body weight and SWR will have, based on your response to part (b).",
    "crumbs": [
      "03/04. Introduction to simple linear regression"
    ]
  },
  {
    "objectID": "activities/03_slr_introduction.html#exercise-7-computing-correlation-in-r",
    "href": "activities/03_slr_introduction.html#exercise-7-computing-correlation-in-r",
    "title": "03/04. Introduction to simple linear regression",
    "section": "Exercise 7: Computing correlation in R",
    "text": "Exercise 7: Computing correlation in R\nWe can compute the correlation between body weight and SWR using summarize and cor functions:\n\n# correlation\n\n# Note: the order in which you put your two quantitative variables into the cor\n# function doesn't matter! Try switching them around to confirm this for yourself\n# Because of the missing data, we need to include the use = \"complete.obs\" - otherwise the correlation would be computed as NA\nlifts %&gt;%\n    summarize(cor(SWR, BodyweightKg, use = \"complete.obs\"))\n\nIs the computed correlation close to what you guessed in Exercise 6 part (c)?",
    "crumbs": [
      "03/04. Introduction to simple linear regression"
    ]
  },
  {
    "objectID": "activities/03_slr_introduction.html#exercise-8-model-fitting-and-coefficient-interpretation",
    "href": "activities/03_slr_introduction.html#exercise-8-model-fitting-and-coefficient-interpretation",
    "title": "03/04. Introduction to simple linear regression",
    "section": "Exercise 8: Model fitting and coefficient interpretation",
    "text": "Exercise 8: Model fitting and coefficient interpretation\nLet’s fit a simple linear regression model and examine the results. Step through the code chunks slowly, and make note of new code.\n\n# Construct and save the model as lifts_mod\n# the lm() function has two required arguments:\n#  - What's the purpose of \"SWR ~ BodyweightKg\"?\n#  - What's the purpose of \"data = lifts\"?\nlifts_mod &lt;- lm(SWR ~ BodyweightKg, data = lifts)\n\n\n# The summary() function gives us a detailed glance at the model stored in lifts_mod\nsummary(lifts_mod)\n\n\n# A simplified model summary of just the coefficients\ncoef(summary(lifts_mod))\n\n\nUsing the model summary output, complete the following model formula:\nE[SWR | BodyweightKg] = ___ + ___ * BodyweightKg\nInterpret the intercept in terms of the data context. Make sure to use non-causal language, include units, and talk about averages rather than individual cases. Is the intercept meaningful in this situation?\nInterpret the slope in terms of the data context. Make sure to use non-causal language, include units, and talk about averages rather than individual cases.",
    "crumbs": [
      "03/04. Introduction to simple linear regression"
    ]
  },
  {
    "objectID": "activities/03_slr_introduction.html#exercise-9-predictions-and-residuals",
    "href": "activities/03_slr_introduction.html#exercise-9-predictions-and-residuals",
    "title": "03/04. Introduction to simple linear regression",
    "section": "Exercise 9: Predictions and residuals",
    "text": "Exercise 9: Predictions and residuals\nLet’s look at how well our model does at predicting the strength-weight ratio for a lifter named “Chris Della Fave.” We can get the relevant observed data for Della Fave using the filter() and select() dplyr functions. Note–but don’t worry about–the syntax for the select() function, we haven’t learned this yet:\n\nlifts %&gt;% \n    filter(Name == \"Chris Della Fave\") %&gt;% \n    select(BodyweightKg, SWR) \n\n\nPeek back at the scatterplot you made in exercise 6a. Identify which point corresponds to this lifter. Is it close to the trend? Is their SWR higher or lower than expected?\nUse your model formula from the previous exercise to find what our model predicts Della Fave’s SWR should be, based on his body weight. (That is, where do individuals with similar body weight fall on the model trend line? What SWR should would we expect from a 118.4kg lifter?)\nCheck your part b calculation using the predict() function. Take careful note of the syntax – there’s a lot going on!\n\n\n# What is the purpose of newdata = ___???\npredict(lifts_mod, newdata = data.frame(BodyweightKg = 118.39))\n\n\nCalculate the residual or prediction error. How far does Della Fave’s observed SWR fall from the model prediction?\nresidual = observed y - predicted y = ???\nAre positive residuals above or below the trend line? When we have positive residuals, does the model over- or under-estimate SWR? Repeat these questions for negative residuals.",
    "crumbs": [
      "03/04. Introduction to simple linear regression"
    ]
  },
  {
    "objectID": "activities/03_slr_introduction.html#exercise-10-lines-of-best-fit",
    "href": "activities/03_slr_introduction.html#exercise-10-lines-of-best-fit",
    "title": "03/04. Introduction to simple linear regression",
    "section": "Exercise 10: Lines of best fit",
    "text": "Exercise 10: Lines of best fit\nIn this activity, we’ve learned how to fit straight lines to data, to help us visualize the relationship between two quantitative variables. So far, ggplot has chosen the line for us. How does it know which line is “best”, and what does “best” even mean?\nFor this exercise, we’ll be working with the anscombe dataset, which is built in to R. To load this dataset into our environment, we run the following code:\n\n# load anscombe data\ndata(\"anscombe\")\n\nWe’ll consider the relationship between the x1 and y1 variables in the anscombe dataset. Run the following code, which creates a scatterplot with a fitted line to our data using the function geom_abline:\n\n# scatterplot with a fitted line, whose slope is 0.4 and intercept is 3\nanscombe %&gt;%\n  ggplot(aes(x = x1, y = y1)) +\n  geom_point() +\n  geom_abline(slope = 0.4, intercept = 3, col = \"blue\", size = 1)\n\nDescribe the line that you see. Do you think the line is “good”? What are you using to define “good”?\nSome things to think about:\n\nHow many points are above the line?\nHow many points are below the line?\nAre the distances of the points above and below the line roughly similar, or is there meaningful difference?\n\nNow we’ll add another line to our plot. Which line do you think is better suited for this data? Why? Be specific!\n\n# scatterplot with a fitted line, whose slope is 0.4 and intercept is 3\nanscombe %&gt;%\n  ggplot(aes(x = x1, y = y1)) +\n  geom_point() +\n  geom_abline(slope = 0.4, intercept = 3, col = \"blue\", size = 1) +\n  geom_abline(slope = 0.5, intercept = 4, col = \"orange\", size = 1)\n\nIt’s usually quite simple to note when a line is bad, but more difficult to quantify when a line is a good fit for our data. Consider the following line:\n\n# scatterplot with a fitted line, whose slope is 0.4 and intercept is 3\nanscombe %&gt;%\n  ggplot(aes(x = x1, y = y1)) +\n  geom_point() +\n  geom_abline(slope = -0.5, intercept = 10, col = \"red\", size = 1) \n\nIn the reading/videos for today, we formalized the principle of least squares, which gives us one particular definition of a line of best fit that is commonly used in statistics! We’ll take advantage of the vertical distances between each point and the fitted line (residuals), which will help us define (mathematically) a line that best fits our data:\n\nlibrary(broom)\nanscombe %&gt;%\n  lm(y1 ~ x1, data = .) %&gt;%\n  augment() %&gt;%\n  ggplot(aes(x = x1, y = y1)) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  geom_segment(aes(xend = x1, yend = .fitted), col = \"red\") +\n  geom_point()",
    "crumbs": [
      "03/04. Introduction to simple linear regression"
    ]
  },
  {
    "objectID": "activities/03_slr_introduction.html#exercise-11-data-drills-filter-select-summarize",
    "href": "activities/03_slr_introduction.html#exercise-11-data-drills-filter-select-summarize",
    "title": "03/04. Introduction to simple linear regression",
    "section": "Exercise 11: Data drills (filter, select, summarize)",
    "text": "Exercise 11: Data drills (filter, select, summarize)\nThis exercise is designed to help you keep building your dplyr skills. These skills are important to data cleaning and digging, which in turn is important to really making meaning of our data. We’ll work with a simpler set of 10 data points:\n\nnew_lifts &lt;- lifts %&gt;% \n    select(Name, State, Sex, Age, BodyweightKg, SWR) %&gt;% \n    head(10)\n\n\nVerb 1: summarize\nThus far, in the dplyr grammar you’ve seen 3 verbs or action words: summarize(), select(), filter(). Try out the following code and then summarize the point of the summarize() function:\n\nnew_lifts %&gt;% \n    summarize(mean_bodyweight = mean(BodyweightKg, na.rm=T),\n              mean_SWR = mean(SWR, na.rm=T))\n\n\n\nVerb 2: select\nTry out the following code and then summarize the point of the select() function:\n\nnew_lifts %&gt;%\n    select(Name, State)\n\n\nnew_lifts %&gt;% \n    select(-Name, -State)\n\n\n\nVerb 3: filter\nTry out the following code and then summarize the point of the filter() function:\n\nnew_lifts %&gt;% \n    filter(Age &gt;=28)\n\n\nnew_lifts %&gt;% \n    filter(State == \"CA\")\n\n\nnew_lifts %&gt;% \n    filter(Age &gt;= 28, State==\"CA\")\n\nUse dplyr verbs to complete each task below using the new_lifts dataframe.\n\n# Keep only Bodyweight and SWR variables\n\n# Keep only Bodyweight and SWR variables using a different approach\n\n# Keep only participants (observations) who are female\n\n# Keep only participants (observations) who are female and younger than 30\n\n# Calculate the maximum and minimum ages of participants",
    "crumbs": [
      "03/04. Introduction to simple linear regression"
    ]
  },
  {
    "objectID": "activities/03_slr_introduction.html#exercise-12-limitations-of-correlation",
    "href": "activities/03_slr_introduction.html#exercise-12-limitations-of-correlation",
    "title": "03/04. Introduction to simple linear regression",
    "section": "Exercise 12: Limitations of correlation",
    "text": "Exercise 12: Limitations of correlation\nWe previously noted that correlation was a numerical summary of the linear relationship between two variables. We’ll now go through some examples of relationships between quantitative variables to demonstrate why it is incredibly important to visualize our data in addition to just computing numerical summaries!\nWe’ll retun to the anscombe dataset, which contains four different pairs of quantitative variables:\n\nx1, y1\nx2, y2\nx3, y3\nx4, y4\n\nAdapt the code we used in Exercise 7 to compute the correlation between each of these four pairs of variables, below:\n\n# correlation between x1, y1\n\n# correlation between x2, y2\n\n# correlation between x3, y3\n\n# correlation between x4, y4\n\n\nWhat do you notice about each of these correlations (if the answer to this isn’t obvious, double-check your code)?\nDescribe these correlations in terms of strength and direction, using only the numerical summary to assist you in your description.\nDraw an example on the white board or at your tables of what you think the point clouds for these pairs of variables might look like. There are only 11 observations, so you can draw all 11 points if you’d like!\nAdapt the code for scatterplots given previously in this activity to make four distinct scatterplots for each pair of quantitative variables in the anscombe dataset. You do not need to add a smooth trend line or a linear trend line to these plots.\n\n\n# scatterplot: x1, y1\n\n# scatterplot: x2, y2\n\n# scatterplot: x3, y3\n\n# scatterplot: x4, y4\n\n\nBased on the correlations you calculated and scatterplots you made, what is the message of this last exercise as it relates to the limits of correlation?",
    "crumbs": [
      "03/04. Introduction to simple linear regression"
    ]
  },
  {
    "objectID": "activities/03_slr_introduction.html#exercise-13-correlation-and-extreme-values",
    "href": "activities/03_slr_introduction.html#exercise-13-correlation-and-extreme-values",
    "title": "03/04. Introduction to simple linear regression",
    "section": "Exercise 13: Correlation and extreme values",
    "text": "Exercise 13: Correlation and extreme values\nIn this exercise, we’ll explore how correlation changes with the addition of extreme values, or observations. We’ll begin by generating a simulated dataset called dat with two quantitative variables, x and y. Run the code below to create the dataset.\nwhile not required, recall that you can look up function documentation in R using the ? in front of a function name to figure out what that function is doing!\n\n# create a toy dataset\nset.seed(1234)\nx &lt;- rnorm(100, mean = 5, sd = 2)\ny &lt;- -3 * x + rnorm(100, sd = 4)\ndat &lt;- data.frame(x = x, y = y)\n\n\nMake a scatterplot of x vs. y.\n\n\n# scatterplot\n\n\nBased on your scatterplot, describe the correlation between x and y in terms of strength and direction.\nGuess the correlation (the numerical value) between x and y.\nCompute the correlation between x and y. Was your guess from part (c) close?\n\n\n# correlation\n\n\nSuppose we observe an additional observation with x = 15 and y = -45. We can create a new data frame, dat_new1, that contains this observation in addition to the original ones as follows:\n\n\n# creating dat_new1\nx1 &lt;- c(x, 15)\ny1 &lt;- c(y, -45)\ndat_new1 &lt;- data.frame(x = x1, y = y1)\n\n\nMake a scatterplot of x vs. y for this new data frame, and compute the correlation between x and y. Did your correlation change very much with the addition of this observation? Hypothesize why or why not.\n\n\n# scatterplot\n\n# correlation\n\n\nSuppose instead of our additional observation having values x = 15 and y = -45, we instead observe x = 15 and y = -15. We can create a new data frame, dat_new2, that contains this observation in addition to the original ones as follows:\n\n\n# creating dat_new1\nx2 &lt;- c(x, 15)\ny2 &lt;- c(y, 45)\ndat_new2 &lt;- data.frame(x = x2, y = y2)\n\n\nMake a scatterplot of x vs. y for this new data frame, and compute the correlation between x and y. Did your correlation change very much with the addition of this observation? Hypothesize why or why not.\n\n\n# scatterplot\n\n# correlation\n\n\nWhat do you think the takeaway message is of this exercise?\n\n\n\nChallenge Add linear trend lines to your scatterplots from parts (f) and (h). Does this give you any additional insight into why the correlations may have changed in different ways with the addition of a new observation?",
    "crumbs": [
      "03/04. Introduction to simple linear regression"
    ]
  },
  {
    "objectID": "activities/03_slr_introduction.html#reflection",
    "href": "activities/03_slr_introduction.html#reflection",
    "title": "03/04. Introduction to simple linear regression",
    "section": "Reflection",
    "text": "Reflection\nMuch of statistics is about making (hopefully) reasonable assumptions in attempt to summarize observed relationships in data. Today we started considering assumptions of linear relationships between quantitative variables.\nReview the learning objectives at the top of this file and today’s activity. How do you imagine assumptions of linearity might be useful in terms of quantifying relationships between quantitative variables? How do you imagine these assumptions could sometimes fall short, or even be unethical in certain cases?\n\nResponse: Put your response here.\n\n\nSolutions",
    "crumbs": [
      "03/04. Introduction to simple linear regression"
    ]
  }
]