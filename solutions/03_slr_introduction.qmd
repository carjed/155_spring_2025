---
title: "Solutions for 03/04: Introduction to simple linear regression"
subtitle: "Notes and in-class exercises"
format: 
  html:
    embed-resources: true
    toc: true
---

```{r warning=FALSE, message=FALSE}
# Load packages and import data
library(readr)
library(ggplot2)
library(dplyr)

lifts <- read_csv("https://mac-stat.github.io/data/powerlifting.csv")
```

## Exercise 1: Get to know the data

a.  Use an appropriate function to look at the first few rows of the data.

```{r}
head(lifts)
```

b.  Create a new code chunk, and use an appropriate function to learn how much data we have (in terms of cases and variables).

```{r}
dim(lifts)
```

c.  A case represents an individual lifter at a single weightlifting competition.

d.  It looks like some meets may be missing if they weren't detected by the web scraper used by the maintainers of the Open Powerlifting database. They don't describe in detail the process used for transferring PDFs of results to their database, so it's unclear what errors in transcription might have resulted. Still, it's worth taking a moment to appreciate the labor they put into making these results available for passionate powerlifters to explore.

## Exercise 2: Modifying our data

Strength-to-weight ratio (SWR) is defined as `TotalKg`/`BodyweightKg`. We can use the `mutate()` function from the `dplyr` package to create a new variable in our dataframe for `SWR` using the following code:

```{r eval=FALSE}
lifts <- lifts %>% 
    mutate(SWR = TotalKg / BodyweightKg)
```

Adapt the example above to create a new variable called `SWR`, where SWR is defined as `TotalKg`/`BodyweightKg`.

## Exercise 3: Get to know the outcome/response variable

Let's get acquainted with the `SWR` variable.

-   Construct an appropriate plot to visualize the distribution of this variable, and compute appropriate numerical summaries.

```{r}
lifts %>%
  ggplot(aes(SWR)) +
  geom_histogram(bins = 10, col = "black")

lifts %>% summarize(mean(SWR, na.rm = TRUE), min(SWR, na.rm = TRUE), max(SWR, na.rm = TRUE), sd(SWR, na.rm = TRUE))
```

-   Write a good paragraph interpreting the plot and numerical summaries.

Strength-to-weight (SWR) ratio ranges from 0.18 to 12.46, with a mean SWR of 4.4. SWR varies about 2.08 units above and below the mean. We observe that most SWRs appear to be centered between 4 and 7, with a slight right-skew to the data. The distribution of SWRs appears to be unimodal.

## Exercise 4: Data visualization - two quantitative variables

We'd like to visualize the relationship between body weight and the strength-to-weight ratio. A **scatterplot** (or informally, a "point cloud") allows us to do this! The code below creates a scatterplot of body weight vs. SWR using `ggplot()`.

```{r}
# scatterplot

# The alpha = 0.5 in geom_point() adds transparency to the points
# to make them easier to see. You can make this smaller for more transparency
lifts %>%
  ggplot(aes(x = BodyweightKg, y = SWR)) +
  geom_point(alpha = 0.5)
```

a & b. In our plot aesthetics, we now have *two* variables listed (an "x" and a "y") as opposed to just a single variable. The "geom" for a scatterplot is `geom_point`. Otherwise, the code structure remains very similar!

c.  In general, it seems as though higher body weights are associated with lower SWRs. Once body weight (in kg) is greater than 50, the relationship between body weight and SWR appears to be weakly negative, and roughly linear. The points are very dispersed, indicating that there is a good amount of variation in this relationship (hence the term "weak").

## Exercise 5: Scatterplots - patterns in point clouds

Sometimes, it can be easier to see a pattern in a point cloud by adding a **smoothing** line to our scatterplots. The code below adapts the code in Exercise 4 to do this:

```{r}
# scatterplot with smoothing line
lifts %>%
  ggplot(aes(x = BodyweightKg, y = SWR)) +
  geom_point(alpha = 0.5) +
  geom_smooth()
```

a.  This doesn't change my answer much (but it may have changed yours, and that's okay!). It does appear as though there is a weakly negative relationship between body weight and SWR, particularly once body weight is above a certain value.

b.  I would say that yes, a linear relationship here seems reasonable! Even though there is some curvature in the smoothed trend line early on, that is based on **very few** data points. Those data points with low body weights aren't enough to convince me that the relationship couldn't be roughly linear between body weight and SWR.

## Exercise 6: Correlation

b.  I would describe the correlation between body weight and SWR as weak and negative.

c.  I'll guess -0.1, since the line is negative, and the points are very dispersed around the line!

## Exercise 7: Computing correlation in R

```{r}
# correlation

# Note: the order in which you put your two quantitative variables into the cor
# function doesn't matter! Try switching them around to confirm this for yourself
# Because of the missing data, we need to include the use = "complete.obs" - otherwise the correlation would be computed as NA
lifts %>%
    summarize(cor(SWR, BodyweightKg, use = "complete.obs"))
```

So close to our guess!

## Exercise 8: Model fitting and coefficient interpretation

Let's fit a simple linear regression model and examine the results. Step through the code chunks slowly, and make note of new code.

```{r}
# Construct and save the model as lifts_mod
# the lm() function has two required arguments:
#  - What's the purpose of "SWR ~ BodyweightKg"?
#  - What's the purpose of "data = lifts"?
lifts_mod <- lm(SWR ~ BodyweightKg, data = lifts)
```

```{r}
# The summary() function gives us a detailed glance at the model stored in lifts_mod
summary(lifts_mod)
```

```{r}
# A simplified model summary of just the coefficients
coef(summary(lifts_mod))
```

a.  Using the model summary output, complete the following model formula:\
    E\[SWR \| BodyweightKg\] = 5.875 + -0.0097 * BodyweightKg

b.  Interpret the intercept in terms of the data context. *Make sure to use non-causal language, include units, and talk about averages rather than individual cases.* Is the intercept meaningful in this situation?

> The intercept means that on average, we expect n individual with a bodyweight of 0Kg to have a SWR of 5.875. This is not meaningful because a bodyweight of 0Kg is not possible!

c.  Interpret the slope in terms of the data context. *Make sure to use non-causal language, include units, and talk about averages rather than individual cases.*

> The slope coefficient tells us that on average, we expect that a lifter's SWR decreases by 0.0097 per 1Kg increase in bodyweight--so generally, we find that people *in this particular dataset* (i.e., competitive weightlifters) who weigh less tend to have a higher SWR.

## Exercise 9: Predictions and residuals

Let's look at how well our model does at predicting the strength-weight ratio for a lifter named "Chris Della Fave." We can get the relevant **observed** data for Della Fave using the `filter()` and `select()` `dplyr` functions. Note–but don't worry about–the syntax for the `select()` function, we haven't learned this yet:

```{r}
lifts %>% 
    filter(Name == "Chris Della Fave") %>% 
    select(BodyweightKg, SWR) 
```

a.  Peek back at the scatterplot you made in exercise 6a. Identify which point corresponds to this lifter. Is it close to the trend? Is their SWR *higher* or *lower* than expected?

> The observed SWR for Della Fave is much higher than the trendline

b.  Use your model formula from the previous exercise to find what our model *predicts* Della Fave's SWR should be, based on his body weight. (That is, where do individuals with similar body weight fall on the model trend line? What SWR should would we *expect* from a 118.4kg lifter?)

> 5.875 + -0.0097 *118.4 = 4.73
> The predicted SWR is much lower than the observed

c.  Check your part b calculation using the `predict()` function. Take careful note of the syntax -- there's a lot going on!

```{r}
# What is the purpose of newdata = ___???
predict(lifts_mod, newdata = data.frame(BodyweightKg = 118.39))
```

d.  Calculate the **residual** or **prediction error**. How far does Della Fave's *observed* SWR fall from the *model prediction*?

> residual = observed y - predicted y = 10.98-4.73 = 6.25

e.  Are positive residuals above or below the trend line? When we have positive residuals, does the model over- or under-estimate SWR? Repeat these questions for negative residuals.

> positive residual = above the trendline, so the model has UNDERestimated SWR in this case. 

> negative residual = below the trendline, so when this occurs, the model has OVERestimated SWR.

# Additional Practice

## Exercise 10: Lines of best fit

In this activity, we've learned how to fit straight lines to data, to help us visualize the relationship between two quantitative variables. So far, `ggplot` has chosen the line for us. How does it know which line is "best", and what does "best" even mean?

For this exercise, we'll be working with the `anscombe` dataset, which is built in to R. To load this dataset into our environment, we run the following code:

```{r}
# load anscombe data
data("anscombe")
```

We'll consider the relationship between the `x1` and `y1` variables in the `anscombe` dataset. Run the following code, which creates a scatterplot with a fitted line to our data using the function `geom_abline`:

```{r}
# scatterplot with a fitted line, whose slope is 0.4 and intercept is 3
anscombe %>%
  ggplot(aes(x = x1, y = y1)) +
  geom_point() +
  geom_abline(slope = 0.4, intercept = 3, col = "blue", size = 1)
```

Describe the line that you see. Do you think the line is "good"? What are you using to define "good"?

Some things to think about:

-   How many points are **above** the line?
-   How many points are **below** the line?
-   Are the **distances** of the points above and below the line roughly similar, or is there meaningful difference?

Now we'll add *another* line to our plot. Which line do you think is *better* suited for this data? Why? Be specific!

```{r}
# scatterplot with a fitted line, whose slope is 0.4 and intercept is 3
anscombe %>%
  ggplot(aes(x = x1, y = y1)) +
  geom_point() +
  geom_abline(slope = 0.4, intercept = 3, col = "blue", size = 1) +
  geom_abline(slope = 0.5, intercept = 4, col = "orange", size = 1)
```

It's usually quite simple to note when a line is *bad*, but more difficult to quantify when a line is a *good* fit for our data. Consider the following line:

```{r}
# scatterplot with a fitted line, whose slope is 0.4 and intercept is 3
anscombe %>%
  ggplot(aes(x = x1, y = y1)) +
  geom_point() +
  geom_abline(slope = -0.5, intercept = 10, col = "red", size = 1) 
```

In the reading/videos for today, we formalized the **principle of least squares**, which gives us one particular definition of a *line of best fit* that is commonly used in statistics! We'll take advantage of the vertical distances between each point and the fitted line (**residuals**), which will help us define (mathematically) a line that best fits our data:

```{r}
library(broom)
anscombe %>%
  lm(y1 ~ x1, data = .) %>%
  augment() %>%
  ggplot(aes(x = x1, y = y1)) +
  geom_smooth(method = "lm", se = FALSE) +
  geom_segment(aes(xend = x1, yend = .fitted), col = "red") +
  geom_point()
```

## Exercise 11: Data drills (`filter`, `select`, `summarize`)

This exercise is designed to help you keep building your `dplyr` skills. These skills are important to data cleaning and digging, which in turn is important to really making meaning of our data. We'll work with a simpler set of 10 data points:

```{r}
new_lifts <- lifts %>% 
    select(Name, State, Sex, Age, BodyweightKg, SWR) %>% 
    head(10)
```

### Verb 1: `summarize`

Thus far, in the `dplyr` grammar you've seen 3 **verbs** or action words: `summarize()`, `select()`, `filter()`. Try out the following code and then summarize the point of the `summarize()` function:

```{r}
new_lifts %>% 
    summarize(mean_bodyweight = mean(BodyweightKg, na.rm=T),
              mean_SWR = mean(SWR, na.rm=T))
```

### Verb 2: `select`

Try out the following code and then summarize the point of the `select()` function:

```{r}
new_lifts %>%
    select(Name, State)
```

```{r}
new_lifts %>% 
    select(-Name, -State)
```

### Verb 3: `filter`

Try out the following code and then summarize the point of the `filter()` function:

```{r}
new_lifts %>% 
    filter(Age >=28)
```

```{r}
new_lifts %>% 
    filter(State == "CA")
```

```{r}
new_lifts %>% 
    filter(Age >= 28, State=="CA")
```

Use `dplyr` verbs to complete each task below using the `new_lifts` dataframe.

```{r}
# Keep only BodyweightKg and SWR variables

new_lifts %>%
  select(BodyweightKg, SWR)

# Keep only BodyweightKg and SWR variables using a different approach
new_lifts %>%
  select(-Name, -State, -Age, -Sex)

# Keep only participants (observations) who are female
new_lifts %>%
  filter(Sex=="F")

# Keep only participants (observations) who are female and younger than 30
new_lifts %>%
  filter(Sex=="F", Age<30)

# Calculate the maximum and minimum ages of participants
new_lifts %>%
  summarise(age_min = min(Age, na.rm=T),
            age_max = max(Age, na.rm=T))

```

## Exercise 12: Limitations of correlation


```{r}
# correlation between x1, y1
anscombe %>% summarize(cor(x1, y1))

# correlation between x2, y2
anscombe %>% summarize(cor(x2, y2))

# correlation between x3, y3
anscombe %>% summarize(cor(x3, y3))

# correlation between x4, y4
anscombe %>% summarize(cor(x4, y4))

```

a.  Each of these correlations are nearly the same!

b.  Each of these correlations is relatively strong, and positive, since 0.8 is positive and closer to 1 than 0.

c.  

```{r}
# scatterplot: x1, y1
anscombe %>%
  ggplot(aes(x = x1, y = y1)) +
  geom_point()

# scatterplot: x2, y2
anscombe %>%
  ggplot(aes(x = x2, y = y2)) +
  geom_point()

# scatterplot: x3, y3
anscombe %>%
  ggplot(aes(x = x3, y = y3)) +
  geom_point()

# scatterplot: x4, y4
anscombe %>%
  ggplot(aes(x = x4, y = y4)) +
  geom_point()

```

e.  The message of this exercise is that data visualization is important *in addition* to numerical summaries! Many different sets of points can have nearly the same correlation, but display very different patterns in point clouds upon closer inspection. Reporting correlation alone is not enough to summarize the relationship between two quantitative variables, and should be accompanied by a scatter plot!

## Exercise 13: Correlation and **extreme** values

```{r}
# create a toy dataset
set.seed(1234)
x <- rnorm(100, mean = 5, sd = 2)
y <- -3 * x + rnorm(100, sd = 4)
dat <- data.frame(x = x, y = y)
```

a.  

```{r}
# scatterplot
dat %>% 
  ggplot(aes(x = x, y = y)) +
  geom_point()
```

b.  The correlation between x and y is moderately strong and negative.
c.  I'll guess -0.6, since the relationship is negative and is sort of in-between weak and strong.
d.  

```{r}
# correlation
dat %>% summarize(cor(x, y))
```

e.  

```{r}
# creating dat_new1
x1 <- c(x, 15)
y1 <- c(y, -45)
dat_new1 <- data.frame(x = x1, y = y1)
```

f.  

```{r}
# scatterplot
dat_new1 %>%
  ggplot(aes(x1, y1)) +
  geom_point()

# correlation
dat %>% summarize(cor(x1, y1))
```

Our correlation stayed roughly the same with the addition of this new point!

g.  

```{r}
# creating dat_new1
x2 <- c(x, 15)
y2 <- c(y, 45)
dat_new2 <- data.frame(x = x2, y = y2)
```

h.  

```{r}
# scatterplot
dat_new2 %>%
  ggplot(aes(x2, y2)) +
  geom_point()

# correlation
dat_new2 %>% summarize(cor(x2, y2))
```

The correlation changes quite a bit with the addition of this new point! Something to note is that this new point does not follow the rough linear trend that the original points had, that the first point we considered adding also had. This line seems way off base, comparatively!

i.  The takeaway message here is that even though both of these additional points might be considered "outliers" because they have extreme x values, one changes the relationship between x and y much more than the other. In this case, the second point we considered would be **influential** because it changes the observed relationship between all x's and y's much more than the first point we considered. Not all "outliers" are considered equal!

j.  

```{r}
dat_new1 %>%
  ggplot(aes(x1, y1)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)

dat_new2 %>%
  ggplot(aes(x2, y2)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)
```
