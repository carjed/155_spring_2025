---
title: "Solutions for 06. Simple linear regression: Transformations"
subtitle: "Notes and in-class exercises"
format: 
  html:
    embed-resources: true
    toc: true
---

```{r warning=FALSE, message=FALSE}
# Load packages and import data
library(readr)
library(ggplot2)
library(dplyr)

homes <- read_csv("https://mac-stat.github.io/data/homes.csv")

bigmac <- read_csv("https://mac-stat.github.io/data/bigmac.csv")

college <- read_csv("https://mac-stat.github.io/data/college.csv")
```

## Exercise 1: Location transformations

Location transformations are ones that shift a predictor variable up or down by a fixed amount. Using a location transformation is sometimes also called **centering** a predictor.

We'll use the `homes` data in this exercise.

a. Fit a linear regression model of `Price` as a function of `Living.Area`, and call this model `home_mod`.

```{r}
# Fit the model
home_mod <- lm(Price ~ Living.Area, data = homes)

# Display model summary output
coef(summary(home_mod))
```

b. 
    - Interpretation of slope: Every 1 square foot increase in living area is associated with an expected / average increase in house price of $113.12.
    - Interpretation of intercept: The average/expected house price for a house with zero square feet is $13,439.39. Can a house ever be zero square feet??? Nope! The intercept is meaningless in this case.

c. 

```{r}
homes %>% 
    summarize(min(Living.Area))

# mutate() creates a new variable called Living.Area.Shifted that is equal to Living.Area - 600
homes <- homes %>%
    mutate(Living.Area.Shifted = Living.Area-600)
```

d. 
    - In general terms, the intercept in this model should represent the average house price when `Living.Area.Shifted` is 0---in other words when `Living.Area` is 600 square feet. From the coefficient estimates in `home_mod`, we can calculate the expected / predicted house price for 600 square foot homes: 13439.394 + (113.123*600) = 81312.89. So we're expecting the new intercept to be $81312.89.
    - The slope in this model represents the average price change for each unit change in `Living.Area.Shifted` (which is the same as a unit change in `Living.Area`). Based on this, the slope should be the same as in `home_mod` ($113.12 per square foot).

e. Lines up with work in part d!

```{r}
# Fit a model of Price vs. Living.Area.Shifted
home_mod_centered <- lm(Price ~ Living.Area.Shifted, data = homes)

# Display model summary output
coef(summary(home_mod_centered))
```


## Exercise 2: Scale transformations

In the code chunk below, construct a visualization comparing graduation rate (our outcome variable) and admissions rate (our predictor of interest). Remember that your outcome variable should be on the y-axis, in general!

```{r}
# Scatterplot of graduation rate vs. admissions rate
college %>%
  ggplot(aes(x = AdmisRate, y = GradRate)) +
  geom_point()
```

a. The correlation between admissions and graduation rates appears to be weakly negative. Notably, there are hard boundaries to admissions and graduation rates, since both must fall between 0 and 100%! A few colleges hit up against these boundaries. I would say that, with the exception of the observations that have either 0% graduation rates or 0% admission rates, the relationship does appear to be roughly linear.

b. E[GradRate | AdmisRate] = $\beta_0$ + $\beta_1$ AdmisRate

c.

```{r}
# Linear regression model with GradRate as the outcome, AdmisRate as predictor of interest
mod <- lm(GradRate ~ AdmisRate, data = college)
summary(mod)
```


> Intercept Estimate: 0.68409

> Slope Estimate: -0.34613

c. One unit of `AdmisRate` corresponds to a 100% change in admissions rates! The same goes for graduation rate. This is a huge change (in fact, the largest change possible).

d. Suppose I want the interpretation of my slope coefficient for `AdmisRate` in my linear model to be in terms a "1% increase in admissions rate." To achieve this, we could **mutate** our `AdmisRate` variable to range from 0 to 100. Let's do that for `GradRate` too (just because!):

```{r}
# Mutate
college <- college %>%
  mutate(AdmisRate = AdmisRate * 100,
         GradRate = GradRate * 100)
```

e. Fit a *new* linear regression model with the updated `AdmisRate` and `GradRate` variables as your predictor of interest and outcome, respectively. Again, report the intercept and slope estimate from your model.

```{r}
# Linear regression model with updated GradRate as the outcome, updated AdmisRate as predictor of interest
mod_new <- lm(GradRate ~ AdmisRate, data = college)
summary(mod_new)
```


> Intercept Estimate: 68.4088

> Slope Estimate: -0.3461

Our intercept estimate is now 100x larger, and our slope estimate has remained the same! The slope remained the same because we multiplied our outcome and our predictor of interest by the same value, and the intercept is 100x larger because we multiplied our outcome by 100 (recall that the intercept is the average expected outcome when "x" is zero).

f. On average, we expect colleges that differ in admissions rate by 1% to have 0.35% different graduation rates, with colleges with higher admissions rates having lower graduation rates.

## Exercise 3: Log transformations 

a. 

```{r}
# Visualization: Big Mac minutes vs. gross annual teacher income
bigmac %>%
  ggplot(aes(x = gross_annual_teacher_income, y = bigmac_mins)) +
  geom_point() 
```

As annual teacher income gets higher, time it takes in minutes to earn a Big Mac decreases, though the relationship does not appear linear. The amount of time it takes to earn a Big Mac is very high when income is below about 10,000 where it sharply decreases, and then decreases at a much lower rate when income is above around 20,000.

b. Correlation is a summary of the *linear* relationship between two quantitative variables, and this relationship does not appear to be linear!


c.

```{r}
# Linear regression code
mod <- lm(bigmac_mins ~ gross_annual_teacher_income, data = bigmac)
summary(mod)
```

On average, we expect a one dollar increase in gross annual teacher income to be associated with a decrease in the number of minutes it takes to earn a Big Mac by 9 x 10^(-4) minutes. Stated differently, we expect a *ten-thousand* dollar increase in gross annual teacher income to be associated with a decrease in the number of minutes it takes to earn a Big Mac by 9 minutes (note that here I did a *scale* transformation of gross annual teacher income to get this interpretation, which might make more sense when looking at the scale of salary!).

d. 

```{r}
# Residuals vs. fitted values plot
ggplot(mod, aes(x = .fitted, y = .resid)) + 
    geom_point() + 
    geom_hline(yintercept = 0) +
    geom_smooth(se = FALSE)
```

The residuals vs. fitted values plot shows a very clear, nonlinear pattern! As fitted values increase, residuals decrease for a while, and then sharply increase once fitted values are higher than around 40 minutes. The spread of residuals around zero also varies, with greater spread for higher fitted values.

e. The residuals appear to be large for people with negative fitted values and those with very high fitted values. Recall that a linear model does not "know" that number of minutes to earn a Big Mac can't be negative, in context. If we look at the fitted line from our linear model on a scatterplot (see below)...

```{r}
bigmac %>%
  ggplot(aes(x = gross_annual_teacher_income, y = bigmac_mins)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)
```

We observe that negative fitted values and very large fitted values occur when annual teacher income is greater than around 70,000 and less than 10,000, respectively. This implies that the model does a worse job at predicting the number of minutes to earn a Big Mac in countries where annual teacher income is either very high or very low. 




We'll now consider a log transformation of teaching salary. In the code chunk below, create a new variable called `log_sal` that contains the logged values of `gross_annual_teacher_income`.

```{r}
# Creating new variable log_sal
bigmac <- bigmac %>%
  mutate(log_sal = log(gross_annual_teacher_income))
```

f. 

```{r}
bigmac %>%
  ggplot(aes(log_sal, bigmac_mins)) +
  geom_point()
```
The relationship between logged annual teaching salary and minutes to earn a Big Mac appears roughly linear, with a weakly negative relationship. Correlation is likely an appropriate numerical summary for the relationship between these two quantitative variables, as the relationship is roughly linear!


g. 

```{r}
mod_log <- lm(bigmac_mins ~ log_sal, data = bigmac)
summary(mod_log)
```

Each 1 unit increase in logged salary is associated with a 18.14 minute decrease in time to earn a Big Mac on average.

We can also use a property of logarithms to interpret the slope of -18.14 in a different way. Suppose we have two salaries: Salary1 and Salary2. If Salary2 is 10% higher than Salary1, then Salary2/Salary1 = 1.1. It is a property of logarithms that log(Salary2/Salary1) = log(Salary2) - log(Salary1). In this case log(Salary2/Salary1) = log(Salary2) - log(Salary1) = log(1.1) = 0.09531018. So a 10% increase in salary is a 0.09 unit increase in the log scale:

```{r}
# Multiplicative difference of 1.1, or 10% between salaries gives us the 
log(1.1) * -18.142
```

While a 1 unit increase in log salary is associated with an average decrease of 18 Big Mac minutes, a 0.0953 unit increase in log salary (which corresponds to a 10% multiplicative increase), is associated with a 1.7 minute decrease in Big Mac minutes.

```
Underlying math:
Case 1: Salary = x
   E[bigmacmin_1] = beta0 + beta1 log(x)
Case 2: Salary = m*x
   E[bigmacmin_2] = beta0 + beta1 log(m*x)

E[bigmacmin_2] - E[bigmacmin_1] = beta1 log(m)
```

h. 

```{r}
# Residuals vs. fitted values plot
ggplot(mod_log, aes(x = .fitted, y = .resid)) + 
    geom_point() + 
    geom_hline(yintercept = 0) +
    geom_smooth(se = FALSE)
```

The residuals seem to lie roughly around zero for all possible fitted values, though the spread is still noticably larger for larger fitted values compared to smaller ones. This implies that the linearity assumption is likely satisfied for this model, but equal variance may be a concern.


